{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Ray RLlib 노트북"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "필요 패키지 삽입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from horcrux_terrain_v1.envs import SandWorld\n",
    "from horcrux_terrain_v1.envs import PlaneWorld\n",
    "\n",
    "import ray\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms import ppo\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.tune.registry import register_env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ray 실행 (Warning 관련 무시 키워드)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 11:50:41,273\tINFO worker.py:1777 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd119b6a9034c57b3c0aa680c49f42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.12.5</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.36.1</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='127.0.0.1:8265', python_version='3.12.5', ray_version='2.36.1', ray_commit='999f7668b65dbd208817b3671b441fd97fca755c')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(runtime_env={\"env_vars\": {\"PYTHONWARNINGS\": \"ignore::DeprecationWarning\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gym -> Rllib Env 등록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"forward_reward_weight\": 4,\n",
    "    \"side_cost_weight\": 2,\n",
    "    \"unhealthy_max_steps\": 75,\n",
    "    \"healthy_roll_range\": (-55,55),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 0.05,\n",
    "    \"termination_reward\": 0,\n",
    "}\n",
    "\n",
    "# Sand\n",
    "register_env(\"sand-v1\", lambda config: SandWorld(forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                 side_cost_weight=env_config[\"side_cost_weight\"], \n",
    "                                                 unhealthy_max_steps=env_config[\"unhealthy_max_steps\"], \n",
    "                                                 healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                 terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                 rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                 termination_reward=env_config[\"termination_reward\"]))\n",
    "\n",
    "# Plane\n",
    "register_env(\"plane-v1\", lambda config: PlaneWorld(forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                 side_cost_weight=env_config[\"side_cost_weight\"], \n",
    "                                                 unhealthy_max_steps=env_config[\"unhealthy_max_steps\"], \n",
    "                                                 healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                 terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                 rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                 termination_reward=env_config[\"termination_reward\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 알고리즘 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 11:51:00,108\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.resources(num_cpus_per_worker)` has been deprecated. Use `AlgorithmConfig.env_runners(num_cpus_per_env_runner)` instead. This will raise an error in the future!\n",
      "2024-10-03 11:51:00,108\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.resources(num_gpus_per_worker)` has been deprecated. Use `AlgorithmConfig.env_runners(num_gpus_per_env_runner)` instead. This will raise an error in the future!\n",
      "2024-10-03 11:51:00,108\tWARNING deprecation.py:50 -- DeprecationWarning: `rollouts` has been deprecated. Use `AlgorithmConfig.env_runners(..)` instead. This will raise an error in the future!\n",
      "2024-10-03 11:51:00,108\tWARNING deprecation.py:50 -- DeprecationWarning: `AlgorithmConfig.env_runners(num_rollout_workers)` has been deprecated. Use `AlgorithmConfig.env_runners(num_env_runners)` instead. This will raise an error in the future!\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\ray\\rllib\\algorithms\\algorithm.py:555: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\ray\\tune\\logger\\unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "\u001b[36m(pid=32996)\u001b[0m c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "\u001b[36m(pid=32996)\u001b[0m   \"cipher\": algorithms.TripleDES,\n",
      "\u001b[36m(pid=32996)\u001b[0m c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "\u001b[36m(pid=32996)\u001b[0m   \"class\": algorithms.Blowfish,\n",
      "\u001b[36m(pid=32996)\u001b[0m c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "\u001b[36m(pid=32996)\u001b[0m   \"class\": algorithms.TripleDES,\n",
      "\u001b[36m(pid=34276)\u001b[0m c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:243: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\u001b[32m [repeated 22x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(pid=34276)\u001b[0m   \"cipher\": algorithms.TripleDES,\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=34276)\u001b[0m c:\\Users\\doore\\anaconda3\\envs\\gdtor\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=34276)\u001b[0m   \"class\": algorithms.Blowfish,\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(pid=34276)\u001b[0m   \"class\": algorithms.TripleDES,\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "2024-10-03 11:51:20,240\tINFO trainable.py:161 -- Trainable.setup took 20.082 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "2024-10-03 11:51:20,240\tWARNING util.py:61 -- Install gputil for GPU system monitoring.\n"
     ]
    }
   ],
   "source": [
    "config = PPOConfig()\n",
    "# Activate new API stack. -> 구려서 안씀.\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "# config.environment(\"sand-v1\")\n",
    "config.environment(\"plane-v1\")\n",
    "config.framework(\"torch\")\n",
    "total_workers = 12\n",
    "config.resources(num_gpus=1,num_cpus_per_worker=1, num_gpus_per_worker= 1/(total_workers+1))\n",
    "config.rollouts(num_rollout_workers=total_workers)\n",
    "config.training(\n",
    "    gamma=0.9, \n",
    "    lr=0.0001, \n",
    "    # kl_coeff=0.3, \n",
    "\n",
    "    # See model catalog for more options.\n",
    "    # https://docs.ray.io/en/latest/rllib/rllib-models.html\n",
    "    model={ \"fcnet_hiddens\": [512, 512, 512, 512, 512],\n",
    "            },\n",
    ")\n",
    "config.evaluation(evaluation_interval=100)\n",
    "\n",
    "# # See model catalog for more options.\n",
    "# # https://docs.ray.io/en/latest/rllib/rllib-models.html\n",
    "# # config.model[\"fcnet_hiddens\"] = [512, 512, 512, 512, 512]\n",
    "# config.model[\"uses_new_env_runners\"] = True\n",
    "# config.model[\"fcnet_hiddens\"] = [1024, 1024, 1024, 1024, 1024]\n",
    "# config.model[\"use_lstm\"] = True\n",
    "# # config.model[\"lstm_cell_size\"] = 2048\n",
    "# config.model[\"lstm_cell_size\"] = 4096\n",
    "# config.model[\"max_seq_len\"] = 200\n",
    "# config.model[\"lstm_use_prev_action\"] = True\n",
    "\n",
    "algo = config.build()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "혹시 이전 학습 결과를 로드할 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm.from_checkpoint(\"./PPO/GD_v2/1st/PPO_GD_V2_512x5_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 파라미터 재조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo.get_config().training().num_sgd_iter\n",
    "\n",
    "#Env runner 파라미터 보기.\n",
    "# algo.env_runner.config[\"exploration_config\"]\n",
    "# algo.get_config().model\n",
    "\n",
    "# algo.compute_single_action()\n",
    "# algo.get_policy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 11:52:21,634\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_0), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 0.20000000000000004, 'cur_lr': 0.00010000000000000003, 'total_loss': 1.2339975607931934, 'policy_loss': -0.18959970952722655, 'vf_loss': 1.4140552848257044, 'vf_explained_var': 0.23740630976615412, 'kl': 0.047709940831922995, 'entropy': 19.856002411791074, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'env_runners': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_timesteps_total': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_episodes': 0, 'episode_return_max': nan, 'episode_return_min': nan, 'episode_return_mean': nan, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000, 'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 344.73473428037966, 'num_env_steps_trained_throughput_per_sec': 344.73473428037966, 'timesteps_total': 4000, 'num_env_steps_sampled_lifetime': 4000, 'num_agent_steps_sampled_lifetime': 4000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000, 'timers': {'training_iteration_time_ms': 11603.124, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 11603.124, 'sample_time_ms': 4986.496, 'load_time_ms': 2.362, 'load_throughput': 1693299.96, 'learn_time_ms': 6597.515, 'learn_throughput': 606.289, 'synch_weights_time_ms': 16.752}, 'counters': {'num_env_steps_sampled': 4000, 'num_env_steps_trained': 4000, 'num_agent_steps_sampled': 4000, 'num_agent_steps_trained': 4000}, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2024-10-03_11-52-28', 'timestamp': 1727923948, 'time_this_iter_s': 11.61886191368103, 'time_total_s': 11.61886191368103, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 11.61886191368103, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': 2.3448979591836734, 'ram_util_percent': 39.33979591836734}})\n",
      "001th iteration done\n",
      "002th iteration done\n",
      "003th iteration done\n",
      "004th iteration done\n",
      "005th iteration done\n",
      "006th iteration done\n",
      "007th iteration done\n",
      "008th iteration done\n",
      "009th iteration done\n",
      "010th iteration done\n",
      "011th iteration done\n",
      "012th iteration done\n",
      "013th iteration done\n",
      "014th iteration done\n",
      "015th iteration done\n",
      "016th iteration done\n",
      "017th iteration done\n",
      "018th iteration done\n",
      "019th iteration done\n",
      "020th iteration done\n",
      "021th iteration done\n",
      "022th iteration done\n",
      "023th iteration done\n",
      "024th iteration done\n",
      "025th iteration done\n",
      "026th iteration done\n",
      "027th iteration done\n",
      "028th iteration done\n",
      "029th iteration done\n",
      "030th iteration done\n",
      "031th iteration done\n",
      "032th iteration done\n",
      "033th iteration done\n",
      "034th iteration done\n",
      "035th iteration done\n",
      "036th iteration done\n",
      "037th iteration done\n",
      "038th iteration done\n",
      "039th iteration done\n",
      "040th iteration done\n",
      "041th iteration done\n",
      "042th iteration done\n",
      "043th iteration done\n",
      "044th iteration done\n",
      "045th iteration done\n",
      "046th iteration done\n",
      "047th iteration done\n",
      "048th iteration done\n",
      "049th iteration done\n",
      "050th iteration done\n",
      "051th iteration done\n",
      "052th iteration done\n",
      "053th iteration done\n",
      "054th iteration done\n",
      "055th iteration done\n",
      "056th iteration done\n",
      "057th iteration done\n",
      "058th iteration done\n",
      "059th iteration done\n",
      "060th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_1), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.3800323170559701, 'policy_loss': -0.22563157900567016, 'vf_loss': 0.5813625092068637, 'vf_explained_var': 0.6019955463947788, 'kl': 0.016000913845072306, 'entropy': 19.695690374476936, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 56265.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 244000, 'num_env_steps_trained': 244000, 'num_agent_steps_sampled': 244000, 'num_agent_steps_trained': 244000}, 'env_runners': {'episode_reward_max': 1163.6486637547255, 'episode_reward_min': -75.04301658177748, 'episode_reward_mean': 572.7606486748615, 'episode_len_mean': 4817.772727272727, 'episode_media': {}, 'episodes_timesteps_total': 211982, 'policy_reward_min': {'default_policy': -75.04301658177748}, 'policy_reward_max': {'default_policy': 1163.6486637547255}, 'policy_reward_mean': {'default_policy': 572.7606486748615}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-1.3132209283587635, 3.6578144454846067, 122.51828404653371, 168.61289996560322, -27.626108639883427, 310.98613256433333, 398.53161983164995, 441.9475156395013, 407.36101189264343, 400.4584816758263, 365.0561918464803, 375.41877961240635, 373.70557861751354, 405.57684875924866, 512.655016332169, 165.3228915812251, -59.39144905470101, 469.99772412093404, 560.8540089988979, 464.1816532439882, 799.3459638039487, 761.1225135904208, 793.4753022358074, 813.241008826498, 817.6009449764691, 776.2808794849414, 801.4058580342461, 902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372], 'episode_lengths': [425, 780, 2678, 3365, 409, 4635, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1753, 1027, 5346, 6000, 4245, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3042, 515, 3714, 48, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [-1.3132209283587635, 3.6578144454846067, 122.51828404653371, 168.61289996560322, -27.626108639883427, 310.98613256433333, 398.53161983164995, 441.9475156395013, 407.36101189264343, 400.4584816758263, 365.0561918464803, 375.41877961240635, 373.70557861751354, 405.57684875924866, 512.655016332169, 165.3228915812251, -59.39144905470101, 469.99772412093404, 560.8540089988979, 464.1816532439882, 799.3459638039487, 761.1225135904208, 793.4753022358074, 813.241008826498, 817.6009449764691, 776.2808794849414, 801.4058580342461, 902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.330917123362222, 'mean_inference_ms': 9.762877096337515, 'mean_action_processing_ms': 0.20434710728088745, 'mean_env_wait_ms': 2.3564834833456683, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.01136281273581765, 'StateBufferConnector_ms': 0.004544583233920011, 'ViewRequirementAgentConnector_ms': 0.10857256976040927}, 'num_episodes': 1, 'episode_return_max': 1163.6486637547255, 'episode_return_min': -75.04301658177748, 'episode_return_mean': 572.7606486748615, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 244000, 'num_agent_steps_trained': 244000, 'num_env_steps_sampled': 244000, 'num_env_steps_trained': 244000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 403.3504995704614, 'num_env_steps_trained_throughput_per_sec': 403.3504995704614, 'timesteps_total': 244000, 'num_env_steps_sampled_lifetime': 244000, 'num_agent_steps_sampled_lifetime': 244000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 244000, 'timers': {'training_iteration_time_ms': 10193.662, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10193.562, 'sample_time_ms': 4376.918, 'load_time_ms': 17.563, 'load_throughput': 227748.62, 'learn_time_ms': 5774.275, 'learn_throughput': 692.728, 'synch_weights_time_ms': 24.406}, 'counters': {'num_env_steps_sampled': 244000, 'num_env_steps_trained': 244000, 'num_agent_steps_sampled': 244000, 'num_agent_steps_trained': 244000}, 'done': False, 'training_iteration': 61, 'trial_id': 'default', 'date': '2024-10-03_12-02-46', 'timestamp': 1727924566, 'time_this_iter_s': 9.932932376861572, 'time_total_s': 629.0623548030853, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 629.0623548030853, 'iterations_since_restore': 61, 'perf': {'cpu_util_percent': 16.057142857142857, 'ram_util_percent': 39.7}})\n",
      "061th iteration done\n",
      "062th iteration done\n",
      "063th iteration done\n",
      "064th iteration done\n",
      "065th iteration done\n",
      "066th iteration done\n",
      "067th iteration done\n",
      "068th iteration done\n",
      "069th iteration done\n",
      "070th iteration done\n",
      "071th iteration done\n",
      "072th iteration done\n",
      "073th iteration done\n",
      "074th iteration done\n",
      "075th iteration done\n",
      "076th iteration done\n",
      "077th iteration done\n",
      "078th iteration done\n",
      "079th iteration done\n",
      "080th iteration done\n",
      "081th iteration done\n",
      "082th iteration done\n",
      "083th iteration done\n",
      "084th iteration done\n",
      "085th iteration done\n",
      "086th iteration done\n",
      "087th iteration done\n",
      "088th iteration done\n",
      "089th iteration done\n",
      "090th iteration done\n",
      "091th iteration done\n",
      "092th iteration done\n",
      "093th iteration done\n",
      "094th iteration done\n",
      "095th iteration done\n",
      "096th iteration done\n",
      "097th iteration done\n",
      "098th iteration done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-03 12:09:52,513\tWARNING env_runner_v2.py:158 -- More than 6000 observations in 6000 env steps for episode 728404237681758076 are buffered in the sampler. If this is more than you expected, check that that you set a horizon on your environment correctly and that it terminates at some point. Note: In multi-agent environments, `rollout_fragment_length` sets the batch size based on (across-agents) environment steps, not the steps of individual agents, which can result in unexpectedly large batches.Also, you may be waiting for your Env to terminate (batch_mode=`complete_episodes`). Make sure it does at some point.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "099th iteration done\n",
      "100th iteration done\n",
      "101th iteration done\n",
      "102th iteration done\n",
      "103th iteration done\n",
      "104th iteration done\n",
      "105th iteration done\n",
      "106th iteration done\n",
      "107th iteration done\n",
      "108th iteration done\n",
      "109th iteration done\n",
      "110th iteration done\n",
      "111th iteration done\n",
      "112th iteration done\n",
      "113th iteration done\n",
      "114th iteration done\n",
      "115th iteration done\n",
      "116th iteration done\n",
      "117th iteration done\n",
      "118th iteration done\n",
      "119th iteration done\n",
      "120th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_2), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.25191531026315306, 'policy_loss': -0.20997085455224238, 'vf_loss': 0.43917697154183283, 'vf_explained_var': 0.6513768991475464, 'kl': 0.014952555193076967, 'entropy': 19.47429323709139, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 112065.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 484000, 'num_env_steps_trained': 484000, 'num_agent_steps_sampled': 484000, 'num_agent_steps_trained': 484000, 'num_env_steps_sampled_for_evaluation_this_iter': 53332}, 'env_runners': {'episode_reward_max': 1812.787585087173, 'episode_reward_min': -75.04301658177748, 'episode_reward_mean': 977.5866689199585, 'episode_len_mean': 5259.164705882353, 'episode_media': {}, 'episodes_timesteps_total': 447029, 'policy_reward_min': {'default_policy': -75.04301658177748}, 'policy_reward_max': {'default_policy': 1812.787585087173}, 'policy_reward_mean': {'default_policy': 977.5866689199585}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [-1.3132209283587635, 3.6578144454846067, 122.51828404653371, 168.61289996560322, -27.626108639883427, 310.98613256433333, 398.53161983164995, 441.9475156395013, 407.36101189264343, 400.4584816758263, 365.0561918464803, 375.41877961240635, 373.70557861751354, 405.57684875924866, 512.655016332169, 165.3228915812251, -59.39144905470101, 469.99772412093404, 560.8540089988979, 464.1816532439882, 799.3459638039487, 761.1225135904208, 793.4753022358074, 813.241008826498, 817.6009449764691, 776.2808794849414, 801.4058580342461, 902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372, 1200.1809036566203, 1177.31043743872, 1211.7306585674037, 1257.2238173936555, 1270.2356615586405, 1267.2139341449592, 1242.931349163488, 1247.26662039028, 1318.4013229087775, 654.846924399795, 1326.656937681515, 1367.6119130400464, 1345.619548575337, 1444.6834909412455, 1446.4814799112507, 1450.245585197548, 1516.3241492827506, 1512.9528241587984, 218.522055279465, 1286.2945969101538, 1534.7388218002015, 1471.87637443092, 1519.8310766644681, 1488.2136652938586, 1527.9103511327155, 1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173], 'episode_lengths': [425, 780, 2678, 3365, 409, 4635, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1753, 1027, 5346, 6000, 4245, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3042, 515, 3714, 48, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3038, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2103, 5153, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4170, 6000, 4583, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [-1.3132209283587635, 3.6578144454846067, 122.51828404653371, 168.61289996560322, -27.626108639883427, 310.98613256433333, 398.53161983164995, 441.9475156395013, 407.36101189264343, 400.4584816758263, 365.0561918464803, 375.41877961240635, 373.70557861751354, 405.57684875924866, 512.655016332169, 165.3228915812251, -59.39144905470101, 469.99772412093404, 560.8540089988979, 464.1816532439882, 799.3459638039487, 761.1225135904208, 793.4753022358074, 813.241008826498, 817.6009449764691, 776.2808794849414, 801.4058580342461, 902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372, 1200.1809036566203, 1177.31043743872, 1211.7306585674037, 1257.2238173936555, 1270.2356615586405, 1267.2139341449592, 1242.931349163488, 1247.26662039028, 1318.4013229087775, 654.846924399795, 1326.656937681515, 1367.6119130400464, 1345.619548575337, 1444.6834909412455, 1446.4814799112507, 1450.245585197548, 1516.3241492827506, 1512.9528241587984, 218.522055279465, 1286.2945969101538, 1534.7388218002015, 1471.87637443092, 1519.8310766644681, 1488.2136652938586, 1527.9103511327155, 1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.331320465436625, 'mean_inference_ms': 9.669481242508027, 'mean_action_processing_ms': 0.20430198543139644, 'mean_env_wait_ms': 2.344380997330819, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00941164353314568, 'StateBufferConnector_ms': 0.005882487577550551, 'ViewRequirementAgentConnector_ms': 0.10719720055075253}, 'num_episodes': 2, 'episode_return_max': 1812.787585087173, 'episode_return_min': -75.04301658177748, 'episode_return_mean': 977.5866689199585, 'episodes_this_iter': 2}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 484000, 'num_agent_steps_trained': 484000, 'num_env_steps_sampled': 484000, 'num_env_steps_trained': 484000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 392.6375314194328, 'num_env_steps_trained_throughput_per_sec': 392.6375314194328, 'timesteps_total': 484000, 'num_env_steps_sampled_lifetime': 484000, 'num_agent_steps_sampled_lifetime': 484000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 484000, 'timers': {'training_iteration_time_ms': 10031.489, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10031.489, 'sample_time_ms': 4324.576, 'load_time_ms': 17.062, 'load_throughput': 234443.412, 'learn_time_ms': 5664.092, 'learn_throughput': 706.203, 'synch_weights_time_ms': 25.137, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 179027.628, 'evaluation_iteration_throughput': 297.898}, 'counters': {'num_env_steps_sampled': 484000, 'num_env_steps_trained': 484000, 'num_agent_steps_sampled': 484000, 'num_agent_steps_trained': 484000, 'num_env_steps_sampled_for_evaluation_this_iter': 53332}, 'done': False, 'training_iteration': 121, 'trial_id': 'default', 'date': '2024-10-03_12-15-51', 'timestamp': 1727925351, 'time_this_iter_s': 10.199254751205444, 'time_total_s': 1412.5897281169891, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 1412.5897281169891, 'iterations_since_restore': 121, 'perf': {'cpu_util_percent': 14.766666666666667, 'ram_util_percent': 40.10000000000001}})\n",
      "121th iteration done\n",
      "122th iteration done\n",
      "123th iteration done\n",
      "124th iteration done\n",
      "125th iteration done\n",
      "126th iteration done\n",
      "127th iteration done\n",
      "128th iteration done\n",
      "129th iteration done\n",
      "130th iteration done\n",
      "131th iteration done\n",
      "132th iteration done\n",
      "133th iteration done\n",
      "134th iteration done\n",
      "135th iteration done\n",
      "136th iteration done\n",
      "137th iteration done\n",
      "138th iteration done\n",
      "139th iteration done\n",
      "140th iteration done\n",
      "141th iteration done\n",
      "142th iteration done\n",
      "143th iteration done\n",
      "144th iteration done\n",
      "145th iteration done\n",
      "146th iteration done\n",
      "147th iteration done\n",
      "148th iteration done\n",
      "149th iteration done\n",
      "150th iteration done\n",
      "151th iteration done\n",
      "152th iteration done\n",
      "153th iteration done\n",
      "154th iteration done\n",
      "155th iteration done\n",
      "156th iteration done\n",
      "157th iteration done\n",
      "158th iteration done\n",
      "159th iteration done\n",
      "160th iteration done\n",
      "161th iteration done\n",
      "162th iteration done\n",
      "163th iteration done\n",
      "164th iteration done\n",
      "165th iteration done\n",
      "166th iteration done\n",
      "167th iteration done\n",
      "168th iteration done\n",
      "169th iteration done\n",
      "170th iteration done\n",
      "171th iteration done\n",
      "172th iteration done\n",
      "173th iteration done\n",
      "174th iteration done\n",
      "175th iteration done\n",
      "176th iteration done\n",
      "177th iteration done\n",
      "178th iteration done\n",
      "179th iteration done\n",
      "180th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_3), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.22430730193893436, 'policy_loss': -0.22549647582314347, 'vf_loss': 0.42754827989988226, 'vf_explained_var': 0.6645269513771098, 'kl': 0.014653826496746679, 'entropy': 19.311252868816418, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 167865.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 724000, 'num_env_steps_trained': 724000, 'num_agent_steps_sampled': 724000, 'num_agent_steps_trained': 724000, 'num_env_steps_sampled_for_evaluation_this_iter': 53332}, 'env_runners': {'episode_reward_max': 2348.1679922594576, 'episode_reward_min': -75.04301658177748, 'episode_reward_mean': 1562.0617981596254, 'episode_len_mean': 5631.29, 'episode_media': {}, 'episodes_timesteps_total': 563129, 'policy_reward_min': {'default_policy': -75.04301658177748}, 'policy_reward_max': {'default_policy': 2348.1679922594576}, 'policy_reward_mean': {'default_policy': 1562.0617981596254}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372, 1200.1809036566203, 1177.31043743872, 1211.7306585674037, 1257.2238173936555, 1270.2356615586405, 1267.2139341449592, 1242.931349163488, 1247.26662039028, 1318.4013229087775, 654.846924399795, 1326.656937681515, 1367.6119130400464, 1345.619548575337, 1444.6834909412455, 1446.4814799112507, 1450.245585197548, 1516.3241492827506, 1512.9528241587984, 218.522055279465, 1286.2945969101538, 1534.7388218002015, 1471.87637443092, 1519.8310766644681, 1488.2136652938586, 1527.9103511327155, 1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173, 1774.823100743391, 1831.164706398714, 1876.770874658914, 1856.10210244289, 1785.1701759510372, 1898.8265040779947, 1849.1200569855166, 1952.8511189046567, 824.0156222134325, 1907.7604464775488, 2058.3217507440313, 2041.6795665742864, 2030.3518312537944, 1963.5363457102205, 2066.530068572735, 2083.681660530176, 2032.2482172959456, 2038.565950903047, 2080.43725090474, 1981.0942989069126, 367.20081610653074, 2103.634410216793, 2126.18484033716, 2168.288744581293, 2221.0589915009746, 2234.7378160550193, 2118.772920850382, 2265.1676387289463, 2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726], 'episode_lengths': [6000, 6000, 6000, 3042, 515, 3714, 48, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3038, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2103, 5153, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4170, 6000, 4583, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3376, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1187, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4200, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [902.7711959416001, 751.850966956535, 876.3995395262987, 348.02563848471993, -75.04301658177748, 425.6355902117723, -11.47603864312776, 895.3431101549246, 969.3352669222073, 1077.1831151893853, 1055.270164268104, 1121.9227734388796, 1013.323746128346, 1163.6486637547255, 1095.8496442249382, 1094.0558597360173, 1076.3881764765372, 1200.1809036566203, 1177.31043743872, 1211.7306585674037, 1257.2238173936555, 1270.2356615586405, 1267.2139341449592, 1242.931349163488, 1247.26662039028, 1318.4013229087775, 654.846924399795, 1326.656937681515, 1367.6119130400464, 1345.619548575337, 1444.6834909412455, 1446.4814799112507, 1450.245585197548, 1516.3241492827506, 1512.9528241587984, 218.522055279465, 1286.2945969101538, 1534.7388218002015, 1471.87637443092, 1519.8310766644681, 1488.2136652938586, 1527.9103511327155, 1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173, 1774.823100743391, 1831.164706398714, 1876.770874658914, 1856.10210244289, 1785.1701759510372, 1898.8265040779947, 1849.1200569855166, 1952.8511189046567, 824.0156222134325, 1907.7604464775488, 2058.3217507440313, 2041.6795665742864, 2030.3518312537944, 1963.5363457102205, 2066.530068572735, 2083.681660530176, 2032.2482172959456, 2038.565950903047, 2080.43725090474, 1981.0942989069126, 367.20081610653074, 2103.634410216793, 2126.18484033716, 2168.288744581293, 2221.0589915009746, 2234.7378160550193, 2118.772920850382, 2265.1676387289463, 2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33172899034139675, 'mean_inference_ms': 9.557589132426575, 'mean_action_processing_ms': 0.20376097883393576, 'mean_env_wait_ms': 2.330739890928891, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007999181747436523, 'StateBufferConnector_ms': 0.006000995635986328, 'ViewRequirementAgentConnector_ms': 0.11760783195495605}, 'num_episodes': 3, 'episode_return_max': 2348.1679922594576, 'episode_return_min': -75.04301658177748, 'episode_return_mean': 1562.0617981596254, 'episodes_this_iter': 3}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 724000, 'num_agent_steps_trained': 724000, 'num_env_steps_sampled': 724000, 'num_env_steps_trained': 724000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 399.9689603098438, 'num_env_steps_trained_throughput_per_sec': 399.9689603098438, 'timesteps_total': 724000, 'num_env_steps_sampled_lifetime': 724000, 'num_agent_steps_sampled_lifetime': 724000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 724000, 'timers': {'training_iteration_time_ms': 10091.414, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10091.414, 'sample_time_ms': 4319.511, 'load_time_ms': 17.801, 'load_throughput': 224708.3, 'learn_time_ms': 5726.742, 'learn_throughput': 698.477, 'synch_weights_time_ms': 26.723, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 179027.628, 'evaluation_iteration_throughput': 297.898}, 'counters': {'num_env_steps_sampled': 724000, 'num_env_steps_trained': 724000, 'num_agent_steps_sampled': 724000, 'num_agent_steps_trained': 724000, 'num_env_steps_sampled_for_evaluation_this_iter': 53332}, 'done': False, 'training_iteration': 181, 'trial_id': 'default', 'date': '2024-10-03_12-25-57', 'timestamp': 1727925957, 'time_this_iter_s': 10.012776374816895, 'time_total_s': 2017.6607387065887, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2017.6607387065887, 'iterations_since_restore': 181, 'perf': {'cpu_util_percent': 15.707142857142857, 'ram_util_percent': 39.97857142857142}})\n",
      "181th iteration done\n",
      "182th iteration done\n",
      "183th iteration done\n",
      "184th iteration done\n",
      "185th iteration done\n",
      "186th iteration done\n",
      "187th iteration done\n",
      "188th iteration done\n",
      "189th iteration done\n",
      "190th iteration done\n",
      "191th iteration done\n",
      "192th iteration done\n",
      "193th iteration done\n",
      "194th iteration done\n",
      "195th iteration done\n",
      "196th iteration done\n",
      "197th iteration done\n",
      "198th iteration done\n",
      "199th iteration done\n",
      "200th iteration done\n",
      "201th iteration done\n",
      "202th iteration done\n",
      "203th iteration done\n",
      "204th iteration done\n",
      "205th iteration done\n",
      "206th iteration done\n",
      "207th iteration done\n",
      "208th iteration done\n",
      "209th iteration done\n",
      "210th iteration done\n",
      "211th iteration done\n",
      "212th iteration done\n",
      "213th iteration done\n",
      "214th iteration done\n",
      "215th iteration done\n",
      "216th iteration done\n",
      "217th iteration done\n",
      "218th iteration done\n",
      "219th iteration done\n",
      "220th iteration done\n",
      "221th iteration done\n",
      "222th iteration done\n",
      "223th iteration done\n",
      "224th iteration done\n",
      "225th iteration done\n",
      "226th iteration done\n",
      "227th iteration done\n",
      "228th iteration done\n",
      "229th iteration done\n",
      "230th iteration done\n",
      "231th iteration done\n",
      "232th iteration done\n",
      "233th iteration done\n",
      "234th iteration done\n",
      "235th iteration done\n",
      "236th iteration done\n",
      "237th iteration done\n",
      "238th iteration done\n",
      "239th iteration done\n",
      "240th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_4), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.7206761445729963, 'policy_loss': -0.17909171913339886, 'vf_loss': 0.8797188761993898, 'vf_explained_var': 0.6287201718617511, 'kl': 0.013200979561185768, 'entropy': 19.16204926275438, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 223665.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 964000, 'num_env_steps_trained': 964000, 'num_agent_steps_sampled': 964000, 'num_agent_steps_trained': 964000, 'num_env_steps_sampled_for_evaluation_this_iter': 56660}, 'env_runners': {'episode_reward_max': 2788.59689606423, 'episode_reward_min': 367.20081610653074, 'episode_reward_mean': 2135.5965128101366, 'episode_len_mean': 5816.76, 'episode_media': {}, 'episodes_timesteps_total': 581676, 'policy_reward_min': {'default_policy': 367.20081610653074}, 'policy_reward_max': {'default_policy': 2788.59689606423}, 'policy_reward_mean': {'default_policy': 2135.5965128101366}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173, 1774.823100743391, 1831.164706398714, 1876.770874658914, 1856.10210244289, 1785.1701759510372, 1898.8265040779947, 1849.1200569855166, 1952.8511189046567, 824.0156222134325, 1907.7604464775488, 2058.3217507440313, 2041.6795665742864, 2030.3518312537944, 1963.5363457102205, 2066.530068572735, 2083.681660530176, 2032.2482172959456, 2038.565950903047, 2080.43725090474, 1981.0942989069126, 367.20081610653074, 2103.634410216793, 2126.18484033716, 2168.288744581293, 2221.0589915009746, 2234.7378160550193, 2118.772920850382, 2265.1676387289463, 2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726, 2372.2687020767903, 2354.567932802703, 2349.7461955276553, 2311.5655690904377, 2357.7507997161415, 401.4753023887336, 2409.5421114705887, 2321.6578724400147, 2365.536737358809, 2441.9663156650968, 2403.554506170866, 2434.851286949805, 2486.992541774228, 2482.548906720526, 2424.6019890063, 2428.172790909706, 2448.1620049494936, 2414.323543268562, 2494.226870176027, 2560.889157980858, 2542.3588583999, 2515.0076442588665, 2474.2171880940987, 2581.261500784268, 2471.0081478660354, 2599.3591410916, 2588.307826994778, 2526.631233617597, 2634.654296980424, 2631.489355816786, 2577.1591607249834, 2599.9821408727335, 2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784], 'episode_lengths': [6000, 6000, 4170, 6000, 4583, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3376, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1187, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4200, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1290, 6000, 5735, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 5527, 6000, 5608, 6000], 'policy_default_policy_reward': [1449.9220267049325, 1614.5104313110237, 1013.0616208871749, 1616.6040803068604, 1195.1832718096584, 1702.245074479374, 1590.4615246734415, 1718.7130984288017, 1666.634836207883, 1631.380859804219, 1698.2437758210033, 1740.6020050886634, 1680.9173800903204, 1733.1181721838263, 1723.7080736955959, 1812.787585087173, 1774.823100743391, 1831.164706398714, 1876.770874658914, 1856.10210244289, 1785.1701759510372, 1898.8265040779947, 1849.1200569855166, 1952.8511189046567, 824.0156222134325, 1907.7604464775488, 2058.3217507440313, 2041.6795665742864, 2030.3518312537944, 1963.5363457102205, 2066.530068572735, 2083.681660530176, 2032.2482172959456, 2038.565950903047, 2080.43725090474, 1981.0942989069126, 367.20081610653074, 2103.634410216793, 2126.18484033716, 2168.288744581293, 2221.0589915009746, 2234.7378160550193, 2118.772920850382, 2265.1676387289463, 2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726, 2372.2687020767903, 2354.567932802703, 2349.7461955276553, 2311.5655690904377, 2357.7507997161415, 401.4753023887336, 2409.5421114705887, 2321.6578724400147, 2365.536737358809, 2441.9663156650968, 2403.554506170866, 2434.851286949805, 2486.992541774228, 2482.548906720526, 2424.6019890063, 2428.172790909706, 2448.1620049494936, 2414.323543268562, 2494.226870176027, 2560.889157980858, 2542.3588583999, 2515.0076442588665, 2474.2171880940987, 2581.261500784268, 2471.0081478660354, 2599.3591410916, 2588.307826994778, 2526.631233617597, 2634.654296980424, 2631.489355816786, 2577.1591607249834, 2599.9821408727335, 2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33171169128141365, 'mean_inference_ms': 9.500903543666771, 'mean_action_processing_ms': 0.2032848305332431, 'mean_env_wait_ms': 2.327465621343709, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007997512817382812, 'StateBufferConnector_ms': 0.006895542144775391, 'ViewRequirementAgentConnector_ms': 0.12358427047729492}, 'num_episodes': 1, 'episode_return_max': 2788.59689606423, 'episode_return_min': 367.20081610653074, 'episode_return_mean': 2135.5965128101366, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 964000, 'num_agent_steps_trained': 964000, 'num_env_steps_sampled': 964000, 'num_env_steps_trained': 964000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 388.66469392394964, 'num_env_steps_trained_throughput_per_sec': 388.66469392394964, 'timesteps_total': 964000, 'num_env_steps_sampled_lifetime': 964000, 'num_agent_steps_sampled_lifetime': 964000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 964000, 'timers': {'training_iteration_time_ms': 10094.494, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10094.494, 'sample_time_ms': 4327.356, 'load_time_ms': 18.861, 'load_throughput': 212077.746, 'learn_time_ms': 5720.997, 'learn_throughput': 699.179, 'synch_weights_time_ms': 26.744, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 184066.471, 'evaluation_iteration_throughput': 298.783}, 'counters': {'num_env_steps_sampled': 964000, 'num_env_steps_trained': 964000, 'num_agent_steps_sampled': 964000, 'num_agent_steps_trained': 964000, 'num_env_steps_sampled_for_evaluation_this_iter': 56660}, 'done': False, 'training_iteration': 241, 'trial_id': 'default', 'date': '2024-10-03_12-39-12', 'timestamp': 1727926752, 'time_this_iter_s': 10.30426287651062, 'time_total_s': 2811.7631096839905, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2811.7631096839905, 'iterations_since_restore': 241, 'perf': {'cpu_util_percent': 15.5, 'ram_util_percent': 40.0}})\n",
      "241th iteration done\n",
      "242th iteration done\n",
      "243th iteration done\n",
      "244th iteration done\n",
      "245th iteration done\n",
      "246th iteration done\n",
      "247th iteration done\n",
      "248th iteration done\n",
      "249th iteration done\n",
      "250th iteration done\n",
      "251th iteration done\n",
      "252th iteration done\n",
      "253th iteration done\n",
      "254th iteration done\n",
      "255th iteration done\n",
      "256th iteration done\n",
      "257th iteration done\n",
      "258th iteration done\n",
      "259th iteration done\n",
      "260th iteration done\n",
      "261th iteration done\n",
      "262th iteration done\n",
      "263th iteration done\n",
      "264th iteration done\n",
      "265th iteration done\n",
      "266th iteration done\n",
      "267th iteration done\n",
      "268th iteration done\n",
      "269th iteration done\n",
      "270th iteration done\n",
      "271th iteration done\n",
      "272th iteration done\n",
      "273th iteration done\n",
      "274th iteration done\n",
      "275th iteration done\n",
      "276th iteration done\n",
      "277th iteration done\n",
      "278th iteration done\n",
      "279th iteration done\n",
      "280th iteration done\n",
      "281th iteration done\n",
      "282th iteration done\n",
      "283th iteration done\n",
      "284th iteration done\n",
      "285th iteration done\n",
      "286th iteration done\n",
      "287th iteration done\n",
      "288th iteration done\n",
      "289th iteration done\n",
      "290th iteration done\n",
      "291th iteration done\n",
      "292th iteration done\n",
      "293th iteration done\n",
      "294th iteration done\n",
      "295th iteration done\n",
      "296th iteration done\n",
      "297th iteration done\n",
      "298th iteration done\n",
      "299th iteration done\n",
      "300th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_5), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.04086990278334387, 'policy_loss': -0.2227192977293124, 'vf_loss': 0.240669516343144, 'vf_explained_var': 0.7797949958873052, 'kl': 0.015091150828905688, 'entropy': 18.89176281139415, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 279465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 1204000, 'num_env_steps_trained': 1204000, 'num_agent_steps_sampled': 1204000, 'num_agent_steps_trained': 1204000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'env_runners': {'episode_reward_max': 3093.147432485096, 'episode_reward_min': -130.48974154059852, 'episode_reward_mean': 2426.2145203606806, 'episode_len_mean': 5560.07, 'episode_media': {}, 'episodes_timesteps_total': 556007, 'policy_reward_min': {'default_policy': -130.48974154059852}, 'policy_reward_max': {'default_policy': 3093.147432485096}, 'policy_reward_mean': {'default_policy': 2426.2145203606806}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726, 2372.2687020767903, 2354.567932802703, 2349.7461955276553, 2311.5655690904377, 2357.7507997161415, 401.4753023887336, 2409.5421114705887, 2321.6578724400147, 2365.536737358809, 2441.9663156650968, 2403.554506170866, 2434.851286949805, 2486.992541774228, 2482.548906720526, 2424.6019890063, 2428.172790909706, 2448.1620049494936, 2414.323543268562, 2494.226870176027, 2560.889157980858, 2542.3588583999, 2515.0076442588665, 2474.2171880940987, 2581.261500784268, 2471.0081478660354, 2599.3591410916, 2588.307826994778, 2526.631233617597, 2634.654296980424, 2631.489355816786, 2577.1591607249834, 2599.9821408727335, 2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784, -117.71226663986884, -130.48974154059852, -85.38825799170282, 641.2683389921141, 2772.6527329798814, 2783.3957072014423, 2817.176341709102, 2189.236109637237, 814.4430036660185, 2782.040017508484, 2754.976520981306, 2805.040876853534, 2829.1985019853937, 2882.8270291155486, 673.0323537406757, 2814.231322601035, 2793.13659940629, 2833.88634773617, 2882.7030292295076, 2921.4519398365364, 1345.1853487542921, 2234.7112701443075, 2951.3218858039218, 2955.2456558727154, 2900.978424222232, 2903.4728685352447, 2945.270286995255, 2965.7555464509383, 2937.0385740872007, 2982.8221621669627, 2976.233857746496, 2991.1424763250934, 2983.943320934842, 3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4200, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1290, 6000, 5735, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 5527, 6000, 5608, 6000, 244, 330, 219, 1862, 6000, 6000, 6000, 4984, 2373, 6000, 6000, 6000, 6000, 6000, 1494, 6000, 5907, 6000, 6000, 6000, 3862, 5011, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3595, 5766, 6000, 6000], 'policy_default_policy_reward': [2183.048323917055, 2263.9405830106243, 2230.142105690951, 2241.227291212268, 2196.436573597526, 2283.640276622736, 2263.6626915219476, 2329.627851417851, 1518.52784670834, 2238.414461679021, 2315.1109843078957, 2292.741887631847, 2348.1679922594576, 2289.5104050652726, 2372.2687020767903, 2354.567932802703, 2349.7461955276553, 2311.5655690904377, 2357.7507997161415, 401.4753023887336, 2409.5421114705887, 2321.6578724400147, 2365.536737358809, 2441.9663156650968, 2403.554506170866, 2434.851286949805, 2486.992541774228, 2482.548906720526, 2424.6019890063, 2428.172790909706, 2448.1620049494936, 2414.323543268562, 2494.226870176027, 2560.889157980858, 2542.3588583999, 2515.0076442588665, 2474.2171880940987, 2581.261500784268, 2471.0081478660354, 2599.3591410916, 2588.307826994778, 2526.631233617597, 2634.654296980424, 2631.489355816786, 2577.1591607249834, 2599.9821408727335, 2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784, -117.71226663986884, -130.48974154059852, -85.38825799170282, 641.2683389921141, 2772.6527329798814, 2783.3957072014423, 2817.176341709102, 2189.236109637237, 814.4430036660185, 2782.040017508484, 2754.976520981306, 2805.040876853534, 2829.1985019853937, 2882.8270291155486, 673.0323537406757, 2814.231322601035, 2793.13659940629, 2833.88634773617, 2882.7030292295076, 2921.4519398365364, 1345.1853487542921, 2234.7112701443075, 2951.3218858039218, 2955.2456558727154, 2900.978424222232, 2903.4728685352447, 2945.270286995255, 2965.7555464509383, 2937.0385740872007, 2982.8221621669627, 2976.233857746496, 2991.1424763250934, 2983.943320934842, 3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33157617936443434, 'mean_inference_ms': 9.472920750144494, 'mean_action_processing_ms': 0.20297234412603227, 'mean_env_wait_ms': 2.327012853875222, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.005997419357299805, 'StateBufferConnector_ms': 0.0068950653076171875, 'ViewRequirementAgentConnector_ms': 0.13389039039611816}, 'num_episodes': 0, 'episode_return_max': 3093.147432485096, 'episode_return_min': -130.48974154059852, 'episode_return_mean': 2426.2145203606806, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1204000, 'num_agent_steps_trained': 1204000, 'num_env_steps_sampled': 1204000, 'num_env_steps_trained': 1204000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 408.27951082821096, 'num_env_steps_trained_throughput_per_sec': 408.27951082821096, 'timesteps_total': 1204000, 'num_env_steps_sampled_lifetime': 1204000, 'num_agent_steps_sampled_lifetime': 1204000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 1204000, 'timers': {'training_iteration_time_ms': 10007.131, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10007.03, 'sample_time_ms': 4331.179, 'load_time_ms': 18.558, 'load_throughput': 215536.297, 'learn_time_ms': 5632.035, 'learn_throughput': 710.223, 'synch_weights_time_ms': 24.923, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 189215.629, 'evaluation_iteration_throughput': 299.468}, 'counters': {'num_env_steps_sampled': 1204000, 'num_env_steps_trained': 1204000, 'num_agent_steps_sampled': 1204000, 'num_agent_steps_trained': 1204000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'done': False, 'training_iteration': 301, 'trial_id': 'default', 'date': '2024-10-03_12-52-44', 'timestamp': 1727927564, 'time_this_iter_s': 9.81020975112915, 'time_total_s': 3622.91818857193, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 3622.91818857193, 'iterations_since_restore': 301, 'perf': {'cpu_util_percent': 14.757142857142854, 'ram_util_percent': 40.2}})\n",
      "301th iteration done\n",
      "302th iteration done\n",
      "303th iteration done\n",
      "304th iteration done\n",
      "305th iteration done\n",
      "306th iteration done\n",
      "307th iteration done\n",
      "308th iteration done\n",
      "309th iteration done\n",
      "310th iteration done\n",
      "311th iteration done\n",
      "312th iteration done\n",
      "313th iteration done\n",
      "314th iteration done\n",
      "315th iteration done\n",
      "316th iteration done\n",
      "317th iteration done\n",
      "318th iteration done\n",
      "319th iteration done\n",
      "320th iteration done\n",
      "321th iteration done\n",
      "322th iteration done\n",
      "323th iteration done\n",
      "324th iteration done\n",
      "325th iteration done\n",
      "326th iteration done\n",
      "327th iteration done\n",
      "328th iteration done\n",
      "329th iteration done\n",
      "330th iteration done\n",
      "331th iteration done\n",
      "332th iteration done\n",
      "333th iteration done\n",
      "334th iteration done\n",
      "335th iteration done\n",
      "336th iteration done\n",
      "337th iteration done\n",
      "338th iteration done\n",
      "339th iteration done\n",
      "340th iteration done\n",
      "341th iteration done\n",
      "342th iteration done\n",
      "343th iteration done\n",
      "344th iteration done\n",
      "345th iteration done\n",
      "346th iteration done\n",
      "347th iteration done\n",
      "348th iteration done\n",
      "349th iteration done\n",
      "350th iteration done\n",
      "351th iteration done\n",
      "352th iteration done\n",
      "353th iteration done\n",
      "354th iteration done\n",
      "355th iteration done\n",
      "356th iteration done\n",
      "357th iteration done\n",
      "358th iteration done\n",
      "359th iteration done\n",
      "360th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_6), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': -0.012414997808074438, 'policy_loss': -0.22114557307714255, 'vf_loss': 0.18519660081831432, 'vf_explained_var': 0.8080340006018197, 'kl': 0.015495621650669847, 'entropy': 18.724242226795482, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 335265.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 1444000, 'num_env_steps_trained': 1444000, 'num_agent_steps_sampled': 1444000, 'num_agent_steps_trained': 1444000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'env_runners': {'episode_reward_max': 3402.3698536895836, 'episode_reward_min': -130.48974154059852, 'episode_reward_mean': 2691.3612248332443, 'episode_len_mean': 5379.83, 'episode_media': {}, 'episodes_timesteps_total': 537983, 'policy_reward_min': {'default_policy': -130.48974154059852}, 'policy_reward_max': {'default_policy': 3402.3698536895836}, 'policy_reward_mean': {'default_policy': 2691.3612248332443}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784, -117.71226663986884, -130.48974154059852, -85.38825799170282, 641.2683389921141, 2772.6527329798814, 2783.3957072014423, 2817.176341709102, 2189.236109637237, 814.4430036660185, 2782.040017508484, 2754.976520981306, 2805.040876853534, 2829.1985019853937, 2882.8270291155486, 673.0323537406757, 2814.231322601035, 2793.13659940629, 2833.88634773617, 2882.7030292295076, 2921.4519398365364, 1345.1853487542921, 2234.7112701443075, 2951.3218858039218, 2955.2456558727154, 2900.978424222232, 2903.4728685352447, 2945.270286995255, 2965.7555464509383, 2937.0385740872007, 2982.8221621669627, 2976.233857746496, 2991.1424763250934, 2983.943320934842, 3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771, 3114.500738688906, 3051.183423576068, 3055.2988785213042, 637.8266459752361, 3102.8667192374915, 3096.6967729774137, 3078.23683085631, 3207.115066979064, 3140.7400117867314, 3163.3779896162278, 3182.9236545743756, 3111.625137332077, 3118.389672835183, 3189.318031454976, 1003.7360836613034, 2987.320322187775, 3221.060617238538, 3169.5455921654698, 3196.3375702517883, 3209.0845943999016, 3268.6567451721503, 2886.2216467704934, 3216.6897289859294, 3325.7825860484636, 1319.5751228585864, 3272.5637356754514, 2221.042338615306, 3329.2872727989434, 3363.2442202817947, 3350.145255400685, 3278.65310111455, 3279.3451877971656, 472.0679346006751, 3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 5527, 6000, 5608, 6000, 244, 330, 219, 1862, 6000, 6000, 6000, 4984, 2373, 6000, 6000, 6000, 6000, 6000, 1494, 6000, 5907, 6000, 6000, 6000, 3862, 5011, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3595, 5766, 6000, 6000, 6000, 6000, 6000, 1351, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2389, 5921, 6000, 6000, 6000, 6000, 6000, 5594, 6000, 6000, 2717, 6000, 4100, 6000, 6000, 6000, 6000, 6000, 1004, 6000, 6000, 6000, 6000, 6000, 3079, 6000, 6000, 6000, 6000, 3046, 6000, 6000], 'policy_default_policy_reward': [2675.323582589508, 2734.0793101967834, 2663.8829408642764, 2711.219231387457, 2742.074433798941, 2658.4988228159286, 2233.6920919814174, 2788.59689606423, 2532.4315686204077, 2693.6238508994784, -117.71226663986884, -130.48974154059852, -85.38825799170282, 641.2683389921141, 2772.6527329798814, 2783.3957072014423, 2817.176341709102, 2189.236109637237, 814.4430036660185, 2782.040017508484, 2754.976520981306, 2805.040876853534, 2829.1985019853937, 2882.8270291155486, 673.0323537406757, 2814.231322601035, 2793.13659940629, 2833.88634773617, 2882.7030292295076, 2921.4519398365364, 1345.1853487542921, 2234.7112701443075, 2951.3218858039218, 2955.2456558727154, 2900.978424222232, 2903.4728685352447, 2945.270286995255, 2965.7555464509383, 2937.0385740872007, 2982.8221621669627, 2976.233857746496, 2991.1424763250934, 2983.943320934842, 3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771, 3114.500738688906, 3051.183423576068, 3055.2988785213042, 637.8266459752361, 3102.8667192374915, 3096.6967729774137, 3078.23683085631, 3207.115066979064, 3140.7400117867314, 3163.3779896162278, 3182.9236545743756, 3111.625137332077, 3118.389672835183, 3189.318031454976, 1003.7360836613034, 2987.320322187775, 3221.060617238538, 3169.5455921654698, 3196.3375702517883, 3209.0845943999016, 3268.6567451721503, 2886.2216467704934, 3216.6897289859294, 3325.7825860484636, 1319.5751228585864, 3272.5637356754514, 2221.042338615306, 3329.2872727989434, 3363.2442202817947, 3350.145255400685, 3278.65310111455, 3279.3451877971656, 472.0679346006751, 3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3312204572919014, 'mean_inference_ms': 9.455506200423155, 'mean_action_processing_ms': 0.20302595550737146, 'mean_env_wait_ms': 2.3297715213380155, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.007997512817382812, 'StateBufferConnector_ms': 0.0050013065338134766, 'ViewRequirementAgentConnector_ms': 0.1394054889678955}, 'num_episodes': 1, 'episode_return_max': 3402.3698536895836, 'episode_return_min': -130.48974154059852, 'episode_return_mean': 2691.3612248332443, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1444000, 'num_agent_steps_trained': 1444000, 'num_env_steps_sampled': 1444000, 'num_env_steps_trained': 1444000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 394.8715421294527, 'num_env_steps_trained_throughput_per_sec': 394.8715421294527, 'timesteps_total': 1444000, 'num_env_steps_sampled_lifetime': 1444000, 'num_agent_steps_sampled_lifetime': 1444000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 1444000, 'timers': {'training_iteration_time_ms': 10159.761, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10159.761, 'sample_time_ms': 4340.227, 'load_time_ms': 18.774, 'load_throughput': 213059.164, 'learn_time_ms': 5774.782, 'learn_throughput': 692.667, 'synch_weights_time_ms': 25.635, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 189215.629, 'evaluation_iteration_throughput': 299.468}, 'counters': {'num_env_steps_sampled': 1444000, 'num_env_steps_trained': 1444000, 'num_agent_steps_sampled': 1444000, 'num_agent_steps_trained': 1444000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'done': False, 'training_iteration': 361, 'trial_id': 'default', 'date': '2024-10-03_13-02-52', 'timestamp': 1727928172, 'time_this_iter_s': 10.138880968093872, 'time_total_s': 4229.595450639725, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 4229.595450639725, 'iterations_since_restore': 361, 'perf': {'cpu_util_percent': 14.6, 'ram_util_percent': 40.18571428571429}})\n",
      "361th iteration done\n",
      "362th iteration done\n",
      "363th iteration done\n",
      "364th iteration done\n",
      "365th iteration done\n",
      "366th iteration done\n",
      "367th iteration done\n",
      "368th iteration done\n",
      "369th iteration done\n",
      "370th iteration done\n",
      "371th iteration done\n",
      "372th iteration done\n",
      "373th iteration done\n",
      "374th iteration done\n",
      "375th iteration done\n",
      "376th iteration done\n",
      "377th iteration done\n",
      "378th iteration done\n",
      "379th iteration done\n",
      "380th iteration done\n",
      "381th iteration done\n",
      "382th iteration done\n",
      "383th iteration done\n",
      "384th iteration done\n",
      "385th iteration done\n",
      "386th iteration done\n",
      "387th iteration done\n",
      "388th iteration done\n",
      "389th iteration done\n",
      "390th iteration done\n",
      "391th iteration done\n",
      "392th iteration done\n",
      "393th iteration done\n",
      "394th iteration done\n",
      "395th iteration done\n",
      "396th iteration done\n",
      "397th iteration done\n",
      "398th iteration done\n",
      "399th iteration done\n",
      "400th iteration done\n",
      "401th iteration done\n",
      "402th iteration done\n",
      "403th iteration done\n",
      "404th iteration done\n",
      "405th iteration done\n",
      "406th iteration done\n",
      "407th iteration done\n",
      "408th iteration done\n",
      "409th iteration done\n",
      "410th iteration done\n",
      "411th iteration done\n",
      "412th iteration done\n",
      "413th iteration done\n",
      "414th iteration done\n",
      "415th iteration done\n",
      "416th iteration done\n",
      "417th iteration done\n",
      "418th iteration done\n",
      "419th iteration done\n",
      "420th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_7), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': -0.013002754451446635, 'policy_loss': -0.21511750862763454, 'vf_loss': 0.17893057318254846, 'vf_explained_var': 0.8215342895959014, 'kl': 0.015265305676016916, 'entropy': 18.522653007507323, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 391065.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 1684000, 'num_env_steps_trained': 1684000, 'num_agent_steps_sampled': 1684000, 'num_agent_steps_trained': 1684000, 'num_env_steps_sampled_for_evaluation_this_iter': 51306}, 'env_runners': {'episode_reward_max': 3758.747644398931, 'episode_reward_min': 245.296998889539, 'episode_reward_mean': 3029.1626224506854, 'episode_len_mean': 5457.14, 'episode_media': {}, 'episodes_timesteps_total': 545714, 'policy_reward_min': {'default_policy': 245.296998889539}, 'policy_reward_max': {'default_policy': 3758.747644398931}, 'policy_reward_mean': {'default_policy': 3029.1626224506854}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771, 3114.500738688906, 3051.183423576068, 3055.2988785213042, 637.8266459752361, 3102.8667192374915, 3096.6967729774137, 3078.23683085631, 3207.115066979064, 3140.7400117867314, 3163.3779896162278, 3182.9236545743756, 3111.625137332077, 3118.389672835183, 3189.318031454976, 1003.7360836613034, 2987.320322187775, 3221.060617238538, 3169.5455921654698, 3196.3375702517883, 3209.0845943999016, 3268.6567451721503, 2886.2216467704934, 3216.6897289859294, 3325.7825860484636, 1319.5751228585864, 3272.5637356754514, 2221.042338615306, 3329.2872727989434, 3363.2442202817947, 3350.145255400685, 3278.65310111455, 3279.3451877971656, 472.0679346006751, 3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836, 3419.4718338032226, 3488.42408948537, 3397.7395328680027, 3438.711343047009, 3492.399690000689, 3472.1414265082285, 3445.67742418823, 3453.578067375246, 3485.371416625112, 3539.330449526441, 3429.5453526379533, 3526.6272183477945, 2601.96825309159, 3552.586447569259, 3567.6700802698756, 2119.05966490865, 741.2023133784328, 3534.1148876462644, 3531.441591209536, 961.3386467140936, 3629.0155658084823, 3526.521658535561, 3592.7056045543554, 3620.384381642225, 3583.5305382236998, 3588.6432759196027, 3669.384414719916, 3573.667623684291, 991.8503099612209, 3640.003683291995, 245.296998889539, 3641.934985938746, 3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 3595, 5766, 6000, 6000, 6000, 6000, 6000, 1351, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2389, 5921, 6000, 6000, 6000, 6000, 6000, 5594, 6000, 6000, 2717, 6000, 4100, 6000, 6000, 6000, 6000, 6000, 1004, 6000, 6000, 6000, 6000, 6000, 3079, 6000, 6000, 6000, 6000, 3046, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4759, 6000, 6000, 3645, 1365, 6000, 6000, 1681, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1687, 6000, 474, 6000, 6000, 6000, 6000, 6000, 1541, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [3009.027707928526, 3011.8414103072064, 2950.7253593176097, 2968.1300692706686, 2929.8498473736895, 3047.468592329309, 3093.147432485096, 1416.332894369574, 2890.666277176681, 3063.522942913688, 3077.051681741771, 3114.500738688906, 3051.183423576068, 3055.2988785213042, 637.8266459752361, 3102.8667192374915, 3096.6967729774137, 3078.23683085631, 3207.115066979064, 3140.7400117867314, 3163.3779896162278, 3182.9236545743756, 3111.625137332077, 3118.389672835183, 3189.318031454976, 1003.7360836613034, 2987.320322187775, 3221.060617238538, 3169.5455921654698, 3196.3375702517883, 3209.0845943999016, 3268.6567451721503, 2886.2216467704934, 3216.6897289859294, 3325.7825860484636, 1319.5751228585864, 3272.5637356754514, 2221.042338615306, 3329.2872727989434, 3363.2442202817947, 3350.145255400685, 3278.65310111455, 3279.3451877971656, 472.0679346006751, 3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836, 3419.4718338032226, 3488.42408948537, 3397.7395328680027, 3438.711343047009, 3492.399690000689, 3472.1414265082285, 3445.67742418823, 3453.578067375246, 3485.371416625112, 3539.330449526441, 3429.5453526379533, 3526.6272183477945, 2601.96825309159, 3552.586447569259, 3567.6700802698756, 2119.05966490865, 741.2023133784328, 3534.1148876462644, 3531.441591209536, 961.3386467140936, 3629.0155658084823, 3526.521658535561, 3592.7056045543554, 3620.384381642225, 3583.5305382236998, 3588.6432759196027, 3669.384414719916, 3573.667623684291, 991.8503099612209, 3640.003683291995, 245.296998889539, 3641.934985938746, 3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3312020329340235, 'mean_inference_ms': 9.448447273186213, 'mean_action_processing_ms': 0.20305266110793263, 'mean_env_wait_ms': 2.3303732497461755, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.00799870491027832, 'StateBufferConnector_ms': 0.009000539779663086, 'ViewRequirementAgentConnector_ms': 0.1260242462158203}, 'num_episodes': 0, 'episode_return_max': 3758.747644398931, 'episode_return_min': 245.296998889539, 'episode_return_mean': 3029.1626224506854, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1684000, 'num_agent_steps_trained': 1684000, 'num_env_steps_sampled': 1684000, 'num_env_steps_trained': 1684000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 404.94667236936493, 'num_env_steps_trained_throughput_per_sec': 404.94667236936493, 'timesteps_total': 1684000, 'num_env_steps_sampled_lifetime': 1684000, 'num_agent_steps_sampled_lifetime': 1684000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 1684000, 'timers': {'training_iteration_time_ms': 10064.826, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10064.826, 'sample_time_ms': 4341.117, 'load_time_ms': 17.914, 'load_throughput': 223285.665, 'learn_time_ms': 5680.881, 'learn_throughput': 704.116, 'synch_weights_time_ms': 24.516, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 184062.132, 'evaluation_iteration_throughput': 300.575}, 'counters': {'num_env_steps_sampled': 1684000, 'num_env_steps_trained': 1684000, 'num_agent_steps_sampled': 1684000, 'num_agent_steps_trained': 1684000, 'num_env_steps_sampled_for_evaluation_this_iter': 51306}, 'done': False, 'training_iteration': 421, 'trial_id': 'default', 'date': '2024-10-03_13-15-46', 'timestamp': 1727928946, 'time_this_iter_s': 9.886847496032715, 'time_total_s': 5003.026691198349, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 5003.026691198349, 'iterations_since_restore': 421, 'perf': {'cpu_util_percent': 14.564285714285715, 'ram_util_percent': 40.2}})\n",
      "421th iteration done\n",
      "422th iteration done\n",
      "423th iteration done\n",
      "424th iteration done\n",
      "425th iteration done\n",
      "426th iteration done\n",
      "427th iteration done\n",
      "428th iteration done\n",
      "429th iteration done\n",
      "430th iteration done\n",
      "431th iteration done\n",
      "432th iteration done\n",
      "433th iteration done\n",
      "434th iteration done\n",
      "435th iteration done\n",
      "436th iteration done\n",
      "437th iteration done\n",
      "438th iteration done\n",
      "439th iteration done\n",
      "440th iteration done\n",
      "441th iteration done\n",
      "442th iteration done\n",
      "443th iteration done\n",
      "444th iteration done\n",
      "445th iteration done\n",
      "446th iteration done\n",
      "447th iteration done\n",
      "448th iteration done\n",
      "449th iteration done\n",
      "450th iteration done\n",
      "451th iteration done\n",
      "452th iteration done\n",
      "453th iteration done\n",
      "454th iteration done\n",
      "455th iteration done\n",
      "456th iteration done\n",
      "457th iteration done\n",
      "458th iteration done\n",
      "459th iteration done\n",
      "460th iteration done\n",
      "461th iteration done\n",
      "462th iteration done\n",
      "463th iteration done\n",
      "464th iteration done\n",
      "465th iteration done\n",
      "466th iteration done\n",
      "467th iteration done\n",
      "468th iteration done\n",
      "469th iteration done\n",
      "470th iteration done\n",
      "471th iteration done\n",
      "472th iteration done\n",
      "473th iteration done\n",
      "474th iteration done\n",
      "475th iteration done\n",
      "476th iteration done\n",
      "477th iteration done\n",
      "478th iteration done\n",
      "479th iteration done\n",
      "480th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_8), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.060663900115797594, 'policy_loss': -0.2208932115446015, 'vf_loss': 0.25781903281026597, 'vf_explained_var': 0.7783181317390934, 'kl': 0.015630009805349347, 'entropy': 18.331433462327528, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 446865.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 1924000, 'num_env_steps_trained': 1924000, 'num_agent_steps_sampled': 1924000, 'num_agent_steps_trained': 1924000, 'num_env_steps_sampled_for_evaluation_this_iter': 51306}, 'env_runners': {'episode_reward_max': 4047.948808622243, 'episode_reward_min': -19.193895500462396, 'episode_reward_mean': 3361.9504628028994, 'episode_len_mean': 5532.32, 'episode_media': {}, 'episodes_timesteps_total': 553232, 'policy_reward_min': {'default_policy': -19.193895500462396}, 'policy_reward_max': {'default_policy': 4047.948808622243}, 'policy_reward_mean': {'default_policy': 3361.9504628028994}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836, 3419.4718338032226, 3488.42408948537, 3397.7395328680027, 3438.711343047009, 3492.399690000689, 3472.1414265082285, 3445.67742418823, 3453.578067375246, 3485.371416625112, 3539.330449526441, 3429.5453526379533, 3526.6272183477945, 2601.96825309159, 3552.586447569259, 3567.6700802698756, 2119.05966490865, 741.2023133784328, 3534.1148876462644, 3531.441591209536, 961.3386467140936, 3629.0155658084823, 3526.521658535561, 3592.7056045543554, 3620.384381642225, 3583.5305382236998, 3588.6432759196027, 3669.384414719916, 3573.667623684291, 991.8503099612209, 3640.003683291995, 245.296998889539, 3641.934985938746, 3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931, 3719.1574903756846, 3684.614623787271, 3641.862817528497, 3710.0847479885338, 3783.941812664352, 3792.1597570079452, 2610.8661242347234, 3780.765162284362, 3735.4924725463075, 3696.0437164057917, 3789.939437518101, 3804.2581386472766, 3822.860446175614, 3838.2688148577286, 3811.6323332284524, 3790.271925690735, 323.8301406170852, 3859.2722918488944, 3789.166154432031, 3887.1571147810837, 3828.6278746632406, 3754.6081413002503, 3832.1623905253937, -19.193895500462396, 3851.320122648526, 3811.5658319236054, 3820.6974304125715, 2818.8018685627294, 3871.277175809642, 3906.990939332921, 3895.2952152175644, 3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 3079, 6000, 6000, 6000, 6000, 3046, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4759, 6000, 6000, 3645, 1365, 6000, 6000, 1681, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1687, 6000, 474, 6000, 6000, 6000, 6000, 6000, 1541, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4210, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 658, 6000, 6000, 6000, 6000, 6000, 6000, 44, 6000, 6000, 6000, 5043, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [3316.6139500443337, 3360.4863372399705, 3339.5423325851534, 3258.7719765386955, 3317.689472617404, 1661.5621026435813, 3352.0184878829746, 3086.905027801986, 3386.526850755423, 3370.4707646209035, 1700.293996105033, 3340.9969708831677, 3402.3698536895836, 3419.4718338032226, 3488.42408948537, 3397.7395328680027, 3438.711343047009, 3492.399690000689, 3472.1414265082285, 3445.67742418823, 3453.578067375246, 3485.371416625112, 3539.330449526441, 3429.5453526379533, 3526.6272183477945, 2601.96825309159, 3552.586447569259, 3567.6700802698756, 2119.05966490865, 741.2023133784328, 3534.1148876462644, 3531.441591209536, 961.3386467140936, 3629.0155658084823, 3526.521658535561, 3592.7056045543554, 3620.384381642225, 3583.5305382236998, 3588.6432759196027, 3669.384414719916, 3573.667623684291, 991.8503099612209, 3640.003683291995, 245.296998889539, 3641.934985938746, 3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931, 3719.1574903756846, 3684.614623787271, 3641.862817528497, 3710.0847479885338, 3783.941812664352, 3792.1597570079452, 2610.8661242347234, 3780.765162284362, 3735.4924725463075, 3696.0437164057917, 3789.939437518101, 3804.2581386472766, 3822.860446175614, 3838.2688148577286, 3811.6323332284524, 3790.271925690735, 323.8301406170852, 3859.2722918488944, 3789.166154432031, 3887.1571147810837, 3828.6278746632406, 3754.6081413002503, 3832.1623905253937, -19.193895500462396, 3851.320122648526, 3811.5658319236054, 3820.6974304125715, 2818.8018685627294, 3871.277175809642, 3906.990939332921, 3895.2952152175644, 3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33128186199655935, 'mean_inference_ms': 9.448541398714251, 'mean_action_processing_ms': 0.20294402177308993, 'mean_env_wait_ms': 2.3292951513252804, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.004878520965576172, 'StateBufferConnector_ms': 0.00599980354309082, 'ViewRequirementAgentConnector_ms': 0.11698389053344727}, 'num_episodes': 1, 'episode_return_max': 4047.948808622243, 'episode_return_min': -19.193895500462396, 'episode_return_mean': 3361.9504628028994, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 1924000, 'num_agent_steps_trained': 1924000, 'num_env_steps_sampled': 1924000, 'num_env_steps_trained': 1924000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 398.2067941934189, 'num_env_steps_trained_throughput_per_sec': 398.2067941934189, 'timesteps_total': 1924000, 'num_env_steps_sampled_lifetime': 1924000, 'num_agent_steps_sampled_lifetime': 1924000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 1924000, 'timers': {'training_iteration_time_ms': 9989.445, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 9989.345, 'sample_time_ms': 4333.252, 'load_time_ms': 18.058, 'load_throughput': 221507.425, 'learn_time_ms': 5612.188, 'learn_throughput': 712.734, 'synch_weights_time_ms': 25.547, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 184062.132, 'evaluation_iteration_throughput': 300.575}, 'counters': {'num_env_steps_sampled': 1924000, 'num_env_steps_trained': 1924000, 'num_agent_steps_sampled': 1924000, 'num_agent_steps_trained': 1924000, 'num_env_steps_sampled_for_evaluation_this_iter': 51306}, 'done': False, 'training_iteration': 481, 'trial_id': 'default', 'date': '2024-10-03_13-25-50', 'timestamp': 1727929550, 'time_this_iter_s': 10.05903434753418, 'time_total_s': 5606.109448432922, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 5606.109448432922, 'iterations_since_restore': 481, 'perf': {'cpu_util_percent': 14.42666666666667, 'ram_util_percent': 40.29333333333333}})\n",
      "481th iteration done\n",
      "482th iteration done\n",
      "483th iteration done\n",
      "484th iteration done\n",
      "485th iteration done\n",
      "486th iteration done\n",
      "487th iteration done\n",
      "488th iteration done\n",
      "489th iteration done\n",
      "490th iteration done\n",
      "491th iteration done\n",
      "492th iteration done\n",
      "493th iteration done\n",
      "494th iteration done\n",
      "495th iteration done\n",
      "496th iteration done\n",
      "497th iteration done\n",
      "498th iteration done\n",
      "499th iteration done\n",
      "500th iteration done\n",
      "501th iteration done\n",
      "502th iteration done\n",
      "503th iteration done\n",
      "504th iteration done\n",
      "505th iteration done\n",
      "506th iteration done\n",
      "507th iteration done\n",
      "508th iteration done\n",
      "509th iteration done\n",
      "510th iteration done\n",
      "511th iteration done\n",
      "512th iteration done\n",
      "513th iteration done\n",
      "514th iteration done\n",
      "515th iteration done\n",
      "516th iteration done\n",
      "517th iteration done\n",
      "518th iteration done\n",
      "519th iteration done\n",
      "520th iteration done\n",
      "521th iteration done\n",
      "522th iteration done\n",
      "523th iteration done\n",
      "524th iteration done\n",
      "525th iteration done\n",
      "526th iteration done\n",
      "527th iteration done\n",
      "528th iteration done\n",
      "529th iteration done\n",
      "530th iteration done\n",
      "531th iteration done\n",
      "532th iteration done\n",
      "533th iteration done\n",
      "534th iteration done\n",
      "535th iteration done\n",
      "536th iteration done\n",
      "537th iteration done\n",
      "538th iteration done\n",
      "539th iteration done\n",
      "540th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_9), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.6145813274027039, 'policy_loss': -0.154760942287663, 'vf_loss': 0.750847325141626, 'vf_explained_var': 0.7309858367007266, 'kl': 0.012177748719066937, 'entropy': 18.189251961246615, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 502665.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 2164000, 'num_env_steps_trained': 2164000, 'num_agent_steps_sampled': 2164000, 'num_agent_steps_trained': 2164000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'env_runners': {'episode_reward_max': 4288.667645766333, 'episode_reward_min': -169.3007523198567, 'episode_reward_mean': 3556.3838116453057, 'episode_len_mean': 5471.17, 'episode_media': {}, 'episodes_timesteps_total': 547117, 'policy_reward_min': {'default_policy': -169.3007523198567}, 'policy_reward_max': {'default_policy': 4288.667645766333}, 'policy_reward_mean': {'default_policy': 3556.3838116453057}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931, 3719.1574903756846, 3684.614623787271, 3641.862817528497, 3710.0847479885338, 3783.941812664352, 3792.1597570079452, 2610.8661242347234, 3780.765162284362, 3735.4924725463075, 3696.0437164057917, 3789.939437518101, 3804.2581386472766, 3822.860446175614, 3838.2688148577286, 3811.6323332284524, 3790.271925690735, 323.8301406170852, 3859.2722918488944, 3789.166154432031, 3887.1571147810837, 3828.6278746632406, 3754.6081413002503, 3832.1623905253937, -19.193895500462396, 3851.320122648526, 3811.5658319236054, 3820.6974304125715, 2818.8018685627294, 3871.277175809642, 3906.990939332921, 3895.2952152175644, 3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764, 4048.4483098119877, 3991.7968804237958, 3952.443971378999, 3962.4961012601743, 1733.694486851668, 4085.8198288029644, 4020.2343641557, 4021.536872146977, 1807.584580171474, 419.86593398066503, 4047.6882324678113, 4036.50578047744, 4063.3529179191737, 4008.6406616772265, 586.3127193494341, 4057.7566893106036, 4052.385408611917, 4044.1012941072504, 4068.0042853698174, 4015.0470212839823, 4133.259811537628, 4159.160116753292, 4100.751202909297, 4099.547578464755, 4104.812848874607, 4065.492508715154, 4077.318418400502, -169.3007523198567, 4108.755671582819, 4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646], 'episode_lengths': [6000, 6000, 6000, 6000, 1541, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4210, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 658, 6000, 6000, 6000, 6000, 6000, 6000, 44, 6000, 6000, 6000, 5043, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2883, 6000, 6000, 6000, 3208, 647, 6000, 6000, 6000, 6000, 1298, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 364, 6000, 6000, 6000, 6000, 6000, 3022, 158, 6000, 4547, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3494], 'policy_default_policy_reward': [3686.945638038569, 3645.2118860155356, 3625.919713021048, 3649.856051203833, 720.6222402984735, 3660.076706061627, 3702.239823445604, 3634.0674954653045, 3651.374033684587, 3707.3906740060597, 3758.747644398931, 3719.1574903756846, 3684.614623787271, 3641.862817528497, 3710.0847479885338, 3783.941812664352, 3792.1597570079452, 2610.8661242347234, 3780.765162284362, 3735.4924725463075, 3696.0437164057917, 3789.939437518101, 3804.2581386472766, 3822.860446175614, 3838.2688148577286, 3811.6323332284524, 3790.271925690735, 323.8301406170852, 3859.2722918488944, 3789.166154432031, 3887.1571147810837, 3828.6278746632406, 3754.6081413002503, 3832.1623905253937, -19.193895500462396, 3851.320122648526, 3811.5658319236054, 3820.6974304125715, 2818.8018685627294, 3871.277175809642, 3906.990939332921, 3895.2952152175644, 3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764, 4048.4483098119877, 3991.7968804237958, 3952.443971378999, 3962.4961012601743, 1733.694486851668, 4085.8198288029644, 4020.2343641557, 4021.536872146977, 1807.584580171474, 419.86593398066503, 4047.6882324678113, 4036.50578047744, 4063.3529179191737, 4008.6406616772265, 586.3127193494341, 4057.7566893106036, 4052.385408611917, 4044.1012941072504, 4068.0042853698174, 4015.0470212839823, 4133.259811537628, 4159.160116753292, 4100.751202909297, 4099.547578464755, 4104.812848874607, 4065.492508715154, 4077.318418400502, -169.3007523198567, 4108.755671582819, 4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3313060224229127, 'mean_inference_ms': 9.449758141743441, 'mean_action_processing_ms': 0.20289290058149878, 'mean_env_wait_ms': 2.3298534561258437, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.009323835372924805, 'StateBufferConnector_ms': 0.003998517990112305, 'ViewRequirementAgentConnector_ms': 0.11680912971496582}, 'num_episodes': 1, 'episode_return_max': 4288.667645766333, 'episode_return_min': -169.3007523198567, 'episode_return_mean': 3556.3838116453057, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2164000, 'num_agent_steps_trained': 2164000, 'num_env_steps_sampled': 2164000, 'num_env_steps_trained': 2164000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 401.04637405630297, 'num_env_steps_trained_throughput_per_sec': 401.04637405630297, 'timesteps_total': 2164000, 'num_env_steps_sampled_lifetime': 2164000, 'num_agent_steps_sampled_lifetime': 2164000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 2164000, 'timers': {'training_iteration_time_ms': 10011.168, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10011.068, 'sample_time_ms': 4362.163, 'load_time_ms': 18.985, 'load_throughput': 210691.492, 'learn_time_ms': 5604.445, 'learn_throughput': 713.719, 'synch_weights_time_ms': 24.876, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 186421.956, 'evaluation_iteration_throughput': 301.786}, 'counters': {'num_env_steps_sampled': 2164000, 'num_env_steps_trained': 2164000, 'num_agent_steps_sampled': 2164000, 'num_agent_steps_trained': 2164000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'done': False, 'training_iteration': 541, 'trial_id': 'default', 'date': '2024-10-03_13-39-07', 'timestamp': 1727930347, 'time_this_iter_s': 9.985909461975098, 'time_total_s': 6401.8947768211365, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 6401.8947768211365, 'iterations_since_restore': 541, 'perf': {'cpu_util_percent': 14.47857142857143, 'ram_util_percent': 40.278571428571425}})\n",
      "541th iteration done\n",
      "542th iteration done\n",
      "543th iteration done\n",
      "544th iteration done\n",
      "545th iteration done\n",
      "546th iteration done\n",
      "547th iteration done\n",
      "548th iteration done\n",
      "549th iteration done\n",
      "550th iteration done\n",
      "551th iteration done\n",
      "552th iteration done\n",
      "553th iteration done\n",
      "554th iteration done\n",
      "555th iteration done\n",
      "556th iteration done\n",
      "557th iteration done\n",
      "558th iteration done\n",
      "559th iteration done\n",
      "560th iteration done\n",
      "561th iteration done\n",
      "562th iteration done\n",
      "563th iteration done\n",
      "564th iteration done\n",
      "565th iteration done\n",
      "566th iteration done\n",
      "567th iteration done\n",
      "568th iteration done\n",
      "569th iteration done\n",
      "570th iteration done\n",
      "571th iteration done\n",
      "572th iteration done\n",
      "573th iteration done\n",
      "574th iteration done\n",
      "575th iteration done\n",
      "576th iteration done\n",
      "577th iteration done\n",
      "578th iteration done\n",
      "579th iteration done\n",
      "580th iteration done\n",
      "581th iteration done\n",
      "582th iteration done\n",
      "583th iteration done\n",
      "584th iteration done\n",
      "585th iteration done\n",
      "586th iteration done\n",
      "587th iteration done\n",
      "588th iteration done\n",
      "589th iteration done\n",
      "590th iteration done\n",
      "591th iteration done\n",
      "592th iteration done\n",
      "593th iteration done\n",
      "594th iteration done\n",
      "595th iteration done\n",
      "596th iteration done\n",
      "597th iteration done\n",
      "598th iteration done\n",
      "599th iteration done\n",
      "600th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_10), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.7551810022894173, 'policy_loss': -0.15383711142405387, 'vf_loss': 0.8896024676925448, 'vf_explained_var': 0.7237625901417065, 'kl': 0.012783967553813575, 'entropy': 17.97576190579322, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 558465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 2404000, 'num_env_steps_trained': 2404000, 'num_agent_steps_sampled': 2404000, 'num_agent_steps_trained': 2404000, 'num_env_steps_sampled_for_evaluation_this_iter': 59045}, 'env_runners': {'episode_reward_max': 4434.543512235934, 'episode_reward_min': -169.3007523198567, 'episode_reward_mean': 3848.0983981633194, 'episode_len_mean': 5584.17, 'episode_media': {}, 'episodes_timesteps_total': 558417, 'policy_reward_min': {'default_policy': -169.3007523198567}, 'policy_reward_max': {'default_policy': 4434.543512235934}, 'policy_reward_mean': {'default_policy': 3848.0983981633194}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764, 4048.4483098119877, 3991.7968804237958, 3952.443971378999, 3962.4961012601743, 1733.694486851668, 4085.8198288029644, 4020.2343641557, 4021.536872146977, 1807.584580171474, 419.86593398066503, 4047.6882324678113, 4036.50578047744, 4063.3529179191737, 4008.6406616772265, 586.3127193494341, 4057.7566893106036, 4052.385408611917, 4044.1012941072504, 4068.0042853698174, 4015.0470212839823, 4133.259811537628, 4159.160116753292, 4100.751202909297, 4099.547578464755, 4104.812848874607, 4065.492508715154, 4077.318418400502, -169.3007523198567, 4108.755671582819, 4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646, 4258.267616961934, 658.8427259994808, 4311.283820667009, 4195.989598410385, 4265.137002671635, 4201.462925660303, 4278.343173947589, 4308.797947982331, 4232.594960846367, 4259.336966929276, 4242.860190884544, 4332.981376530468, 4274.213862618594, 4255.02488516751, 4307.417756700446, 4272.731858010923, 4271.389609025369, 4326.484193398022, 4286.235185072161, 4227.629519222455, 4315.849258645909, 4302.615526147406, 4309.162622686809, 4336.518118521446, 2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2883, 6000, 6000, 6000, 3208, 647, 6000, 6000, 6000, 6000, 1298, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 364, 6000, 6000, 6000, 6000, 6000, 3022, 158, 6000, 4547, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3494, 6000, 1444, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4150, 6000, 6000, 6000, 6000, 5202, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [3843.5988481744475, 3964.601385566713, 3950.961560765045, 3913.613179882535, 3901.638603946863, 3967.881595949897, 3941.4877242218367, 3972.775976823199, 3654.465014871311, 4017.7404539929726, 4047.948808622243, 3948.731375450239, 3987.764335087764, 4048.4483098119877, 3991.7968804237958, 3952.443971378999, 3962.4961012601743, 1733.694486851668, 4085.8198288029644, 4020.2343641557, 4021.536872146977, 1807.584580171474, 419.86593398066503, 4047.6882324678113, 4036.50578047744, 4063.3529179191737, 4008.6406616772265, 586.3127193494341, 4057.7566893106036, 4052.385408611917, 4044.1012941072504, 4068.0042853698174, 4015.0470212839823, 4133.259811537628, 4159.160116753292, 4100.751202909297, 4099.547578464755, 4104.812848874607, 4065.492508715154, 4077.318418400502, -169.3007523198567, 4108.755671582819, 4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646, 4258.267616961934, 658.8427259994808, 4311.283820667009, 4195.989598410385, 4265.137002671635, 4201.462925660303, 4278.343173947589, 4308.797947982331, 4232.594960846367, 4259.336966929276, 4242.860190884544, 4332.981376530468, 4274.213862618594, 4255.02488516751, 4307.417756700446, 4272.731858010923, 4271.389609025369, 4326.484193398022, 4286.235185072161, 4227.629519222455, 4315.849258645909, 4302.615526147406, 4309.162622686809, 4336.518118521446, 2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3313750260908247, 'mean_inference_ms': 9.45344107322759, 'mean_action_processing_ms': 0.2028528557509177, 'mean_env_wait_ms': 2.329368286722832, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.006445407867431641, 'StateBufferConnector_ms': 0.004000425338745117, 'ViewRequirementAgentConnector_ms': 0.12585973739624023}, 'num_episodes': 0, 'episode_return_max': 4434.543512235934, 'episode_return_min': -169.3007523198567, 'episode_return_mean': 3848.0983981633194, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2404000, 'num_agent_steps_trained': 2404000, 'num_env_steps_sampled': 2404000, 'num_env_steps_trained': 2404000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 407.47369561278623, 'num_env_steps_trained_throughput_per_sec': 407.47369561278623, 'timesteps_total': 2404000, 'num_env_steps_sampled_lifetime': 2404000, 'num_agent_steps_sampled_lifetime': 2404000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 2404000, 'timers': {'training_iteration_time_ms': 10281.742, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10281.742, 'sample_time_ms': 4361.331, 'load_time_ms': 19.824, 'load_throughput': 201771.215, 'learn_time_ms': 5875.885, 'learn_throughput': 680.749, 'synch_weights_time_ms': 24.102, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 187916.793, 'evaluation_iteration_throughput': 301.856}, 'counters': {'num_env_steps_sampled': 2404000, 'num_env_steps_trained': 2404000, 'num_agent_steps_sampled': 2404000, 'num_agent_steps_trained': 2404000, 'num_env_steps_sampled_for_evaluation_this_iter': 59045}, 'done': False, 'training_iteration': 601, 'trial_id': 'default', 'date': '2024-10-03_13-52-32', 'timestamp': 1727931152, 'time_this_iter_s': 9.82785964012146, 'time_total_s': 7205.879936695099, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 7205.879936695099, 'iterations_since_restore': 601, 'perf': {'cpu_util_percent': 15.47857142857143, 'ram_util_percent': 40.89999999999999}})\n",
      "601th iteration done\n",
      "602th iteration done\n",
      "603th iteration done\n",
      "604th iteration done\n",
      "605th iteration done\n",
      "606th iteration done\n",
      "607th iteration done\n",
      "608th iteration done\n",
      "609th iteration done\n",
      "610th iteration done\n",
      "611th iteration done\n",
      "612th iteration done\n",
      "613th iteration done\n",
      "614th iteration done\n",
      "615th iteration done\n",
      "616th iteration done\n",
      "617th iteration done\n",
      "618th iteration done\n",
      "619th iteration done\n",
      "620th iteration done\n",
      "621th iteration done\n",
      "622th iteration done\n",
      "623th iteration done\n",
      "624th iteration done\n",
      "625th iteration done\n",
      "626th iteration done\n",
      "627th iteration done\n",
      "628th iteration done\n",
      "629th iteration done\n",
      "630th iteration done\n",
      "631th iteration done\n",
      "632th iteration done\n",
      "633th iteration done\n",
      "634th iteration done\n",
      "635th iteration done\n",
      "636th iteration done\n",
      "637th iteration done\n",
      "638th iteration done\n",
      "639th iteration done\n",
      "640th iteration done\n",
      "641th iteration done\n",
      "642th iteration done\n",
      "643th iteration done\n",
      "644th iteration done\n",
      "645th iteration done\n",
      "646th iteration done\n",
      "647th iteration done\n",
      "648th iteration done\n",
      "649th iteration done\n",
      "650th iteration done\n",
      "651th iteration done\n",
      "652th iteration done\n",
      "653th iteration done\n",
      "654th iteration done\n",
      "655th iteration done\n",
      "656th iteration done\n",
      "657th iteration done\n",
      "658th iteration done\n",
      "659th iteration done\n",
      "660th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_11), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.019336191236331898, 'policy_loss': -0.22155952619048216, 'vf_loss': 0.21651291083390758, 'vf_explained_var': 0.8028275648111938, 'kl': 0.016054523185558018, 'entropy': 17.759867177983764, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 614265.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 2644000, 'num_env_steps_trained': 2644000, 'num_agent_steps_sampled': 2644000, 'num_agent_steps_trained': 2644000, 'num_env_steps_sampled_for_evaluation_this_iter': 59045}, 'env_runners': {'episode_reward_max': 4650.332880186317, 'episode_reward_min': -88.8774356861231, 'episode_reward_mean': 4072.0239646312043, 'episode_len_mean': 5663.53, 'episode_media': {}, 'episodes_timesteps_total': 566353, 'policy_reward_min': {'default_policy': -88.8774356861231}, 'policy_reward_max': {'default_policy': 4650.332880186317}, 'policy_reward_mean': {'default_policy': 4072.0239646312043}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646, 4258.267616961934, 658.8427259994808, 4311.283820667009, 4195.989598410385, 4265.137002671635, 4201.462925660303, 4278.343173947589, 4308.797947982331, 4232.594960846367, 4259.336966929276, 4242.860190884544, 4332.981376530468, 4274.213862618594, 4255.02488516751, 4307.417756700446, 4272.731858010923, 4271.389609025369, 4326.484193398022, 4286.235185072161, 4227.629519222455, 4315.849258645909, 4302.615526147406, 4309.162622686809, 4336.518118521446, 2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063, 4419.781134715175, 4362.858341492176, 4327.787317862656, 4384.4592307328485, 2996.2234696234073, 4386.719969823815, 4476.660905877315, 4503.036120802751, 3636.254717346548, 4447.081011880884, 4432.366521537128, 4505.997652130096, 1796.22899807371, 4496.371285025465, 4477.345978537567, 4406.249802152572, 4479.442303224999, 4522.254144159491, 4414.557308981102, 2673.861253172164, 4534.271090939423, 4504.804924417806, 4553.95092516561, 4025.7864057408024, 4524.811297633148, 3522.7297198157466, 4602.091789509125, 2971.537718588823, 4472.8608842623125, 4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886], 'episode_lengths': [6000, 6000, 6000, 6000, 3022, 158, 6000, 4547, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3494, 6000, 1444, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4150, 6000, 6000, 6000, 6000, 5202, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 5167, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2532, 6000, 6000, 6000, 6000, 6000, 6000, 3801, 6000, 6000, 6000, 6000, 6000, 5094, 6000, 4006, 6000, 6000, 6000, 6000, 5156, 6000, 6000, 6000, 6000, 2580, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [4175.241649696017, 4151.817604971023, 4135.60542494099, 4093.2080979788184, 1998.4858465408306, -88.8774356861231, 4072.1873769174285, 3024.4523964458645, 4190.427442373285, 4124.734760115995, 4115.65092750776, 4227.198272285127, 4193.425052856051, 4288.667645766333, 4246.507001027791, 2186.6759698050646, 4258.267616961934, 658.8427259994808, 4311.283820667009, 4195.989598410385, 4265.137002671635, 4201.462925660303, 4278.343173947589, 4308.797947982331, 4232.594960846367, 4259.336966929276, 4242.860190884544, 4332.981376530468, 4274.213862618594, 4255.02488516751, 4307.417756700446, 4272.731858010923, 4271.389609025369, 4326.484193398022, 4286.235185072161, 4227.629519222455, 4315.849258645909, 4302.615526147406, 4309.162622686809, 4336.518118521446, 2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063, 4419.781134715175, 4362.858341492176, 4327.787317862656, 4384.4592307328485, 2996.2234696234073, 4386.719969823815, 4476.660905877315, 4503.036120802751, 3636.254717346548, 4447.081011880884, 4432.366521537128, 4505.997652130096, 1796.22899807371, 4496.371285025465, 4477.345978537567, 4406.249802152572, 4479.442303224999, 4522.254144159491, 4414.557308981102, 2673.861253172164, 4534.271090939423, 4504.804924417806, 4553.95092516561, 4025.7864057408024, 4524.811297633148, 3522.7297198157466, 4602.091789509125, 2971.537718588823, 4472.8608842623125, 4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33153599121851884, 'mean_inference_ms': 9.452853875952764, 'mean_action_processing_ms': 0.20311995610351719, 'mean_env_wait_ms': 2.3322031880181515, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0033800601959228516, 'StateBufferConnector_ms': 0.0030012130737304688, 'ViewRequirementAgentConnector_ms': 0.14352130889892578}, 'num_episodes': 1, 'episode_return_max': 4650.332880186317, 'episode_return_min': -88.8774356861231, 'episode_return_mean': 4072.0239646312043, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2644000, 'num_agent_steps_trained': 2644000, 'num_env_steps_sampled': 2644000, 'num_env_steps_trained': 2644000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 389.90634094773094, 'num_env_steps_trained_throughput_per_sec': 389.90634094773094, 'timesteps_total': 2644000, 'num_env_steps_sampled_lifetime': 2644000, 'num_agent_steps_sampled_lifetime': 2644000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 2644000, 'timers': {'training_iteration_time_ms': 10192.28, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10192.28, 'sample_time_ms': 4318.455, 'load_time_ms': 20.253, 'load_throughput': 197499.603, 'learn_time_ms': 5827.996, 'learn_throughput': 686.342, 'synch_weights_time_ms': 25.525, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 187916.793, 'evaluation_iteration_throughput': 301.856}, 'counters': {'num_env_steps_sampled': 2644000, 'num_env_steps_trained': 2644000, 'num_agent_steps_sampled': 2644000, 'num_agent_steps_trained': 2644000, 'num_env_steps_sampled_for_evaluation_this_iter': 59045}, 'done': False, 'training_iteration': 661, 'trial_id': 'default', 'date': '2024-10-03_14-02-47', 'timestamp': 1727931767, 'time_this_iter_s': 10.27481484413147, 'time_total_s': 7819.672018289566, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 7819.672018289566, 'iterations_since_restore': 661, 'perf': {'cpu_util_percent': 16.692857142857143, 'ram_util_percent': 42.71428571428572}})\n",
      "661th iteration done\n",
      "662th iteration done\n",
      "663th iteration done\n",
      "664th iteration done\n",
      "665th iteration done\n",
      "666th iteration done\n",
      "667th iteration done\n",
      "668th iteration done\n",
      "669th iteration done\n",
      "670th iteration done\n",
      "671th iteration done\n",
      "672th iteration done\n",
      "673th iteration done\n",
      "674th iteration done\n",
      "675th iteration done\n",
      "676th iteration done\n",
      "677th iteration done\n",
      "678th iteration done\n",
      "679th iteration done\n",
      "680th iteration done\n",
      "681th iteration done\n",
      "682th iteration done\n",
      "683th iteration done\n",
      "684th iteration done\n",
      "685th iteration done\n",
      "686th iteration done\n",
      "687th iteration done\n",
      "688th iteration done\n",
      "689th iteration done\n",
      "690th iteration done\n",
      "691th iteration done\n",
      "692th iteration done\n",
      "693th iteration done\n",
      "694th iteration done\n",
      "695th iteration done\n",
      "696th iteration done\n",
      "697th iteration done\n",
      "698th iteration done\n",
      "699th iteration done\n",
      "700th iteration done\n",
      "701th iteration done\n",
      "702th iteration done\n",
      "703th iteration done\n",
      "704th iteration done\n",
      "705th iteration done\n",
      "706th iteration done\n",
      "707th iteration done\n",
      "708th iteration done\n",
      "709th iteration done\n",
      "710th iteration done\n",
      "711th iteration done\n",
      "712th iteration done\n",
      "713th iteration done\n",
      "714th iteration done\n",
      "715th iteration done\n",
      "716th iteration done\n",
      "717th iteration done\n",
      "718th iteration done\n",
      "719th iteration done\n",
      "720th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_12), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.036423016281458, 'policy_loss': -0.22095329834809227, 'vf_loss': 0.23279830142683916, 'vf_explained_var': 0.7854532630853756, 'kl': 0.01618305384137638, 'entropy': 17.59082311814831, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 670065.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 2884000, 'num_env_steps_trained': 2884000, 'num_agent_steps_sampled': 2884000, 'num_agent_steps_trained': 2884000, 'num_env_steps_sampled_for_evaluation_this_iter': 55420}, 'env_runners': {'episode_reward_max': 4796.702375053568, 'episode_reward_min': 1481.0041859536302, 'episode_reward_mean': 4277.7062895891495, 'episode_len_mean': 5706.47, 'episode_media': {}, 'episodes_timesteps_total': 570647, 'policy_reward_min': {'default_policy': 1481.0041859536302}, 'policy_reward_max': {'default_policy': 4796.702375053568}, 'policy_reward_mean': {'default_policy': 4277.7062895891495}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063, 4419.781134715175, 4362.858341492176, 4327.787317862656, 4384.4592307328485, 2996.2234696234073, 4386.719969823815, 4476.660905877315, 4503.036120802751, 3636.254717346548, 4447.081011880884, 4432.366521537128, 4505.997652130096, 1796.22899807371, 4496.371285025465, 4477.345978537567, 4406.249802152572, 4479.442303224999, 4522.254144159491, 4414.557308981102, 2673.861253172164, 4534.271090939423, 4504.804924417806, 4553.95092516561, 4025.7864057408024, 4524.811297633148, 3522.7297198157466, 4602.091789509125, 2971.537718588823, 4472.8608842623125, 4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886, 4630.228135514708, 4611.79624503458, 4638.061541066559, 4577.107715015397, 4626.441508703609, 4618.295433945646, 2960.706995355383, 4651.882304243654, 4605.207324869251, 4703.0274341459135, 4642.071331576637, 4672.073817421547, 4688.345479567506, 4651.281188135942, 3563.8300608178934, 4793.792715841423, 4675.514771816945, 4663.64482258195, 4699.554321142262, 4720.905330858491, 4720.018904293574, 4692.921502738538, 4655.829600961911, 4698.8557164124095, 2059.336812839157, 4689.646255165736, 4730.858054182014, 4710.779551335259, 4778.85333833477, 4773.39156348061, 2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127], 'episode_lengths': [4150, 6000, 6000, 6000, 6000, 5202, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 5167, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2532, 6000, 6000, 6000, 6000, 6000, 6000, 3801, 6000, 6000, 6000, 6000, 6000, 5094, 6000, 4006, 6000, 6000, 6000, 6000, 5156, 6000, 6000, 6000, 6000, 2580, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3880, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4981, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3207, 6000, 6000, 6000, 6000, 6000, 2956, 6000, 6000, 6000, 6000, 6000, 6000, 1935, 6000, 6000], 'policy_default_policy_reward': [2165.9282720973265, 4318.27489772775, 4378.206515888066, 4347.80873608544, 4402.20505189895, 3593.763375386767, 4394.7793117680185, 4367.956515706551, 4391.542604469102, 4399.810734514463, 4377.972443753867, 4409.730233743845, 4378.96120819156, 4411.607740748049, 4268.70496271613, 4370.950970009037, 4434.543512235934, 4413.791385308063, 4419.781134715175, 4362.858341492176, 4327.787317862656, 4384.4592307328485, 2996.2234696234073, 4386.719969823815, 4476.660905877315, 4503.036120802751, 3636.254717346548, 4447.081011880884, 4432.366521537128, 4505.997652130096, 1796.22899807371, 4496.371285025465, 4477.345978537567, 4406.249802152572, 4479.442303224999, 4522.254144159491, 4414.557308981102, 2673.861253172164, 4534.271090939423, 4504.804924417806, 4553.95092516561, 4025.7864057408024, 4524.811297633148, 3522.7297198157466, 4602.091789509125, 2971.537718588823, 4472.8608842623125, 4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886, 4630.228135514708, 4611.79624503458, 4638.061541066559, 4577.107715015397, 4626.441508703609, 4618.295433945646, 2960.706995355383, 4651.882304243654, 4605.207324869251, 4703.0274341459135, 4642.071331576637, 4672.073817421547, 4688.345479567506, 4651.281188135942, 3563.8300608178934, 4793.792715841423, 4675.514771816945, 4663.64482258195, 4699.554321142262, 4720.905330858491, 4720.018904293574, 4692.921502738538, 4655.829600961911, 4698.8557164124095, 2059.336812839157, 4689.646255165736, 4730.858054182014, 4710.779551335259, 4778.85333833477, 4773.39156348061, 2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33181906353364843, 'mean_inference_ms': 9.447843291788658, 'mean_action_processing_ms': 0.20302654758854213, 'mean_env_wait_ms': 2.3340030281044757, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.002002239227294922, 'StateBufferConnector_ms': 0.024448394775390625, 'ViewRequirementAgentConnector_ms': 0.12228965759277344}, 'num_episodes': 0, 'episode_return_max': 4796.702375053568, 'episode_return_min': 1481.0041859536302, 'episode_return_mean': 4277.7062895891495, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 2884000, 'num_agent_steps_trained': 2884000, 'num_env_steps_sampled': 2884000, 'num_env_steps_trained': 2884000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 390.48468773706736, 'num_env_steps_trained_throughput_per_sec': 390.48468773706736, 'timesteps_total': 2884000, 'num_env_steps_sampled_lifetime': 2884000, 'num_agent_steps_sampled_lifetime': 2884000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 2884000, 'timers': {'training_iteration_time_ms': 10074.442, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10072.843, 'sample_time_ms': 4278.051, 'load_time_ms': 20.311, 'load_throughput': 196936.715, 'learn_time_ms': 5750.225, 'learn_throughput': 695.625, 'synch_weights_time_ms': 24.096, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 187365.313, 'evaluation_iteration_throughput': 301.75}, 'counters': {'num_env_steps_sampled': 2884000, 'num_env_steps_trained': 2884000, 'num_agent_steps_sampled': 2884000, 'num_agent_steps_trained': 2884000, 'num_env_steps_sampled_for_evaluation_this_iter': 55420}, 'done': False, 'training_iteration': 721, 'trial_id': 'default', 'date': '2024-10-03_14-15-59', 'timestamp': 1727932559, 'time_this_iter_s': 10.243679523468018, 'time_total_s': 8611.230510473251, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 8611.230510473251, 'iterations_since_restore': 721, 'perf': {'cpu_util_percent': 16.359999999999996, 'ram_util_percent': 42.50666666666667}})\n",
      "721th iteration done\n",
      "722th iteration done\n",
      "723th iteration done\n",
      "724th iteration done\n",
      "725th iteration done\n",
      "726th iteration done\n",
      "727th iteration done\n",
      "728th iteration done\n",
      "729th iteration done\n",
      "730th iteration done\n",
      "731th iteration done\n",
      "732th iteration done\n",
      "733th iteration done\n",
      "734th iteration done\n",
      "735th iteration done\n",
      "736th iteration done\n",
      "737th iteration done\n",
      "738th iteration done\n",
      "739th iteration done\n",
      "740th iteration done\n",
      "741th iteration done\n",
      "742th iteration done\n",
      "743th iteration done\n",
      "744th iteration done\n",
      "745th iteration done\n",
      "746th iteration done\n",
      "747th iteration done\n",
      "748th iteration done\n",
      "749th iteration done\n",
      "750th iteration done\n",
      "751th iteration done\n",
      "752th iteration done\n",
      "753th iteration done\n",
      "754th iteration done\n",
      "755th iteration done\n",
      "756th iteration done\n",
      "757th iteration done\n",
      "758th iteration done\n",
      "759th iteration done\n",
      "760th iteration done\n",
      "761th iteration done\n",
      "762th iteration done\n",
      "763th iteration done\n",
      "764th iteration done\n",
      "765th iteration done\n",
      "766th iteration done\n",
      "767th iteration done\n",
      "768th iteration done\n",
      "769th iteration done\n",
      "770th iteration done\n",
      "771th iteration done\n",
      "772th iteration done\n",
      "773th iteration done\n",
      "774th iteration done\n",
      "775th iteration done\n",
      "776th iteration done\n",
      "777th iteration done\n",
      "778th iteration done\n",
      "779th iteration done\n",
      "780th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_13), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': -0.009269434656266885, 'policy_loss': -0.21973943588554218, 'vf_loss': 0.18583238349638515, 'vf_explained_var': 0.8337357760757529, 'kl': 0.016222301069744184, 'entropy': 17.321446189060005, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 725865.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 3124000, 'num_env_steps_trained': 3124000, 'num_agent_steps_sampled': 3124000, 'num_agent_steps_trained': 3124000, 'num_env_steps_sampled_for_evaluation_this_iter': 55420}, 'env_runners': {'episode_reward_max': 5050.914537583858, 'episode_reward_min': -246.0965180999978, 'episode_reward_mean': 4348.084379407655, 'episode_len_mean': 5539.43, 'episode_media': {}, 'episodes_timesteps_total': 553943, 'policy_reward_min': {'default_policy': -246.0965180999978}, 'policy_reward_max': {'default_policy': 5050.914537583858}, 'policy_reward_mean': {'default_policy': 4348.084379407655}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886, 4630.228135514708, 4611.79624503458, 4638.061541066559, 4577.107715015397, 4626.441508703609, 4618.295433945646, 2960.706995355383, 4651.882304243654, 4605.207324869251, 4703.0274341459135, 4642.071331576637, 4672.073817421547, 4688.345479567506, 4651.281188135942, 3563.8300608178934, 4793.792715841423, 4675.514771816945, 4663.64482258195, 4699.554321142262, 4720.905330858491, 4720.018904293574, 4692.921502738538, 4655.829600961911, 4698.8557164124095, 2059.336812839157, 4689.646255165736, 4730.858054182014, 4710.779551335259, 4778.85333833477, 4773.39156348061, 2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127, 4776.091726808566, 4848.406428826201, 4762.670874756061, 4791.0388176311935, 4815.398374277046, 4820.140507673904, 4650.40140695139, 3367.6134009220877, 4814.820279507545, 4854.868332060217, 4853.12326762979, 4862.214981205873, 283.4193907769254, 4162.910370658065, 4910.41817316465, -246.0965180999978, 4771.614020373857, 4862.104708895221, 2122.9887819781293, 4797.616527369413, 4846.048771039612, 4816.401616164154, 4865.8861259078085, 4870.429228661692, 4925.089128543249, 4922.967304113227, -27.127783538517715, 4867.487390380842, 4909.301484294866, 4950.522749175783, 4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352], 'episode_lengths': [6000, 6000, 6000, 5156, 6000, 6000, 6000, 6000, 2580, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3880, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4981, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3207, 6000, 6000, 6000, 6000, 6000, 2956, 6000, 6000, 6000, 6000, 6000, 6000, 1935, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4631, 6000, 6000, 6000, 6000, 710, 5376, 6000, 323, 6000, 6000, 3423, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 46, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2386, 6000, 6000, 6000, 5420, 5707, 6000, 6000, 6000, 3226, 6000], 'policy_default_policy_reward': [4514.897879514303, 4533.138319608459, 4535.122124329893, 3334.7464904285653, 4512.288674759297, 4608.174447235098, 4563.535205751983, 4526.143719461464, 1885.7241243493684, 4650.332880186317, 4586.300687845839, 4575.5510758546825, 4524.941402070886, 4630.228135514708, 4611.79624503458, 4638.061541066559, 4577.107715015397, 4626.441508703609, 4618.295433945646, 2960.706995355383, 4651.882304243654, 4605.207324869251, 4703.0274341459135, 4642.071331576637, 4672.073817421547, 4688.345479567506, 4651.281188135942, 3563.8300608178934, 4793.792715841423, 4675.514771816945, 4663.64482258195, 4699.554321142262, 4720.905330858491, 4720.018904293574, 4692.921502738538, 4655.829600961911, 4698.8557164124095, 2059.336812839157, 4689.646255165736, 4730.858054182014, 4710.779551335259, 4778.85333833477, 4773.39156348061, 2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127, 4776.091726808566, 4848.406428826201, 4762.670874756061, 4791.0388176311935, 4815.398374277046, 4820.140507673904, 4650.40140695139, 3367.6134009220877, 4814.820279507545, 4854.868332060217, 4853.12326762979, 4862.214981205873, 283.4193907769254, 4162.910370658065, 4910.41817316465, -246.0965180999978, 4771.614020373857, 4862.104708895221, 2122.9887819781293, 4797.616527369413, 4846.048771039612, 4816.401616164154, 4865.8861259078085, 4870.429228661692, 4925.089128543249, 4922.967304113227, -27.127783538517715, 4867.487390380842, 4909.301484294866, 4950.522749175783, 4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3321749601369286, 'mean_inference_ms': 9.436587035727127, 'mean_action_processing_ms': 0.20264929746317217, 'mean_env_wait_ms': 2.3348126993048384, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0010001659393310547, 'StateBufferConnector_ms': 0.021447181701660156, 'ViewRequirementAgentConnector_ms': 0.16995501518249512}, 'num_episodes': 0, 'episode_return_max': 5050.914537583858, 'episode_return_min': -246.0965180999978, 'episode_return_mean': 4348.084379407655, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3124000, 'num_agent_steps_trained': 3124000, 'num_env_steps_sampled': 3124000, 'num_env_steps_trained': 3124000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 385.00714240211255, 'num_env_steps_trained_throughput_per_sec': 385.00714240211255, 'timesteps_total': 3124000, 'num_env_steps_sampled_lifetime': 3124000, 'num_agent_steps_sampled_lifetime': 3124000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 3124000, 'timers': {'training_iteration_time_ms': 10118.666, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10118.666, 'sample_time_ms': 4286.16, 'load_time_ms': 18.314, 'load_throughput': 218414.087, 'learn_time_ms': 5783.262, 'learn_throughput': 691.651, 'synch_weights_time_ms': 29.36, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 187365.313, 'evaluation_iteration_throughput': 301.75}, 'counters': {'num_env_steps_sampled': 3124000, 'num_env_steps_trained': 3124000, 'num_agent_steps_sampled': 3124000, 'num_agent_steps_trained': 3124000, 'num_env_steps_sampled_for_evaluation_this_iter': 55420}, 'done': False, 'training_iteration': 781, 'trial_id': 'default', 'date': '2024-10-03_14-26-08', 'timestamp': 1727933168, 'time_this_iter_s': 10.396891355514526, 'time_total_s': 9219.010983467102, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 9219.010983467102, 'iterations_since_restore': 781, 'perf': {'cpu_util_percent': 16.46, 'ram_util_percent': 42.513333333333335}})\n",
      "781th iteration done\n",
      "782th iteration done\n",
      "783th iteration done\n",
      "784th iteration done\n",
      "785th iteration done\n",
      "786th iteration done\n",
      "787th iteration done\n",
      "788th iteration done\n",
      "789th iteration done\n",
      "790th iteration done\n",
      "791th iteration done\n",
      "792th iteration done\n",
      "793th iteration done\n",
      "794th iteration done\n",
      "795th iteration done\n",
      "796th iteration done\n",
      "797th iteration done\n",
      "798th iteration done\n",
      "799th iteration done\n",
      "800th iteration done\n",
      "801th iteration done\n",
      "802th iteration done\n",
      "803th iteration done\n",
      "804th iteration done\n",
      "805th iteration done\n",
      "806th iteration done\n",
      "807th iteration done\n",
      "808th iteration done\n",
      "809th iteration done\n",
      "810th iteration done\n",
      "811th iteration done\n",
      "812th iteration done\n",
      "813th iteration done\n",
      "814th iteration done\n",
      "815th iteration done\n",
      "816th iteration done\n",
      "817th iteration done\n",
      "818th iteration done\n",
      "819th iteration done\n",
      "820th iteration done\n",
      "821th iteration done\n",
      "822th iteration done\n",
      "823th iteration done\n",
      "824th iteration done\n",
      "825th iteration done\n",
      "826th iteration done\n",
      "827th iteration done\n",
      "828th iteration done\n",
      "829th iteration done\n",
      "830th iteration done\n",
      "831th iteration done\n",
      "832th iteration done\n",
      "833th iteration done\n",
      "834th iteration done\n",
      "835th iteration done\n",
      "836th iteration done\n",
      "837th iteration done\n",
      "838th iteration done\n",
      "839th iteration done\n",
      "840th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_14), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.04579005550833479, 'policy_loss': -0.2188337400615696, 'vf_loss': 0.23917235877292584, 'vf_explained_var': 0.7967559685630183, 'kl': 0.016758147491047124, 'entropy': 17.148849206329675, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 781665.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 3364000, 'num_env_steps_trained': 3364000, 'num_agent_steps_sampled': 3364000, 'num_agent_steps_trained': 3364000, 'num_env_steps_sampled_for_evaluation_this_iter': 58429}, 'env_runners': {'episode_reward_max': 5250.786292316162, 'episode_reward_min': -246.0965180999978, 'episode_reward_mean': 4461.597686822179, 'episode_len_mean': 5441.06, 'episode_media': {}, 'episodes_timesteps_total': 544106, 'policy_reward_min': {'default_policy': -246.0965180999978}, 'policy_reward_max': {'default_policy': 5250.786292316162}, 'policy_reward_mean': {'default_policy': 4461.597686822179}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127, 4776.091726808566, 4848.406428826201, 4762.670874756061, 4791.0388176311935, 4815.398374277046, 4820.140507673904, 4650.40140695139, 3367.6134009220877, 4814.820279507545, 4854.868332060217, 4853.12326762979, 4862.214981205873, 283.4193907769254, 4162.910370658065, 4910.41817316465, -246.0965180999978, 4771.614020373857, 4862.104708895221, 2122.9887819781293, 4797.616527369413, 4846.048771039612, 4816.401616164154, 4865.8861259078085, 4870.429228661692, 4925.089128543249, 4922.967304113227, -27.127783538517715, 4867.487390380842, 4909.301484294866, 4950.522749175783, 4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352, 5054.302959899652, 5015.488354238216, 3454.6937923242813, 5020.134155117885, 5108.149808955259, 5001.5996099635595, 5065.007192807534, 5035.439375214214, 5040.083737384747, 5076.667879062623, 5086.728846763394, 2384.3744891048545, 5056.468811040934, 5083.5624937791445, 5044.65255767223, 5037.211122732358, 5126.571881781333, 5097.50846885606, 5113.855481732768, 5149.001388245534, 5142.087390260312, 5094.297334909063, 5170.664632073605, 5184.168501417416, 5228.157885181042, 5162.983569148966, 5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569], 'episode_lengths': [2956, 6000, 6000, 6000, 6000, 6000, 6000, 1935, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 4631, 6000, 6000, 6000, 6000, 710, 5376, 6000, 323, 6000, 6000, 3423, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 46, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2386, 6000, 6000, 6000, 5420, 5707, 6000, 6000, 6000, 3226, 6000, 6000, 6000, 4336, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2877, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 156, 6000, 6000, 6000, 6000, 6000, 6000, 2378, 220, 6000, 6000, 6000], 'policy_default_policy_reward': [2273.846146089112, 4791.455149886153, 4703.407585172106, 4796.702375053568, 4772.790002105522, 4719.069520259757, 4779.935172575007, 1481.0041859536302, 4776.9922343569815, 4735.349083194127, 4776.091726808566, 4848.406428826201, 4762.670874756061, 4791.0388176311935, 4815.398374277046, 4820.140507673904, 4650.40140695139, 3367.6134009220877, 4814.820279507545, 4854.868332060217, 4853.12326762979, 4862.214981205873, 283.4193907769254, 4162.910370658065, 4910.41817316465, -246.0965180999978, 4771.614020373857, 4862.104708895221, 2122.9887819781293, 4797.616527369413, 4846.048771039612, 4816.401616164154, 4865.8861259078085, 4870.429228661692, 4925.089128543249, 4922.967304113227, -27.127783538517715, 4867.487390380842, 4909.301484294866, 4950.522749175783, 4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352, 5054.302959899652, 5015.488354238216, 3454.6937923242813, 5020.134155117885, 5108.149808955259, 5001.5996099635595, 5065.007192807534, 5035.439375214214, 5040.083737384747, 5076.667879062623, 5086.728846763394, 2384.3744891048545, 5056.468811040934, 5083.5624937791445, 5044.65255767223, 5037.211122732358, 5126.571881781333, 5097.50846885606, 5113.855481732768, 5149.001388245534, 5142.087390260312, 5094.297334909063, 5170.664632073605, 5184.168501417416, 5228.157885181042, 5162.983569148966, 5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3324385460710637, 'mean_inference_ms': 9.42401362901721, 'mean_action_processing_ms': 0.20233971011167826, 'mean_env_wait_ms': 2.3363076537438747, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03000950813293457, 'StateBufferConnector_ms': 0.00035309791564941406, 'ViewRequirementAgentConnector_ms': 0.20270514488220215}, 'num_episodes': 1, 'episode_return_max': 5250.786292316162, 'episode_return_min': -246.0965180999978, 'episode_return_mean': 4461.597686822179, 'episodes_this_iter': 1}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3364000, 'num_agent_steps_trained': 3364000, 'num_env_steps_sampled': 3364000, 'num_env_steps_trained': 3364000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 407.84008440530465, 'num_env_steps_trained_throughput_per_sec': 407.84008440530465, 'timesteps_total': 3364000, 'num_env_steps_sampled_lifetime': 3364000, 'num_agent_steps_sampled_lifetime': 3364000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 3364000, 'timers': {'training_iteration_time_ms': 10081.738, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10081.738, 'sample_time_ms': 4285.238, 'load_time_ms': 16.754, 'load_throughput': 238742.056, 'learn_time_ms': 5752.542, 'learn_throughput': 695.345, 'synch_weights_time_ms': 27.047, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 188122.808, 'evaluation_iteration_throughput': 301.792}, 'counters': {'num_env_steps_sampled': 3364000, 'num_env_steps_trained': 3364000, 'num_agent_steps_sampled': 3364000, 'num_agent_steps_trained': 3364000, 'num_env_steps_sampled_for_evaluation_this_iter': 58429}, 'done': False, 'training_iteration': 841, 'trial_id': 'default', 'date': '2024-10-03_14-39-28', 'timestamp': 1727933968, 'time_this_iter_s': 9.816324949264526, 'time_total_s': 10018.126446723938, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 10018.126446723938, 'iterations_since_restore': 841, 'perf': {'cpu_util_percent': 15.721428571428572, 'ram_util_percent': 42.592857142857156}})\n",
      "841th iteration done\n",
      "842th iteration done\n",
      "843th iteration done\n",
      "844th iteration done\n",
      "845th iteration done\n",
      "846th iteration done\n",
      "847th iteration done\n",
      "848th iteration done\n",
      "849th iteration done\n",
      "850th iteration done\n",
      "851th iteration done\n",
      "852th iteration done\n",
      "853th iteration done\n",
      "854th iteration done\n",
      "855th iteration done\n",
      "856th iteration done\n",
      "857th iteration done\n",
      "858th iteration done\n",
      "859th iteration done\n",
      "860th iteration done\n",
      "861th iteration done\n",
      "862th iteration done\n",
      "863th iteration done\n",
      "864th iteration done\n",
      "865th iteration done\n",
      "866th iteration done\n",
      "867th iteration done\n",
      "868th iteration done\n",
      "869th iteration done\n",
      "870th iteration done\n",
      "871th iteration done\n",
      "872th iteration done\n",
      "873th iteration done\n",
      "874th iteration done\n",
      "875th iteration done\n",
      "876th iteration done\n",
      "877th iteration done\n",
      "878th iteration done\n",
      "879th iteration done\n",
      "880th iteration done\n",
      "881th iteration done\n",
      "882th iteration done\n",
      "883th iteration done\n",
      "884th iteration done\n",
      "885th iteration done\n",
      "886th iteration done\n",
      "887th iteration done\n",
      "888th iteration done\n",
      "889th iteration done\n",
      "890th iteration done\n",
      "891th iteration done\n",
      "892th iteration done\n",
      "893th iteration done\n",
      "894th iteration done\n",
      "895th iteration done\n",
      "896th iteration done\n",
      "897th iteration done\n",
      "898th iteration done\n",
      "899th iteration done\n",
      "900th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_15), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.017167023339018386, 'policy_loss': -0.22235123026835663, 'vf_loss': 0.21411155302322255, 'vf_explained_var': 0.837612626501309, 'kl': 0.016728691880487003, 'entropy': 17.005917530675088, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 837465.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 3604000, 'num_env_steps_trained': 3604000, 'num_agent_steps_sampled': 3604000, 'num_agent_steps_trained': 3604000, 'num_env_steps_sampled_for_evaluation_this_iter': 50108}, 'env_runners': {'episode_reward_max': 5383.685693860274, 'episode_reward_min': -160.60976052412343, 'episode_reward_mean': 4729.913899225371, 'episode_len_mean': 5548.92, 'episode_media': {}, 'episodes_timesteps_total': 554892, 'policy_reward_min': {'default_policy': -160.60976052412343}, 'policy_reward_max': {'default_policy': 5383.685693860274}, 'policy_reward_mean': {'default_policy': 4729.913899225371}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352, 5054.302959899652, 5015.488354238216, 3454.6937923242813, 5020.134155117885, 5108.149808955259, 5001.5996099635595, 5065.007192807534, 5035.439375214214, 5040.083737384747, 5076.667879062623, 5086.728846763394, 2384.3744891048545, 5056.468811040934, 5083.5624937791445, 5044.65255767223, 5037.211122732358, 5126.571881781333, 5097.50846885606, 5113.855481732768, 5149.001388245534, 5142.087390260312, 5094.297334909063, 5170.664632073605, 5184.168501417416, 5228.157885181042, 5162.983569148966, 5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569, 5226.861276273267, 5227.974070407954, 5266.344724425847, 5271.271499296955, 5249.012897494186, 5207.9430376323635, 5230.53156664254, 5233.03359597903, 5309.693519265493, 5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 2386, 6000, 6000, 6000, 5420, 5707, 6000, 6000, 6000, 3226, 6000, 6000, 6000, 4336, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 2877, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 156, 6000, 6000, 6000, 6000, 6000, 6000, 2378, 220, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3270, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1092, 6000, 219, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1605, 6000, 6000, 6000], 'policy_default_policy_reward': [4898.3820979739785, 4946.428064326402, 4984.797681080623, 4926.41817178374, 4939.47938176604, 4924.581375592016, 1131.1484567788575, 5008.622529156974, 4982.480094433108, 5050.914537583858, 4466.152142524399, 4443.834860526016, 4964.086117027035, 4995.576532766548, 4893.126441905629, 2317.0596675465135, 5020.87165644352, 5054.302959899652, 5015.488354238216, 3454.6937923242813, 5020.134155117885, 5108.149808955259, 5001.5996099635595, 5065.007192807534, 5035.439375214214, 5040.083737384747, 5076.667879062623, 5086.728846763394, 2384.3744891048545, 5056.468811040934, 5083.5624937791445, 5044.65255767223, 5037.211122732358, 5126.571881781333, 5097.50846885606, 5113.855481732768, 5149.001388245534, 5142.087390260312, 5094.297334909063, 5170.664632073605, 5184.168501417416, 5228.157885181042, 5162.983569148966, 5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569, 5226.861276273267, 5227.974070407954, 5266.344724425847, 5271.271499296955, 5249.012897494186, 5207.9430376323635, 5230.53156664254, 5233.03359597903, 5309.693519265493, 5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.33257479763842285, 'mean_inference_ms': 9.412998745346135, 'mean_action_processing_ms': 0.2020873826469284, 'mean_env_wait_ms': 2.3376753846136857, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.03000950813293457, 'StateBufferConnector_ms': 0.0004775524139404297, 'ViewRequirementAgentConnector_ms': 0.15009355545043945}, 'num_episodes': 0, 'episode_return_max': 5383.685693860274, 'episode_return_min': -160.60976052412343, 'episode_return_mean': 4729.913899225371, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3604000, 'num_agent_steps_trained': 3604000, 'num_env_steps_sampled': 3604000, 'num_env_steps_trained': 3604000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 392.9207170114728, 'num_env_steps_trained_throughput_per_sec': 392.9207170114728, 'timesteps_total': 3604000, 'num_env_steps_sampled_lifetime': 3604000, 'num_agent_steps_sampled_lifetime': 3604000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 3604000, 'timers': {'training_iteration_time_ms': 10052.567, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10052.567, 'sample_time_ms': 4278.667, 'load_time_ms': 14.986, 'load_throughput': 266908.738, 'learn_time_ms': 5729.252, 'learn_throughput': 698.171, 'synch_weights_time_ms': 29.662, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 185554.55, 'evaluation_iteration_throughput': 301.978}, 'counters': {'num_env_steps_sampled': 3604000, 'num_env_steps_trained': 3604000, 'num_agent_steps_sampled': 3604000, 'num_agent_steps_trained': 3604000, 'num_env_steps_sampled_for_evaluation_this_iter': 50108}, 'done': False, 'training_iteration': 901, 'trial_id': 'default', 'date': '2024-10-03_14-52-19', 'timestamp': 1727934739, 'time_this_iter_s': 10.191282749176025, 'time_total_s': 10787.496574401855, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 10787.496574401855, 'iterations_since_restore': 901, 'perf': {'cpu_util_percent': 16.81428571428571, 'ram_util_percent': 42.64285714285715}})\n",
      "901th iteration done\n",
      "902th iteration done\n",
      "903th iteration done\n",
      "904th iteration done\n",
      "905th iteration done\n",
      "906th iteration done\n",
      "907th iteration done\n",
      "908th iteration done\n",
      "909th iteration done\n",
      "910th iteration done\n",
      "911th iteration done\n",
      "912th iteration done\n",
      "913th iteration done\n",
      "914th iteration done\n",
      "915th iteration done\n",
      "916th iteration done\n",
      "917th iteration done\n",
      "918th iteration done\n",
      "919th iteration done\n",
      "920th iteration done\n",
      "921th iteration done\n",
      "922th iteration done\n",
      "923th iteration done\n",
      "924th iteration done\n",
      "925th iteration done\n",
      "926th iteration done\n",
      "927th iteration done\n",
      "928th iteration done\n",
      "929th iteration done\n",
      "930th iteration done\n",
      "931th iteration done\n",
      "932th iteration done\n",
      "933th iteration done\n",
      "934th iteration done\n",
      "935th iteration done\n",
      "936th iteration done\n",
      "937th iteration done\n",
      "938th iteration done\n",
      "939th iteration done\n",
      "940th iteration done\n",
      "941th iteration done\n",
      "942th iteration done\n",
      "943th iteration done\n",
      "944th iteration done\n",
      "945th iteration done\n",
      "946th iteration done\n",
      "947th iteration done\n",
      "948th iteration done\n",
      "949th iteration done\n",
      "950th iteration done\n",
      "951th iteration done\n",
      "952th iteration done\n",
      "953th iteration done\n",
      "954th iteration done\n",
      "955th iteration done\n",
      "956th iteration done\n",
      "957th iteration done\n",
      "958th iteration done\n",
      "959th iteration done\n",
      "960th iteration done\n",
      "Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_16), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': 0.07357965128155805, 'policy_loss': -0.21443823086378236, 'vf_loss': 0.2628191741983286, 'vf_explained_var': 0.7961735467756949, 'kl': 0.016591742109809002, 'entropy': 16.803504658770816, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 893265.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 3844000, 'num_env_steps_trained': 3844000, 'num_agent_steps_sampled': 3844000, 'num_agent_steps_trained': 3844000, 'num_env_steps_sampled_for_evaluation_this_iter': 50108}, 'env_runners': {'episode_reward_max': 5593.191618954761, 'episode_reward_min': -160.60976052412343, 'episode_reward_mean': 4967.868487292563, 'episode_len_mean': 5619.81, 'episode_media': {}, 'episodes_timesteps_total': 561981, 'policy_reward_min': {'default_policy': -160.60976052412343}, 'policy_reward_max': {'default_policy': 5593.191618954761}, 'policy_reward_mean': {'default_policy': 4967.868487292563}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569, 5226.861276273267, 5227.974070407954, 5266.344724425847, 5271.271499296955, 5249.012897494186, 5207.9430376323635, 5230.53156664254, 5233.03359597903, 5309.693519265493, 5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777, 5471.755454458562, 5471.843934241108, 5355.85060617692, 5255.052657003926, 5344.9086179198985, 5339.7079134729665, 5377.825748916925, 1499.7630035333937, 4503.06199446396, 5371.353621920722, 5440.593759819431, 5352.565030859711, 5469.77338472973, 5426.176823721582, 5450.06263149515, 5364.313914109948, 5427.497707647056, 5379.794079068108, 5460.247035024505, 5365.805680216639, 5412.0933663970145, 5380.974785660675, 5403.894224052473, 5436.24179325151, 5451.442173285209, 5442.585411172193, 5446.150407473866, 5373.481545437783, 5428.856793034958, 5527.938902272439, 5497.805255633895, 5442.144961402069, 5476.477667672792, 5395.621930413543, 5461.507984033421, 5505.1510199185495, 5496.126450340144, 5464.229346616609, 5506.771173498097, 5443.552620775789, 5593.191618954761, 5469.696708341956, 5539.390597161525], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 156, 6000, 6000, 6000, 6000, 6000, 6000, 2378, 220, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 3270, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1092, 6000, 219, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1605, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1746, 5295, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [5214.195087569351, 5169.989345878952, 4625.386917279416, 5131.892042997868, 5111.627441440557, -105.11444401289123, 5198.737505298798, 5117.3447453292065, 5175.568112682737, 5153.054065672352, 5192.748290155149, 5176.321439277147, 1905.2103214404938, -156.62858983266628, 5203.215600054697, 5250.786292316162, 5208.291657033569, 5226.861276273267, 5227.974070407954, 5266.344724425847, 5271.271499296955, 5249.012897494186, 5207.9430376323635, 5230.53156664254, 5233.03359597903, 5309.693519265493, 5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777, 5471.755454458562, 5471.843934241108, 5355.85060617692, 5255.052657003926, 5344.9086179198985, 5339.7079134729665, 5377.825748916925, 1499.7630035333937, 4503.06199446396, 5371.353621920722, 5440.593759819431, 5352.565030859711, 5469.77338472973, 5426.176823721582, 5450.06263149515, 5364.313914109948, 5427.497707647056, 5379.794079068108, 5460.247035024505, 5365.805680216639, 5412.0933663970145, 5380.974785660675, 5403.894224052473, 5436.24179325151, 5451.442173285209, 5442.585411172193, 5446.150407473866, 5373.481545437783, 5428.856793034958, 5527.938902272439, 5497.805255633895, 5442.144961402069, 5476.477667672792, 5395.621930413543, 5461.507984033421, 5505.1510199185495, 5496.126450340144, 5464.229346616609, 5506.771173498097, 5443.552620775789, 5593.191618954761, 5469.696708341956, 5539.390597161525]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3328149442907303, 'mean_inference_ms': 9.400015076370458, 'mean_action_processing_ms': 0.20199336242463725, 'mean_env_wait_ms': 2.3388611001258943, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0, 'StateBufferConnector_ms': 0.00012445449829101562, 'ViewRequirementAgentConnector_ms': 0.168778657913208}, 'num_episodes': 0, 'episode_return_max': 5593.191618954761, 'episode_return_min': -160.60976052412343, 'episode_return_mean': 4967.868487292563, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 3844000, 'num_agent_steps_trained': 3844000, 'num_env_steps_sampled': 3844000, 'num_env_steps_trained': 3844000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 387.27192955910454, 'num_env_steps_trained_throughput_per_sec': 387.27192955910454, 'timesteps_total': 3844000, 'num_env_steps_sampled_lifetime': 3844000, 'num_agent_steps_sampled_lifetime': 3844000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 3844000, 'timers': {'training_iteration_time_ms': 10137.417, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10137.417, 'sample_time_ms': 4285.757, 'load_time_ms': 19.563, 'load_throughput': 204463.554, 'learn_time_ms': 5801.364, 'learn_throughput': 689.493, 'synch_weights_time_ms': 30.116, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 185554.55, 'evaluation_iteration_throughput': 301.978}, 'counters': {'num_env_steps_sampled': 3844000, 'num_env_steps_trained': 3844000, 'num_agent_steps_sampled': 3844000, 'num_agent_steps_trained': 3844000, 'num_env_steps_sampled_for_evaluation_this_iter': 50108}, 'done': False, 'training_iteration': 961, 'trial_id': 'default', 'date': '2024-10-03_15-02-26', 'timestamp': 1727935346, 'time_this_iter_s': 10.339245557785034, 'time_total_s': 11393.598290205002, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 11393.598290205002, 'iterations_since_restore': 961, 'perf': {'cpu_util_percent': 16.8, 'ram_util_percent': 42.64000000000001}})\n",
      "961th iteration done\n",
      "962th iteration done\n",
      "963th iteration done\n",
      "964th iteration done\n",
      "965th iteration done\n",
      "966th iteration done\n",
      "967th iteration done\n",
      "968th iteration done\n",
      "969th iteration done\n",
      "970th iteration done\n",
      "971th iteration done\n",
      "972th iteration done\n",
      "973th iteration done\n",
      "974th iteration done\n",
      "975th iteration done\n",
      "976th iteration done\n",
      "977th iteration done\n",
      "978th iteration done\n",
      "979th iteration done\n",
      "980th iteration done\n",
      "981th iteration done\n",
      "982th iteration done\n",
      "983th iteration done\n",
      "984th iteration done\n",
      "985th iteration done\n",
      "986th iteration done\n",
      "987th iteration done\n",
      "988th iteration done\n",
      "989th iteration done\n",
      "990th iteration done\n",
      "991th iteration done\n",
      "992th iteration done\n",
      "993th iteration done\n",
      "994th iteration done\n",
      "995th iteration done\n",
      "996th iteration done\n",
      "997th iteration done\n",
      "998th iteration done\n",
      "999th iteration done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_GD_V3_512x5_final), metrics={'evaluation': {'env_runners': {'episode_reward_max': 5723.757065302427, 'episode_reward_min': 5576.7617990429, 'episode_reward_mean': 5637.427962705935, 'episode_len_mean': 6000.0, 'episode_media': {}, 'episodes_timesteps_total': 60000, 'policy_reward_min': {'default_policy': 5576.7617990429}, 'policy_reward_max': {'default_policy': 5723.757065302427}, 'policy_reward_mean': {'default_policy': 5637.427962705935}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5577.758627678155, 5636.487975045921, 5576.7617990429, 5622.9884634896025, 5664.3256521857575, 5660.9263460111815, 5607.499493993334, 5590.432282006756, 5713.34192230332, 5723.757065302427], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [5577.758627678155, 5636.487975045921, 5576.7617990429, 5622.9884634896025, 5664.3256521857575, 5660.9263460111815, 5607.499493993334, 5590.432282006756, 5713.34192230332, 5723.757065302427]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.1692381375667043, 'mean_inference_ms': 1.6339516186406549, 'mean_action_processing_ms': 0.1116075241475352, 'mean_env_wait_ms': 1.3863557107954725, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.0, 'StateBufferConnector_ms': 0.0, 'ViewRequirementAgentConnector_ms': 0.10060548782348633}, 'num_episodes': 10, 'episode_return_max': 5723.757065302427, 'episode_return_min': 5576.7617990429, 'episode_return_mean': 5637.427962705935, 'episodes_this_iter': 10}, 'num_agent_steps_sampled_this_iter': 60000, 'num_env_steps_sampled_this_iter': 60000, 'timesteps_this_iter': 60000, 'num_healthy_workers': 0, 'num_in_flight_async_reqs': 0, 'num_remote_worker_restarts': 0}, 'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': 1.5187500000000005, 'cur_lr': 0.00010000000000000003, 'total_loss': -0.017139250835183487, 'policy_loss': -0.22414658120883407, 'vf_loss': 0.1815937619382107, 'vf_explained_var': 0.8479069216917919, 'kl': 0.016733215095757592, 'entropy': 16.707189176415884, 'entropy_coeff': 0.0}, 'model': {}, 'num_grad_updates_lifetime': 929535.5, 'diff_num_grad_updates_vs_sampler_policy': 464.5}}, 'num_env_steps_sampled': 4000000, 'num_env_steps_trained': 4000000, 'num_agent_steps_sampled': 4000000, 'num_agent_steps_trained': 4000000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'env_runners': {'episode_reward_max': 5666.22536008332, 'episode_reward_min': -160.60976052412343, 'episode_reward_mean': 5206.296113225899, 'episode_len_mean': 5772.27, 'episode_media': {}, 'episodes_timesteps_total': 577227, 'policy_reward_min': {'default_policy': -160.60976052412343}, 'policy_reward_max': {'default_policy': 5666.22536008332}, 'policy_reward_mean': {'default_policy': 5206.296113225899}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777, 5471.755454458562, 5471.843934241108, 5355.85060617692, 5255.052657003926, 5344.9086179198985, 5339.7079134729665, 5377.825748916925, 1499.7630035333937, 4503.06199446396, 5371.353621920722, 5440.593759819431, 5352.565030859711, 5469.77338472973, 5426.176823721582, 5450.06263149515, 5364.313914109948, 5427.497707647056, 5379.794079068108, 5460.247035024505, 5365.805680216639, 5412.0933663970145, 5380.974785660675, 5403.894224052473, 5436.24179325151, 5451.442173285209, 5442.585411172193, 5446.150407473866, 5373.481545437783, 5428.856793034958, 5527.938902272439, 5497.805255633895, 5442.144961402069, 5476.477667672792, 5395.621930413543, 5461.507984033421, 5505.1510199185495, 5496.126450340144, 5464.229346616609, 5506.771173498097, 5443.552620775789, 5593.191618954761, 5469.696708341956, 5539.390597161525, 5172.8343322654155, 5468.354613613464, 5516.666851712199, 5528.021231013576, 5551.390974399247, 5590.61096702169, 5524.356290061374, 5489.446576857858, 5588.770411756431, 5512.181535544842, 5591.231828296011, 5627.402962804903, 5648.82235862562, 5603.54384446205, 5524.786777773912, 5617.03648553497, 5666.22536008332, 5625.044192873986, 5576.516172819386, 5579.030658844125, 5557.351256876546, 5523.415790868693, 5623.876405423866, 5611.765200112773, 5661.91437575784, 5657.457155927832], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 3270, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1092, 6000, 219, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1605, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 1746, 5295, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [5205.34003184478, 5247.418576610959, 5304.429690950029, 5326.6204171401305, 5231.953616646071, 2468.0456957633755, 5238.947122795431, 5235.043701787942, 5362.568398783417, 5291.602083186402, 5316.229136859005, 5282.115714183582, 5277.159378537575, 5264.817968539198, 5254.299067891847, 770.2985992665751, 5266.349855243755, -160.60976052412343, 5359.613876383969, 5242.173676092177, 5265.409911002664, 5345.428419519879, 5336.793555308412, 5262.522340129261, 5383.685693860274, 5314.7231255604775, 5314.611904117779, 1284.9101993421632, 5308.575319179913, 5324.023402209672, 5343.175657443777, 5471.755454458562, 5471.843934241108, 5355.85060617692, 5255.052657003926, 5344.9086179198985, 5339.7079134729665, 5377.825748916925, 1499.7630035333937, 4503.06199446396, 5371.353621920722, 5440.593759819431, 5352.565030859711, 5469.77338472973, 5426.176823721582, 5450.06263149515, 5364.313914109948, 5427.497707647056, 5379.794079068108, 5460.247035024505, 5365.805680216639, 5412.0933663970145, 5380.974785660675, 5403.894224052473, 5436.24179325151, 5451.442173285209, 5442.585411172193, 5446.150407473866, 5373.481545437783, 5428.856793034958, 5527.938902272439, 5497.805255633895, 5442.144961402069, 5476.477667672792, 5395.621930413543, 5461.507984033421, 5505.1510199185495, 5496.126450340144, 5464.229346616609, 5506.771173498097, 5443.552620775789, 5593.191618954761, 5469.696708341956, 5539.390597161525, 5172.8343322654155, 5468.354613613464, 5516.666851712199, 5528.021231013576, 5551.390974399247, 5590.61096702169, 5524.356290061374, 5489.446576857858, 5588.770411756431, 5512.181535544842, 5591.231828296011, 5627.402962804903, 5648.82235862562, 5603.54384446205, 5524.786777773912, 5617.03648553497, 5666.22536008332, 5625.044192873986, 5576.516172819386, 5579.030658844125, 5557.351256876546, 5523.415790868693, 5623.876405423866, 5611.765200112773, 5661.91437575784, 5657.457155927832]}, 'sampler_perf': {'mean_raw_obs_processing_ms': 0.3328894953416927, 'mean_inference_ms': 9.3924301661119, 'mean_action_processing_ms': 0.20197596049058014, 'mean_env_wait_ms': 2.339786542861168, 'mean_env_render_ms': 0.0}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': 0.002130270004272461, 'StateBufferConnector_ms': 0.00012445449829101562, 'ViewRequirementAgentConnector_ms': 0.17416596412658691}, 'num_episodes': 0, 'episode_return_max': 5666.22536008332, 'episode_return_min': -160.60976052412343, 'episode_return_mean': 5206.296113225899, 'episodes_this_iter': 0}, 'num_healthy_workers': 12, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4000000, 'num_agent_steps_trained': 4000000, 'num_env_steps_sampled': 4000000, 'num_env_steps_trained': 4000000, 'num_env_steps_sampled_this_iter': 4000, 'num_env_steps_trained_this_iter': 4000, 'num_env_steps_sampled_throughput_per_sec': 390.2718077761279, 'num_env_steps_trained_throughput_per_sec': 390.2718077761279, 'timesteps_total': 4000000, 'num_env_steps_sampled_lifetime': 4000000, 'num_agent_steps_sampled_lifetime': 4000000, 'num_steps_trained_this_iter': 4000, 'agent_timesteps_total': 4000000, 'timers': {'training_iteration_time_ms': 10119.298, 'restore_workers_time_ms': 0.0, 'training_step_time_ms': 10119.298, 'sample_time_ms': 4291.955, 'load_time_ms': 18.239, 'load_throughput': 219309.726, 'learn_time_ms': 5781.739, 'learn_throughput': 691.833, 'synch_weights_time_ms': 26.826, 'restore_eval_workers_time_ms': 0.0, 'evaluation_iteration_time_ms': 186884.454, 'evaluation_iteration_throughput': 301.951}, 'counters': {'num_env_steps_sampled': 4000000, 'num_env_steps_trained': 4000000, 'num_agent_steps_sampled': 4000000, 'num_agent_steps_trained': 4000000, 'num_env_steps_sampled_for_evaluation_this_iter': 60000}, 'done': False, 'training_iteration': 1000, 'trial_id': 'default', 'date': '2024-10-03_15-12-19', 'timestamp': 1727935939, 'time_this_iter_s': 209.11995005607605, 'time_total_s': 11986.42851614952, 'pid': 27044, 'hostname': 'OMEN-45L', 'node_ip': '127.0.0.1', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'plane-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 12, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.07692307692307693, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'enable_connectors': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.9, 'lr': 0.0001, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 4000, 'model': {'_disable_preprocessor_api': False, '_disable_action_flattening': False, 'fcnet_hiddens': [512, 512, 512, 512, 512], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, 'max_requests_in_flight_per_sampler_worker': 2, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x000001AD8AF69260>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': 100, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'ignore_env_runner_failures': False, 'recreate_failed_env_runners': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30, 'env_runner_restore_timeout_s': 1800, '_model_config_dict': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'sgd_minibatch_size': 128, 'mini_batch_size_per_learner': None, 'num_sgd_iter': 30, 'shuffle_sequences': True, 'vf_loss_coeff': 1.0, 'entropy_coeff': 0.0, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 10.0, 'vf_share_layers': -1, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 11986.42851614952, 'iterations_since_restore': 1000, 'perf': {'cpu_util_percent': 3.7628762541806027, 'ram_util_percent': 42.68695652173912}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "n_iter = 1000\n",
    "save_iter = 0\n",
    "save_name = \"PPO_GD_V3_512x5\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}th iteration done\")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%60 == 0:\n",
    "        checkpoint_dir = algo.save(save_name+\"_\"+str(save_iter))\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "algo.save(save_name+str(\"_final\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경에서 학습된 Policy 테스트하기 (RL Module 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.core.rl_module import RLModule\n",
    "import pathlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from horcrux_terrain_v1.envs import SandWorld\n",
    "import time\n",
    "\n",
    "algo = Algorithm.from_checkpoint(\"./ModelV2_512x5_11\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"horcrux_terrain_v1/plane-v1\", \n",
    "#                terminate_when_unhealthy = False, \n",
    "#                render_mode = \"human\", \n",
    "#             #    render_camera_name = 'ceiling', \n",
    "#                use_gait = True,\n",
    "#                gait_params = (30,30,40,40,0),\n",
    "#                **env_config,\n",
    "#                ) \n",
    "\n",
    "# obs, info = env.reset()\n",
    "\n",
    "# algo.get_policy().action_connectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"horcrux_terrain_v1/sand-v1\", \n",
    "#                terminate_when_unhealthy = False, \n",
    "#                render_mode = \"human\", \n",
    "#             #    render_camera_name = 'ceiling', \n",
    "#                use_gait = True,\n",
    "#                gait_params = (30,30,40,40,0),\n",
    "#                **env_config,\n",
    "#                ) \n",
    "\n",
    "env = gym.make(\"horcrux_terrain_v1/plane-v1\", \n",
    "               terminate_when_unhealthy = False, \n",
    "               render_mode = \"human\", \n",
    "            #    render_camera_name = 'ceiling', \n",
    "               use_gait = True,\n",
    "               gait_params = (30,30,40,40,0),\n",
    "               **env_config,\n",
    "               ) \n",
    "\n",
    "for j in range(5):\n",
    "   episode_return = 0\n",
    "   terminated = truncated = False\n",
    "\n",
    "   obs, info = env.reset()\n",
    "\n",
    "\n",
    "   for i in range(6000):\n",
    "      action = algo.compute_single_action(obs, explore=False)\n",
    "      \n",
    "      obs, reward, terminated, truncated, info = env.step(action)\n",
    "      \n",
    "      prev_a = action\n",
    "\n",
    "      if terminated:\n",
    "         print(\"terminated\")\n",
    "\n",
    "      episode_return += reward\n",
    "\n",
    "   print(f\"Reached episode return of {episode_return}.\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "환경에서 학습된 Policy 테스트하기 (PPO 알고리즘 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from horcrux_terrain_v1.envs import SandWorld\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import time\n",
    "\n",
    "env = gym.make(\"horcrux_terrain_v1/plane-v1\", \n",
    "               terminate_when_unhealthy = False, \n",
    "               render_mode = \"human\", \n",
    "            #    render_camera_name = 'ceiling', \n",
    "               use_gait = True,\n",
    "               gait_params = (30,30,40,40,0),\n",
    "               **env_config,\n",
    "               ) \n",
    "\n",
    "for j in range(10):\n",
    "   episode_return = 0\n",
    "   terminated = truncated = False\n",
    "\n",
    "   obs, info = env.reset()\n",
    "\n",
    "   init_state = state = [np.zeros([4096], np.float32) for _ in range(200)]\n",
    "   prev_action = np.zeros((14), np.float32)\n",
    "   for i in range(1000):\n",
    "\n",
    "      a, init_state = algo.compute_single_action(observation= obs, state=init_state, prev_action=prev_action,policy_id=\"default_policy\")\n",
    "      \n",
    "      obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "      prev_action = a\n",
    "      if terminated:\n",
    "         print(\"terminated\")\n",
    "\n",
    "      episode_return += reward\n",
    "\n",
    "   print(f\"Reached episode return of {episode_return}.\")\n",
    "\n",
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rllib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
