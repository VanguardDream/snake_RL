{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada3dd6c-e196-4236-87e2-59bd12ee93c9",
   "metadata": {},
   "source": [
    "# Horcrux Joystick 입력 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d86890-4e2f-4c3e-a30c-b281c5de415b",
   "metadata": {},
   "source": [
    "## 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f4abf-b333-49c3-9ea6-22f049e2eb51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 조이스틱 환경 삽입\n",
    "from horcrux_terrain_v1.envs import PlaneJoyWorld\n",
    "from horcrux_terrain_v1.envs import PlaneWorld\n",
    "\n",
    "# Ray 패키지 삽입\n",
    "import ray\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "\n",
    "from ray.tune.registry import register_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517ec57-16da-4789-a76f-2c77998e7a5e",
   "metadata": {},
   "source": [
    "## Ray 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31cbbe-264f-4298-a2f1-471cf823d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import psutil\n",
    "\n",
    "conn_ip = \"\"\n",
    "interfaces = psutil.net_if_addrs()\n",
    "for interface_name, addresses in interfaces.items():\n",
    "    if \"openvpn\" in interface_name.lower() and \"tap\" in interface_name.lower():\n",
    "        snicaddrs = interfaces[str(interface_name)]\n",
    "        for addrfamily in snicaddrs:\n",
    "            if addrfamily.family == socket.AF_INET:\n",
    "                conn_ip = addrfamily.address\n",
    "\n",
    "# 해당 init을 통해서 VPN을 통한 외부 접속 가능함.\n",
    "ray.init(dashboard_host=conn_ip, dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407944-23a9-42b0-854b-c19f1c43bcdc",
   "metadata": {},
   "source": [
    "## Gym 환경 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e905-5daf-45c4-919f-98e53d97572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"forward_reward_weight\": 6.5,\n",
    "    \"side_cost_weight\": 2.0,\n",
    "    \"unhealthy_max_steps\": 100,\n",
    "    \"healthy_reward\": 0.5,\n",
    "    \"healthy_roll_range\": (-35,35),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 0.01,\n",
    "    \"rotation_orientation_cost_weight\": 1.2,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 60, 60, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "}\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     side_cost_weight=env_config[\"side_cost_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     rotation_orientation_cost_weight=env_config[\"rotation_orientation_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                   )\n",
    "            )\n",
    "\n",
    "# Plane\n",
    "register_env(\"plane-v1\", lambda config: PlaneWorld(forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                 side_cost_weight=env_config[\"side_cost_weight\"], \n",
    "                                                 unhealthy_max_steps=env_config[\"unhealthy_max_steps\"], \n",
    "                                                 healthy_reward=env_config[\"healthy_reward\"],\n",
    "                                                 healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                 terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                 rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                 rotation_orientation_cost_weight=env_config[\"rotation_orientation_cost_weight\"],\n",
    "                                                 termination_reward=env_config[\"termination_reward\"],\n",
    "                                                 use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                 gait_params=env_config[\"gait_params\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b260cf6f-c922-49e2-96ff-6a94536a1bd0",
   "metadata": {},
   "source": [
    "## 학습된 알고리즘 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d211abe2-7e3f-4825-abc9-521ca36200b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo = Algorithm.from_checkpoint(\"./Paper_agents/good/Linear/SAC_layer_512_5_32_Linear_restart_final\")\n",
    "\n",
    "# trained_weights = algo.get_weights()\n",
    "# algo.cleanup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf2134-3167-46f1-b28b-7d305065f559",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436edebc-bcaa-45fa-9941-58ad2868655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SACConfig()\n",
    "\n",
    "# 구형 API 구조 사용\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "\n",
    "config.environment(\"joy-v1\")\n",
    "config.framework(\"torch\")\n",
    "\n",
    "# 병렬 CPU 사용 설정\n",
    "total_workers = 12\n",
    "config.resources(num_gpus=1)\n",
    "config.env_runners(num_env_runners=12)\n",
    "config.training(\n",
    "    gamma=0.95,\n",
    "    replay_buffer_config={\n",
    "    \"_enable_replay_buffer_api\": True,\n",
    "    \"capacity\": int(1e6),\n",
    "    # If True prioritized replay buffer will be used.\n",
    "    \"prioritized_replay\": False,\n",
    "    \"prioritized_replay_alpha\": 0.6,\n",
    "    \"prioritized_replay_beta\": 0.4,\n",
    "    \"prioritized_replay_eps\": 1e-6,\n",
    "    # Whether to compute priorities already on the remote worker side.\n",
    "    \"worker_side_prioritization\": False,\n",
    "    },\n",
    "\n",
    "    q_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "    policy_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define a custom policy model.\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "\n",
    "    train_batch_size_per_learner = 8192,\n",
    "    num_steps_sampled_before_learning_starts = 6000,\n",
    ")\n",
    "\n",
    "algo = config.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae756f-bb08-4813-bf07-c019392dac99",
   "metadata": {},
   "source": [
    "## 학습시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae0dfe-e461-442b-b090-cc437723543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "n_iter = 21000\n",
    "save_iter = 0\n",
    "save_name = \"SAC_layer_512_5_32_linear_friction_joy2\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}th iteration done\")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%3000 == 0:\n",
    "        checkpoint_dir = algo.save(save_name+\"_\"+str(save_iter))\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "algo.save(save_name+str(\"_final\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f40a7-044a-4e2c-a8c0-fcb8575b5bde",
   "metadata": {},
   "source": [
    "# 학습 알고리즘 평가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcfb0e4-1a84-492f-a0d7-9787b0182bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm.from_checkpoint(\"./SAC_layer_512_5_32_linear_friction_joy_1\") # 학습된 정책 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e963f9-0653-4c35-a7f4-3fb03d534bfe",
   "metadata": {},
   "source": [
    "## 평가용 Env 생성 및 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825c204-3cca-4c0d-878c-a68833f12909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import torch\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from horcrux_terrain_v1.envs import SandWorld\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "import time\n",
    "\n",
    "eval_config = env_config\n",
    "eval_config[\"use_friction_chg\"] = False\n",
    "eval_config[\"joy_input_random\"] = False\n",
    "eval_config[\"joy_input\"] = (0.7, 0, 0.6)\n",
    "\n",
    "\n",
    "env = gym.make(\"horcrux_terrain_v1/plane-v2\", \n",
    "               terminate_when_unhealthy = False, \n",
    "               render_mode = \"human\", \n",
    "               render_camera_name = 'ceiling', \n",
    "               use_gait = True,               \n",
    "               **eval_config,\n",
    "               ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b174b-71a4-4a63-8788-02fb73512db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(3):\n",
    "   episode_return = 0\n",
    "   terminated = truncated = False\n",
    "\n",
    "   obs, info = env.reset()\n",
    "\n",
    "   for i in range(1000):\n",
    "\n",
    "      action = algo.compute_single_action(observation= obs)\n",
    "      \n",
    "      obs, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "      if terminated:\n",
    "         print(\"terminated\")\n",
    "\n",
    "      episode_return += reward\n",
    "\n",
    "   print(f\"Reached episode return of {episode_return}.\")\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1aaeb7-4697-41bc-ad9b-079f609dc5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdtor",
   "language": "python",
   "name": "gdtor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
