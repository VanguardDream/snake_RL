{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada3dd6c-e196-4236-87e2-59bd12ee93c9",
   "metadata": {},
   "source": [
    "# Horcrux Joystick 입력 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d86890-4e2f-4c3e-a30c-b281c5de415b",
   "metadata": {},
   "source": [
    "## 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9f4abf-b333-49c3-9ea6-22f049e2eb51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 조이스틱 환경 삽입\n",
    "import horcrux_terrain_v2\n",
    "from horcrux_terrain_v2.envs import PlaneJoyWorld\n",
    "\n",
    "# Ray 패키지 삽입\n",
    "import ray\n",
    "import os\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import mediapy as media\n",
    "\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93044ef8",
   "metadata": {},
   "source": [
    "# 사용자 구성 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe50062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "class CustomSACModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        model_shape = model_config['fcnet_hiddens']\n",
    "        print(model_config)\n",
    "\n",
    "        # Shared actor trunk\n",
    "        self.shared = FullyConnectedNetwork(\n",
    "            obs_space, action_space, model_shape[-1], model_config, name + \"_shared\"\n",
    "        )\n",
    "\n",
    "        # Value network head 확장\n",
    "        self.value_branch = nn.Sequential(\n",
    "            nn.Linear(model_shape[-1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._value_out = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        features, _ = self.shared(input_dict, state, seq_lens)\n",
    "        self._value_out = self.value_branch(features)\n",
    "        return features, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self._value_out.squeeze(1)\n",
    "    \n",
    "    \n",
    "ModelCatalog.register_custom_model(\"custom_sac_model\", CustomSACModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf2442",
   "metadata": {},
   "source": [
    "# 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e9cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_filename(base_path, ext=\".mp4\"):\n",
    "    \"\"\"중복된 파일명이 존재하면 숫자를 증가하여 새로운 경로를 반환\"\"\"\n",
    "    if not base_path.endswith(ext):\n",
    "        base_path += ext  # 확장자 자동 추가\n",
    "\n",
    "    file_name, file_ext = os.path.splitext(base_path)  # 파일명과 확장자 분리\n",
    "    count = 0\n",
    "    new_path = f\"{file_name}-episode-0\"+file_ext\n",
    "\n",
    "    while os.path.exists(new_path):  # 파일 존재 여부 확인\n",
    "        new_path = f\"{file_name}{count}-episode-0{file_ext}\"\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    return f\"rl-video{count-1}\", new_path\n",
    "\n",
    "\n",
    "def default_plot(x, y, f_name='default_plot', legends=['acc_x', 'acc_y', 'acc_z'], title=''):\n",
    "    colors = plt.get_cmap(\"tab10\").colors\n",
    "    fig, ax = plt.subplots(figsize=(15/2.54, 10/2.54))\n",
    "    ax.set_facecolor((0.95, 0.95, 0.95)) \n",
    "\n",
    "    n_column = len(np.shape(y))\n",
    "    if n_column>2:\n",
    "        print(\"The dimmension of data must be less than 3. (1D or 2D)\")\n",
    "        return -1\n",
    "    \n",
    "    n_data = np.shape(y)[1]\n",
    "\n",
    "    for i in range(n_data):\n",
    "        # **Plot**\n",
    "        ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[i], label=legends[i])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[1], label=legends[1])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[2], label=legends[2])\n",
    "\n",
    "    # **Grid 설정**\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=1, color=\"#202020\", alpha=0.7)  # 주요 그리드\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, color=\"#404040\", alpha=0.5)  # 보조 그리드\n",
    "\n",
    "    # **Axis 스타일 설정**\n",
    "    ax.spines[\"top\"].set_linewidth(1.0)\n",
    "    ax.spines[\"right\"].set_linewidth(1.0)\n",
    "    ax.spines[\"left\"].set_linewidth(1.0)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.0)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", labelsize=11, width=1.0)  # 폰트 크기 및 라인 두께\n",
    "    ax.xaxis.label.set_size(12)\n",
    "    ax.yaxis.label.set_size(12)\n",
    "\n",
    "    # **폰트 및 제목 설정**\n",
    "    plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    ax.set_xlabel(\"X-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Y-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # **Legend (MATLAB 스타일 적용)**\n",
    "    ax.legend(loc=\"upper right\", ncol=3, fontsize=10, frameon=True)\n",
    "\n",
    "    # **비율 설정 (MATLAB의 `pbaspect([2.1 1 1])`과 비슷한 효과)**\n",
    "    fig.set_size_inches(2.1 * 5, 5)  # 비율 2.1:1 (기본 높이 5inch 기준)\n",
    "\n",
    "    # **Save Figure (MATLAB saveas와 유사)**\n",
    "    plt.savefig(f\"./figs/{f_name}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, kernel, mode='same')  # 'valid'는 경계 제외\n",
    "\n",
    "\n",
    "def get_data_from_info(info):\n",
    "    # Status info\n",
    "    stat_init_rpy = np.array([_info['init_rpy'] for _info in info])\n",
    "    stat_init_com = np.array([_info['init_com'] for _info in info])\n",
    "    stat_xy_vel = np.array([[_info['x_velocity'], _info['y_velocity']] for _info in info])\n",
    "    stat_yaw_vel = np.array([_info['yaw_velocity'] for _info in info])\n",
    "    stat_quat = np.array([_info['head_quat'] for _info in info])\n",
    "    stat_ang_vel = np.array([_info['head_ang_vel'] for _info in info])\n",
    "    stat_lin_acc = np.array([_info['head_lin_acc'] for _info in info])\n",
    "    stat_motion_vector = np.array([_info['motion_vector'] for _info in info])\n",
    "    stat_com_pos = np.array([_info['com_pos'] for _info in info])\n",
    "    stat_com_ypr = np.array([_info['com_ypr'] for _info in info])\n",
    "    stat_step_ypr = np.array([_info['step_ypr'] for _info in info])\n",
    "    \n",
    "\n",
    "    # Rew info\n",
    "    rew_linear_movement = np.array([_info['reward_linear_movement'] for _info in info])\n",
    "    reward_angular_movement = np.array([_info['reward_angular_movement'] for _info in info])\n",
    "    reward_efficiency = np.array([_info['reward_efficiency'] for _info in info])\n",
    "    reward_healthy = np.array([_info['reward_healthy'] for _info in info])\n",
    "    cost_ctrl = np.array([_info['cost_ctrl'] for _info in info])\n",
    "    cost_unhealthy = np.array([_info['cost_unhealthy'] for _info in info])\n",
    "    cost_orientation = np.array([_info['cost_orientation'] for _info in info])\n",
    "    cost_yaw_vel = np.array([_info['cost_yaw_vel'] for _info in info])\n",
    "    direction_similarity = np.array([_info['direction_similarity'] for _info in info])\n",
    "    rotation_alignment = np.array([_info['rotation_alignment'] for _info in info])\n",
    "\n",
    "    # Input info\n",
    "    input_joy = np.array([_info['joy_input'] for _info in info])\n",
    "\n",
    "    data_dict = {\n",
    "        'stat_init_rpy': stat_init_rpy,\n",
    "        'stat_init_com': stat_init_com,\n",
    "        'stat_xy_vel': stat_xy_vel,\n",
    "        'stat_yaw_vel': stat_yaw_vel,\n",
    "        'stat_quat': stat_quat,\n",
    "        'stat_ang_vel': stat_ang_vel,\n",
    "        'stat_lin_acc': stat_lin_acc,\n",
    "        'stat_motion_vector': stat_motion_vector,\n",
    "        'stat_com_pos': stat_com_pos,\n",
    "        'stat_com_ypr': stat_com_ypr,\n",
    "        'stat_step_ypr': stat_step_ypr,\n",
    "\n",
    "        'rew_linear_movement': rew_linear_movement,\n",
    "        'reward_angular_movement': reward_angular_movement,\n",
    "        'reward_efficiency': reward_efficiency,\n",
    "        'reward_healthy': reward_healthy,\n",
    "        'cost_ctrl': cost_ctrl,\n",
    "        'cost_unhealthy': cost_unhealthy,\n",
    "        'cost_orientation': cost_orientation,\n",
    "        'cost_yaw_vel': cost_yaw_vel,\n",
    "        'direction_similarity': direction_similarity,\n",
    "        'rotation_alignment': rotation_alignment,\n",
    "\n",
    "        'input_joy': input_joy,\n",
    "    }\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517ec57-16da-4789-a76f-2c77998e7a5e",
   "metadata": {},
   "source": [
    "## Ray 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df31cbbe-264f-4298-a2f1-471cf823d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 10:50:52,501\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://10.130.6.78:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c78575737d44daa77b59cf0984fae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.12.9</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.39.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.130.6.78:8265\" target=\"_blank\">http://10.130.6.78:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='10.130.6.78:8265', python_version='3.12.9', ray_version='2.39.0', ray_commit='5a6c33536df3f6ed5e987a169b82739bb7e3d80e')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407944-23a9-42b0-854b-c19f1c43bcdc",
   "metadata": {},
   "source": [
    "## Gym 환경 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6809e905-5daf-45c4-919f-98e53d97572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"gait_sampling_interval\": 0.01,\n",
    "    \"forward_reward_weight\": 200.0,\n",
    "    \"rotation_reward_weight\": 100.0,\n",
    "    \"unhealthy_max_steps\": 80.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-30,30),\n",
    "    \"terminating_roll_range\": (-80,80),\n",
    "    \"rotation_norm_cost_weight\": 8.0,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 0.05,\n",
    "}\n",
    "\n",
    "render_env_config = {\n",
    "    \"forward_reward_weight\": 60.0,\n",
    "    \"rotation_reward_weight\": 40.0,\n",
    "    \"unhealthy_max_steps\": 100.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-35,35),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 1.5,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"render_mode\": \"rgb_array\",\n",
    "    \"render_camera_name\": 'ceiling',\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 1.5,\n",
    "}\n",
    "\n",
    "# env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     rotation_reward_weight=env_config[\"rotation_reward_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                     use_imu_window=env_config[\"use_imu_window\"],\n",
    "                                                     ctrl_cost_weight=env_config[\"ctrl_cost_weight\"],\n",
    "                                                   )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf2134-3167-46f1-b28b-7d305065f559",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 설정하기 PPO\n",
    "+ 신형 API 구조 사용해보기 (get_policy() 메서드 오류 생김... 추론 못함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436edebc-bcaa-45fa-9941-58ad2868655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ray.rllib.core.rl_module import RLModuleSpec\n",
    "# from ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module import (\n",
    "#     PPOTorchRLModule\n",
    "# )\n",
    "\n",
    "# from ray.rllib.examples.rl_modules.classes.lstm_containing_rlm import (\n",
    "#     LSTMContainingRLModule,\n",
    "# )\n",
    "# from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "\n",
    "# config = PPOConfig()\n",
    "\n",
    "# # 구형 API 구조 사용\n",
    "# config.api_stack(\n",
    "#     enable_rl_module_and_learner=True,\n",
    "#     enable_env_runner_and_connector_v2=True,\n",
    "# )\n",
    "\n",
    "# config.environment(\"joy-v1\")\n",
    "# config.framework(\"torch\")\n",
    "\n",
    "# # 병렬 CPU 사용 설정\n",
    "# total_workers = 16\n",
    "# config.learners(num_learners = 1, num_gpus_per_learner=1)\n",
    "# config.env_runners(num_env_runners = total_workers, num_cpus_per_env_runner = 1, rollout_fragment_length = 'auto')\n",
    "# config.rl_module(\n",
    "#     rl_module_spec=RLModuleSpec(\n",
    "#         module_class=LSTMContainingRLModule,\n",
    "#         learner_only=False,\n",
    "#         inference_only=False,\n",
    "#     ),\n",
    "#     model_config = DefaultModelConfig(\n",
    "#         fcnet_hiddens=[512, 512, 512, 512, 512, 512],\n",
    "#         fcnet_activation=\"swish\",\n",
    "#         use_lstm=True,\n",
    "#         max_seq_len=100,\n",
    "#         lstm_use_prev_action=True,\n",
    "#         lstm_cell_size=256,\n",
    "#     ),\n",
    "# )\n",
    "# config.training(\n",
    "#     # Default config sets\n",
    "#     gamma=0.95,\n",
    "#     lr=0.0001,\n",
    "#     train_batch_size_per_learner = 100000,\n",
    "#     minibatch_size = 5000,\n",
    "#     num_epochs = 10,\n",
    "#     shuffle_batch_per_epoch = False,\n",
    "\n",
    "#     # PPO config sets\n",
    "#     entropy_coeff = 0.01,\n",
    "#     vf_loss_coeff = 0.5, #이 값 튜닝 진행해야함. (기본값 : 1.0)\n",
    "#     vf_clip_param = 5,\n",
    "# )\n",
    "\n",
    "# algo = config.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08a3de",
   "metadata": {},
   "source": [
    "+ 학습 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff56cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = Algorithm.from_checkpoint('learned_policy/PPO_OldAPI_LSTM_328_22')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d102417",
   "metadata": {},
   "source": [
    "+ 구형 API 사용해서 구현\n",
    "RNN 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c7d27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PPOConfig()\n",
    "\n",
    "# 구형 API 구조 사용\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "\n",
    "config.environment(\"joy-v1\")\n",
    "config.framework(\"torch\")\n",
    "config.resources(\n",
    "    num_gpus=0,\n",
    "    num_gpus_per_learner_worker=1,\n",
    ")\n",
    "\n",
    "# 병렬 CPU 사용 설정\n",
    "total_workers = 16\n",
    "# config.learners(num_learners = 1, num_gpus_per_learner=1)\n",
    "config.env_runners(num_env_runners = total_workers, num_cpus_per_env_runner = 1, rollout_fragment_length = 'auto')\n",
    "\n",
    "config.training(\n",
    "    # Default config sets\n",
    "    gamma=0.95,\n",
    "    lr=0.0001,\n",
    "    train_batch_size = 100000,\n",
    "    minibatch_size = 5000,\n",
    "    num_epochs = 10,\n",
    "    shuffle_batch_per_epoch = False,\n",
    "    model = {\n",
    "        \"fcnet_hiddens\": [512, 512, 512, 512, 512, 512],\n",
    "        \"fcnet_activation\": \"relu\",\n",
    "        # \"post_fcnet_hiddens\": [],\n",
    "        # \"post_fcnet_activation\": \"tanh\",\n",
    "        \"use_lstm\": True,\n",
    "        \"max_seq_len\": 100,\n",
    "        \"lstm_use_prev_action\": True,\n",
    "        \"lstm_cell_size\": 256,\n",
    "\n",
    "        # \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "        # \"custom_model_config\": {},\n",
    "    },\n",
    "\n",
    "    # PPO config sets\n",
    "    entropy_coeff = 0.01,\n",
    "    vf_loss_coeff = 0.5, #이 값 튜닝 진행해야함. (기본값 : 1.0)\n",
    "    vf_clip_param = 5,\n",
    ")\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dfe669f",
   "metadata": {},
   "source": [
    "+ RNN 미사용 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6beae10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:567: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-04-01 10:51:31,226\tINFO trainable.py:161 -- Trainable.setup took 12.605 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = PPOConfig()\n",
    "\n",
    "# 구형 API 구조 사용\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "\n",
    "config.environment(\"joy-v1\")\n",
    "config.framework(\"torch\")\n",
    "config.resources(\n",
    "    num_cpus_for_main_process=8,\n",
    "    num_gpus=1,\n",
    "    # num_learner_workers=1,\n",
    "    # num_gpus_per_learner_worker=1,\n",
    ")\n",
    "\n",
    "config.learners(\n",
    "    num_learners=0,\n",
    "    num_gpus_per_learner=1,\n",
    ")\n",
    "\n",
    "# 병렬 CPU 사용 설정\n",
    "total_workers = 16\n",
    "config.env_runners(num_env_runners = total_workers, num_cpus_per_env_runner = 1, rollout_fragment_length = 'auto')\n",
    "\n",
    "config.training(\n",
    "    # Default config sets\n",
    "    gamma=0.95,\n",
    "    lr=0.0005,\n",
    "    train_batch_size = 100000,\n",
    "    minibatch_size = 10000,\n",
    "    num_epochs = 10,\n",
    "    shuffle_batch_per_epoch = False,\n",
    "    model = {\n",
    "        \"fcnet_hiddens\": [512, 512, 512, 512, 512, 512],\n",
    "        \"fcnet_activation\": \"swish\",\n",
    "        # \"post_fcnet_hiddens\": [],\n",
    "        # \"post_fcnet_activation\": \"tanh\",\n",
    "\n",
    "        # \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "        # \"custom_model_config\": {},\n",
    "    },\n",
    "\n",
    "    # PPO config sets\n",
    "    entropy_coeff = 0.01,\n",
    "    vf_loss_coeff = 0.7, #이 값 튜닝 진행해야함. (기본값 : 1.0)\n",
    "    vf_clip_param = 7,\n",
    ")\n",
    "\n",
    "algo = config.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefac126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# pprint(algo.get_config().to_dict())\n",
    "# algo.get_default_policy_class(config).\n",
    "# algo.get_module()\n",
    "\n",
    "# algo.get_config().to_dict()\n",
    "# algo.get_module().get_initial_state()\n",
    "# algo.get_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae756f-bb08-4813-bf07-c019392dac99",
   "metadata": {},
   "source": [
    "## 학습시작\n",
    "+ 구형 API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ae0dfe-e461-442b-b090-cc437723543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 10:52:26,623\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_0), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(0.19999999999999996), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.672675509452819), 'policy_loss': np.float64(-0.022623396011185834), 'vf_loss': np.float64(6.98863534450531), 'vf_explained_var': np.float64(-0.0009770852327346802), 'kl': np.float64(0.0141537233733834), 'entropy': np.float64(19.957668323516845), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(50.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'env_runners': {'episode_reward_max': np.float64(-68274.7263848908), 'episode_reward_min': np.float64(-97009.49718764158), 'episode_reward_mean': np.float64(-82511.57512591072), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 96000, 'policy_reward_min': {'default_policy': np.float64(-97009.49718764158)}, 'policy_reward_max': {'default_policy': np.float64(-68274.7263848908)}, 'policy_reward_mean': {'default_policy': np.float64(-82511.57512591072)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-80557.10919543146), np.float64(-80530.7483839264), np.float64(-85496.30704537108), np.float64(-94473.213896222), np.float64(-82155.14433480585), np.float64(-84490.19292430258), np.float64(-71341.47264341898), np.float64(-76030.89466928408), np.float64(-88685.22319725835), np.float64(-81252.52061360136), np.float64(-68274.7263848908), np.float64(-75929.573877765), np.float64(-85170.28945283458), np.float64(-97009.49718764158), np.float64(-83528.86716999316), np.float64(-85259.4210378242)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-80557.10919543146), np.float64(-80530.7483839264), np.float64(-85496.30704537108), np.float64(-94473.213896222), np.float64(-82155.14433480585), np.float64(-84490.19292430258), np.float64(-71341.47264341898), np.float64(-76030.89466928408), np.float64(-88685.22319725835), np.float64(-81252.52061360136), np.float64(-68274.7263848908), np.float64(-75929.573877765), np.float64(-85170.28945283458), np.float64(-97009.49718764158), np.float64(-83528.86716999316), np.float64(-85259.4210378242)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3297613456027638), 'mean_inference_ms': np.float64(4.409885670142906), 'mean_action_processing_ms': np.float64(0.23650170001882953), 'mean_env_wait_ms': np.float64(1.865314116212506), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.00982135534286499), 'StateBufferConnector_ms': np.float64(0.0041678547859191895), 'ViewRequirementAgentConnector_ms': np.float64(0.11275112628936768)}, 'num_episodes': 16, 'episode_return_max': np.float64(-68274.7263848908), 'episode_return_min': np.float64(-97009.49718764158), 'episode_return_mean': np.float64(-82511.57512591072), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000, 'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1949.5212296863363, 'num_env_steps_trained_throughput_per_sec': 1949.5212296863363, 'timesteps_total': 100000, 'num_env_steps_sampled_lifetime': 100000, 'num_agent_steps_sampled_lifetime': 100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 100000, 'timers': {'training_iteration_time_ms': 51294.656, 'restore_workers_time_ms': 0.021, 'training_step_time_ms': 51294.588, 'sample_time_ms': 49550.993, 'load_time_ms': 24.576, 'load_throughput': 4069058.383, 'learn_time_ms': 1683.128, 'learn_throughput': 59413.2, 'synch_weights_time_ms': 34.37}, 'counters': {'num_env_steps_sampled': 100000, 'num_env_steps_trained': 100000, 'num_agent_steps_sampled': 100000, 'num_agent_steps_trained': 100000}, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2025-04-01_10-52-28', 'timestamp': 1743472348, 'time_this_iter_s': 51.30381202697754, 'time_total_s': 51.30381202697754, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 51.30381202697754, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': np.float64(62.88354430379747), 'ram_util_percent': np.float64(40.61012658227848), 'gpu_util_percent0': np.float64(0.3034177215189873), 'vram_util_percent0': np.float64(0.059872140361286935)}})\n",
      "001, 002, 003, 004, 005, 006, 007, 008, 009, 010, 011, 012, 013, 014, 015, 016, 017, 018, 019, 020, 021, 022, 023, 024, 025, 026, 027, 028, 029, 030, 031, 032, 033, 034, 035, 036, 037, 038, 039, 040, 041, 042, 043, 044, 045, 046, 047, 048, 049, 050, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_1), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(3.4171875), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.56384663105011), 'policy_loss': np.float64(-0.17291955873428377), 'vf_loss': np.float64(6.996112055778504), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.013728971880680093), 'entropy': np.float64(20.74267967224121), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(5050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 5100000, 'num_env_steps_trained': 5100000, 'num_agent_steps_sampled': 5100000, 'num_agent_steps_trained': 5100000}, 'env_runners': {'episode_reward_max': np.float64(-48850.0362380339), 'episode_reward_min': np.float64(-103301.33837726027), 'episode_reward_mean': np.float64(-83343.01993919659), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-103301.33837726027)}, 'policy_reward_max': {'default_policy': np.float64(-48850.0362380339)}, 'policy_reward_mean': {'default_policy': np.float64(-83343.01993919659)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-103301.33837726027), np.float64(-94753.09840923478), np.float64(-69926.1468942584), np.float64(-93364.4391630157), np.float64(-62075.11913928285), np.float64(-80508.24990021173), np.float64(-102526.91211775046), np.float64(-97655.27539629069), np.float64(-102602.68568870965), np.float64(-50183.851391899254), np.float64(-76481.49278138166), np.float64(-79598.50060603768), np.float64(-82364.52203198109), np.float64(-90442.71475702347), np.float64(-99602.37843757881), np.float64(-82454.73130687609), np.float64(-79908.54915637757), np.float64(-99586.74297917531), np.float64(-82524.272048411), np.float64(-59556.55135224093), np.float64(-96648.5994628054), np.float64(-73939.86519056046), np.float64(-100007.71892337257), np.float64(-88799.679870983), np.float64(-73360.67539871903), np.float64(-78426.81036222396), np.float64(-96543.35287290317), np.float64(-95599.45091795095), np.float64(-73660.34906398282), np.float64(-100844.77014287488), np.float64(-71783.16841589646), np.float64(-87396.87579555175), np.float64(-90704.34848195998), np.float64(-84373.57215593087), np.float64(-101641.09582985475), np.float64(-68825.58226011717), np.float64(-82443.9895615702), np.float64(-93417.10287447619), np.float64(-70100.38177100188), np.float64(-79672.53060667872), np.float64(-94037.87454537374), np.float64(-97889.89258611163), np.float64(-100773.44745268459), np.float64(-99143.18908778814), np.float64(-95051.8353925563), np.float64(-81993.17335908239), np.float64(-101179.39016308502), np.float64(-90851.49931922082), np.float64(-101868.43609838313), np.float64(-102233.01307069745), np.float64(-71040.06001667395), np.float64(-98772.25683404172), np.float64(-100316.52233905929), np.float64(-62962.763354056864), np.float64(-93691.33676015242), np.float64(-99410.00859451598), np.float64(-98189.43867823062), np.float64(-75954.57918530819), np.float64(-66361.59916783586), np.float64(-91990.7877075368), np.float64(-80118.85925244085), np.float64(-85373.2820516964), np.float64(-78815.93877523438), np.float64(-65227.324795974644), np.float64(-81634.96323966334), np.float64(-85232.9505125983), np.float64(-54666.82353751679), np.float64(-73204.46909322796), np.float64(-59418.67728661179), np.float64(-72277.17134465104), np.float64(-91607.8850778187), np.float64(-81209.80926371831), np.float64(-73430.54854710681), np.float64(-61276.015779964444), np.float64(-99277.86546558166), np.float64(-89806.01291757454), np.float64(-100232.59506237115), np.float64(-88048.62225241336), np.float64(-84685.32885918535), np.float64(-74562.58423033693), np.float64(-63519.18733465268), np.float64(-88889.24539218971), np.float64(-49313.78699594458), np.float64(-75530.41299050325), np.float64(-62087.28155189351), np.float64(-48850.0362380339), np.float64(-92440.26219707157), np.float64(-75763.06514242165), np.float64(-55527.89865360091), np.float64(-75779.05543765104), np.float64(-90451.07483826242), np.float64(-81343.91201472314), np.float64(-82096.50705582427), np.float64(-81424.56722265981), np.float64(-87473.46903379237), np.float64(-90146.7520886993), np.float64(-88337.49893718892), np.float64(-72407.46974417169), np.float64(-77144.02183282893), np.float64(-94350.16626505212)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-103301.33837726027), np.float64(-94753.09840923478), np.float64(-69926.1468942584), np.float64(-93364.4391630157), np.float64(-62075.11913928285), np.float64(-80508.24990021173), np.float64(-102526.91211775046), np.float64(-97655.27539629069), np.float64(-102602.68568870965), np.float64(-50183.851391899254), np.float64(-76481.49278138166), np.float64(-79598.50060603768), np.float64(-82364.52203198109), np.float64(-90442.71475702347), np.float64(-99602.37843757881), np.float64(-82454.73130687609), np.float64(-79908.54915637757), np.float64(-99586.74297917531), np.float64(-82524.272048411), np.float64(-59556.55135224093), np.float64(-96648.5994628054), np.float64(-73939.86519056046), np.float64(-100007.71892337257), np.float64(-88799.679870983), np.float64(-73360.67539871903), np.float64(-78426.81036222396), np.float64(-96543.35287290317), np.float64(-95599.45091795095), np.float64(-73660.34906398282), np.float64(-100844.77014287488), np.float64(-71783.16841589646), np.float64(-87396.87579555175), np.float64(-90704.34848195998), np.float64(-84373.57215593087), np.float64(-101641.09582985475), np.float64(-68825.58226011717), np.float64(-82443.9895615702), np.float64(-93417.10287447619), np.float64(-70100.38177100188), np.float64(-79672.53060667872), np.float64(-94037.87454537374), np.float64(-97889.89258611163), np.float64(-100773.44745268459), np.float64(-99143.18908778814), np.float64(-95051.8353925563), np.float64(-81993.17335908239), np.float64(-101179.39016308502), np.float64(-90851.49931922082), np.float64(-101868.43609838313), np.float64(-102233.01307069745), np.float64(-71040.06001667395), np.float64(-98772.25683404172), np.float64(-100316.52233905929), np.float64(-62962.763354056864), np.float64(-93691.33676015242), np.float64(-99410.00859451598), np.float64(-98189.43867823062), np.float64(-75954.57918530819), np.float64(-66361.59916783586), np.float64(-91990.7877075368), np.float64(-80118.85925244085), np.float64(-85373.2820516964), np.float64(-78815.93877523438), np.float64(-65227.324795974644), np.float64(-81634.96323966334), np.float64(-85232.9505125983), np.float64(-54666.82353751679), np.float64(-73204.46909322796), np.float64(-59418.67728661179), np.float64(-72277.17134465104), np.float64(-91607.8850778187), np.float64(-81209.80926371831), np.float64(-73430.54854710681), np.float64(-61276.015779964444), np.float64(-99277.86546558166), np.float64(-89806.01291757454), np.float64(-100232.59506237115), np.float64(-88048.62225241336), np.float64(-84685.32885918535), np.float64(-74562.58423033693), np.float64(-63519.18733465268), np.float64(-88889.24539218971), np.float64(-49313.78699594458), np.float64(-75530.41299050325), np.float64(-62087.28155189351), np.float64(-48850.0362380339), np.float64(-92440.26219707157), np.float64(-75763.06514242165), np.float64(-55527.89865360091), np.float64(-75779.05543765104), np.float64(-90451.07483826242), np.float64(-81343.91201472314), np.float64(-82096.50705582427), np.float64(-81424.56722265981), np.float64(-87473.46903379237), np.float64(-90146.7520886993), np.float64(-88337.49893718892), np.float64(-72407.46974417169), np.float64(-77144.02183282893), np.float64(-94350.16626505212)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3467701444236236), 'mean_inference_ms': np.float64(4.11658471751009), 'mean_action_processing_ms': np.float64(0.22642112183476218), 'mean_env_wait_ms': np.float64(1.7991133632204552), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.006929636001586914), 'StateBufferConnector_ms': np.float64(0.004898786544799805), 'ViewRequirementAgentConnector_ms': np.float64(0.12875008583068848)}, 'num_episodes': 16, 'episode_return_max': np.float64(-48850.0362380339), 'episode_return_min': np.float64(-103301.33837726027), 'episode_return_mean': np.float64(-83343.01993919659), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 5100000, 'num_agent_steps_trained': 5100000, 'num_env_steps_sampled': 5100000, 'num_env_steps_trained': 5100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2054.581714077553, 'num_env_steps_trained_throughput_per_sec': 2054.581714077553, 'timesteps_total': 5100000, 'num_env_steps_sampled_lifetime': 5100000, 'num_agent_steps_sampled_lifetime': 5100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 5100000, 'timers': {'training_iteration_time_ms': 48777.874, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48777.843, 'sample_time_ms': 47152.421, 'load_time_ms': 160.979, 'load_throughput': 621197.349, 'learn_time_ms': 1442.634, 'learn_throughput': 69317.661, 'synch_weights_time_ms': 20.565}, 'counters': {'num_env_steps_sampled': 5100000, 'num_env_steps_trained': 5100000, 'num_agent_steps_sampled': 5100000, 'num_agent_steps_trained': 5100000}, 'done': False, 'training_iteration': 51, 'trial_id': 'default', 'date': '2025-04-01_11-33-58', 'timestamp': 1743474838, 'time_this_iter_s': 48.68518805503845, 'time_total_s': 2500.0888278484344, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2500.0888278484344, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': np.float64(64.13636363636364), 'ram_util_percent': np.float64(59.90454545454545), 'gpu_util_percent0': np.float64(0.27424242424242423), 'vram_util_percent0': np.float64(0.11171653053977272)}})\n",
      "051, 052, 053, 054, 055, 056, 057, 058, 059, 060, 061, 062, 063, 064, 065, 066, 067, 068, 069, 070, 071, 072, 073, 074, 075, 076, 077, 078, 079, 080, 081, 082, 083, 084, 085, 086, 087, 088, 089, 090, 091, 092, 093, 094, 095, 096, 097, 098, 099, 100, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_2), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.57054343700409), 'policy_loss': np.float64(-0.1630107680465153), 'vf_loss': np.float64(7.0), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.010511875384231643), 'entropy': np.float64(22.032734947204588), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(10050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 10100000, 'num_env_steps_trained': 10100000, 'num_agent_steps_sampled': 10100000, 'num_agent_steps_trained': 10100000}, 'env_runners': {'episode_reward_max': np.float64(-48390.30147088126), 'episode_reward_min': np.float64(-102437.79467543034), 'episode_reward_mean': np.float64(-78436.33355584899), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-102437.79467543034)}, 'policy_reward_max': {'default_policy': np.float64(-48390.30147088126)}, 'policy_reward_mean': {'default_policy': np.float64(-78436.33355584899)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-57402.68534704239), np.float64(-48460.42245876552), np.float64(-75859.47626225656), np.float64(-60006.26682065879), np.float64(-95581.15022418997), np.float64(-85340.48966982125), np.float64(-83728.59304010028), np.float64(-75599.30649562368), np.float64(-56116.245533383924), np.float64(-86420.09476225582), np.float64(-87905.80532078551), np.float64(-93817.38027150284), np.float64(-73810.27142781274), np.float64(-97032.11184697023), np.float64(-92743.61558847086), np.float64(-59876.43883900831), np.float64(-63213.0947038437), np.float64(-51601.86295186562), np.float64(-99326.7006729805), np.float64(-88969.47846185195), np.float64(-89476.12216168587), np.float64(-86534.173884091), np.float64(-89775.74181491998), np.float64(-97913.28875148173), np.float64(-89384.08357590013), np.float64(-48390.30147088126), np.float64(-75894.52449050422), np.float64(-50005.85892409257), np.float64(-57153.9168330767), np.float64(-59043.18316481396), np.float64(-56224.87767060207), np.float64(-99693.37617649845), np.float64(-83474.10001787271), np.float64(-99271.86341562647), np.float64(-72612.39189535168), np.float64(-83167.21771298537), np.float64(-93649.42842382062), np.float64(-88832.25645727289), np.float64(-90455.62207843724), np.float64(-65149.10522216769), np.float64(-58071.34660438004), np.float64(-63644.57724175044), np.float64(-65870.86994352871), np.float64(-95063.63271970765), np.float64(-63780.53944157464), np.float64(-84344.94893419271), np.float64(-87208.42825451984), np.float64(-94461.13283372282), np.float64(-101504.1274410428), np.float64(-80164.28680264959), np.float64(-101569.61114950167), np.float64(-64861.63624716834), np.float64(-70862.37164259132), np.float64(-78962.6478304627), np.float64(-98692.06553434343), np.float64(-92124.28639117579), np.float64(-70166.29521954285), np.float64(-60236.589364778214), np.float64(-78286.35218513239), np.float64(-60413.23952254855), np.float64(-96680.85766228479), np.float64(-102437.79467543034), np.float64(-65294.00284109806), np.float64(-85284.3392219526), np.float64(-90756.20247490815), np.float64(-93963.82774135491), np.float64(-67893.42973720572), np.float64(-68762.78455133665), np.float64(-62460.81355963267), np.float64(-94935.57854543919), np.float64(-81748.21603933508), np.float64(-93463.43176149685), np.float64(-100508.05449407664), np.float64(-60680.669556056106), np.float64(-102083.3793727714), np.float64(-59949.540994949144), np.float64(-98852.90038717199), np.float64(-58770.20294501181), np.float64(-101561.25620890179), np.float64(-60484.975085725775), np.float64(-93406.42757112432), np.float64(-77054.88151500044), np.float64(-75932.96868692448), np.float64(-65430.89190098636), np.float64(-87274.75040828435), np.float64(-73481.45550190484), np.float64(-97827.31386682951), np.float64(-60920.22014232478), np.float64(-53712.18331230442), np.float64(-88351.12062862114), np.float64(-72493.57689206176), np.float64(-74190.60225588785), np.float64(-62145.38243864651), np.float64(-52508.67181906764), np.float64(-83932.96682054045), np.float64(-60452.74210666351), np.float64(-99323.82905695854), np.float64(-82426.18296215433), np.float64(-76013.10640877705), np.float64(-80979.91328810953)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-57402.68534704239), np.float64(-48460.42245876552), np.float64(-75859.47626225656), np.float64(-60006.26682065879), np.float64(-95581.15022418997), np.float64(-85340.48966982125), np.float64(-83728.59304010028), np.float64(-75599.30649562368), np.float64(-56116.245533383924), np.float64(-86420.09476225582), np.float64(-87905.80532078551), np.float64(-93817.38027150284), np.float64(-73810.27142781274), np.float64(-97032.11184697023), np.float64(-92743.61558847086), np.float64(-59876.43883900831), np.float64(-63213.0947038437), np.float64(-51601.86295186562), np.float64(-99326.7006729805), np.float64(-88969.47846185195), np.float64(-89476.12216168587), np.float64(-86534.173884091), np.float64(-89775.74181491998), np.float64(-97913.28875148173), np.float64(-89384.08357590013), np.float64(-48390.30147088126), np.float64(-75894.52449050422), np.float64(-50005.85892409257), np.float64(-57153.9168330767), np.float64(-59043.18316481396), np.float64(-56224.87767060207), np.float64(-99693.37617649845), np.float64(-83474.10001787271), np.float64(-99271.86341562647), np.float64(-72612.39189535168), np.float64(-83167.21771298537), np.float64(-93649.42842382062), np.float64(-88832.25645727289), np.float64(-90455.62207843724), np.float64(-65149.10522216769), np.float64(-58071.34660438004), np.float64(-63644.57724175044), np.float64(-65870.86994352871), np.float64(-95063.63271970765), np.float64(-63780.53944157464), np.float64(-84344.94893419271), np.float64(-87208.42825451984), np.float64(-94461.13283372282), np.float64(-101504.1274410428), np.float64(-80164.28680264959), np.float64(-101569.61114950167), np.float64(-64861.63624716834), np.float64(-70862.37164259132), np.float64(-78962.6478304627), np.float64(-98692.06553434343), np.float64(-92124.28639117579), np.float64(-70166.29521954285), np.float64(-60236.589364778214), np.float64(-78286.35218513239), np.float64(-60413.23952254855), np.float64(-96680.85766228479), np.float64(-102437.79467543034), np.float64(-65294.00284109806), np.float64(-85284.3392219526), np.float64(-90756.20247490815), np.float64(-93963.82774135491), np.float64(-67893.42973720572), np.float64(-68762.78455133665), np.float64(-62460.81355963267), np.float64(-94935.57854543919), np.float64(-81748.21603933508), np.float64(-93463.43176149685), np.float64(-100508.05449407664), np.float64(-60680.669556056106), np.float64(-102083.3793727714), np.float64(-59949.540994949144), np.float64(-98852.90038717199), np.float64(-58770.20294501181), np.float64(-101561.25620890179), np.float64(-60484.975085725775), np.float64(-93406.42757112432), np.float64(-77054.88151500044), np.float64(-75932.96868692448), np.float64(-65430.89190098636), np.float64(-87274.75040828435), np.float64(-73481.45550190484), np.float64(-97827.31386682951), np.float64(-60920.22014232478), np.float64(-53712.18331230442), np.float64(-88351.12062862114), np.float64(-72493.57689206176), np.float64(-74190.60225588785), np.float64(-62145.38243864651), np.float64(-52508.67181906764), np.float64(-83932.96682054045), np.float64(-60452.74210666351), np.float64(-99323.82905695854), np.float64(-82426.18296215433), np.float64(-76013.10640877705), np.float64(-80979.91328810953)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3448921149339404), 'mean_inference_ms': np.float64(4.096850814926692), 'mean_action_processing_ms': np.float64(0.22566361152750403), 'mean_env_wait_ms': np.float64(1.7909487559850858), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.008661746978759766), 'StateBufferConnector_ms': np.float64(0.004594326019287109), 'ViewRequirementAgentConnector_ms': np.float64(0.12094354629516602)}, 'num_episodes': 16, 'episode_return_max': np.float64(-48390.30147088126), 'episode_return_min': np.float64(-102437.79467543034), 'episode_return_mean': np.float64(-78436.33355584899), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 10100000, 'num_agent_steps_trained': 10100000, 'num_env_steps_sampled': 10100000, 'num_env_steps_trained': 10100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2071.5339200403587, 'num_env_steps_trained_throughput_per_sec': 2071.5339200403587, 'timesteps_total': 10100000, 'num_env_steps_sampled_lifetime': 10100000, 'num_agent_steps_sampled_lifetime': 10100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 10100000, 'timers': {'training_iteration_time_ms': 48662.896, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48662.867, 'sample_time_ms': 47037.078, 'load_time_ms': 163.97, 'load_throughput': 609867.505, 'learn_time_ms': 1440.558, 'learn_throughput': 69417.544, 'synch_weights_time_ms': 20.395}, 'counters': {'num_env_steps_sampled': 10100000, 'num_env_steps_trained': 10100000, 'num_agent_steps_sampled': 10100000, 'num_agent_steps_trained': 10100000}, 'done': False, 'training_iteration': 101, 'trial_id': 'default', 'date': '2025-04-01_12-15-11', 'timestamp': 1743477311, 'time_this_iter_s': 48.28566932678223, 'time_total_s': 4936.7883286476135, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 4936.7883286476135, 'iterations_since_restore': 101, 'perf': {'cpu_util_percent': np.float64(64.80923076923078), 'ram_util_percent': np.float64(59.94153846153846), 'gpu_util_percent0': np.float64(0.2678461538461539), 'vram_util_percent0': np.float64(0.11066644130608974)}})\n",
      "101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_3), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.565304689407348), 'policy_loss': np.float64(-0.17183137766784057), 'vf_loss': np.float64(7.0), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.012432549548409498), 'entropy': np.float64(22.659043006896972), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(15050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 15100000, 'num_env_steps_trained': 15100000, 'num_agent_steps_sampled': 15100000, 'num_agent_steps_trained': 15100000}, 'env_runners': {'episode_reward_max': np.float64(-52387.031022050534), 'episode_reward_min': np.float64(-104337.82694058561), 'episode_reward_mean': np.float64(-78225.52627374204), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-104337.82694058561)}, 'policy_reward_max': {'default_policy': np.float64(-52387.031022050534)}, 'policy_reward_mean': {'default_policy': np.float64(-78225.52627374204)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-59989.56738069965), np.float64(-100703.49137023612), np.float64(-71001.96981907304), np.float64(-91435.60763361977), np.float64(-59054.96650751383), np.float64(-57083.60989886918), np.float64(-65514.418711061466), np.float64(-104337.82694058561), np.float64(-68979.663485513), np.float64(-81641.49813513484), np.float64(-56685.211305072895), np.float64(-85530.7927786349), np.float64(-59925.79180475346), np.float64(-75203.70366763762), np.float64(-72081.24488624005), np.float64(-75280.05335634304), np.float64(-70420.12554070844), np.float64(-91550.20585752114), np.float64(-55050.56589191159), np.float64(-80111.73126739926), np.float64(-93438.06767634962), np.float64(-83324.88060557128), np.float64(-76436.06658461927), np.float64(-54600.00594652996), np.float64(-65004.241230216096), np.float64(-60302.22488435987), np.float64(-92131.05209338093), np.float64(-71862.94506831426), np.float64(-63744.66411359426), np.float64(-93990.9609382989), np.float64(-83654.69202544983), np.float64(-98644.9970652019), np.float64(-79214.91461217872), np.float64(-59702.447018459665), np.float64(-82433.18336486288), np.float64(-67771.38602488945), np.float64(-65455.46649269012), np.float64(-92926.80503778502), np.float64(-85422.64519420675), np.float64(-67282.81134905189), np.float64(-83701.00569756345), np.float64(-60010.120807508414), np.float64(-96965.5745789357), np.float64(-65189.58482073532), np.float64(-78135.74532201467), np.float64(-78930.1667125758), np.float64(-55107.475638407304), np.float64(-86775.41548419125), np.float64(-92229.10343120265), np.float64(-90905.71853637588), np.float64(-78483.11206220373), np.float64(-100382.48481445071), np.float64(-74546.76953822667), np.float64(-89217.45565284303), np.float64(-74201.67410980993), np.float64(-65066.680238158304), np.float64(-98025.58691012242), np.float64(-86909.86077778618), np.float64(-64638.24644903665), np.float64(-96200.53721616337), np.float64(-92779.6264414257), np.float64(-60004.228769955494), np.float64(-98134.0960508659), np.float64(-56149.353681772176), np.float64(-96410.73466313002), np.float64(-70625.62037298232), np.float64(-101091.77591914), np.float64(-84112.78812074396), np.float64(-100945.74578241384), np.float64(-61300.586144913694), np.float64(-97896.63875999137), np.float64(-98878.81586535418), np.float64(-96729.97380799113), np.float64(-52387.031022050534), np.float64(-75984.29850048469), np.float64(-62810.75877086865), np.float64(-74197.17881853646), np.float64(-97766.00116583359), np.float64(-75528.94383764068), np.float64(-87477.17496006507), np.float64(-80364.54353044124), np.float64(-59786.68472664352), np.float64(-56660.1925640736), np.float64(-54815.53798997693), np.float64(-81915.38760176512), np.float64(-81879.15736047708), np.float64(-91536.39461000687), np.float64(-83931.06646156628), np.float64(-61810.04152629745), np.float64(-67988.5777600029), np.float64(-95491.68350907379), np.float64(-93335.3703313435), np.float64(-62365.64466950753), np.float64(-91903.7882475543), np.float64(-70526.08473770862), np.float64(-99801.57039246675), np.float64(-84701.89080986004), np.float64(-64703.553077227785), np.float64(-84290.75273414094), np.float64(-78984.51091506016)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-59989.56738069965), np.float64(-100703.49137023612), np.float64(-71001.96981907304), np.float64(-91435.60763361977), np.float64(-59054.96650751383), np.float64(-57083.60989886918), np.float64(-65514.418711061466), np.float64(-104337.82694058561), np.float64(-68979.663485513), np.float64(-81641.49813513484), np.float64(-56685.211305072895), np.float64(-85530.7927786349), np.float64(-59925.79180475346), np.float64(-75203.70366763762), np.float64(-72081.24488624005), np.float64(-75280.05335634304), np.float64(-70420.12554070844), np.float64(-91550.20585752114), np.float64(-55050.56589191159), np.float64(-80111.73126739926), np.float64(-93438.06767634962), np.float64(-83324.88060557128), np.float64(-76436.06658461927), np.float64(-54600.00594652996), np.float64(-65004.241230216096), np.float64(-60302.22488435987), np.float64(-92131.05209338093), np.float64(-71862.94506831426), np.float64(-63744.66411359426), np.float64(-93990.9609382989), np.float64(-83654.69202544983), np.float64(-98644.9970652019), np.float64(-79214.91461217872), np.float64(-59702.447018459665), np.float64(-82433.18336486288), np.float64(-67771.38602488945), np.float64(-65455.46649269012), np.float64(-92926.80503778502), np.float64(-85422.64519420675), np.float64(-67282.81134905189), np.float64(-83701.00569756345), np.float64(-60010.120807508414), np.float64(-96965.5745789357), np.float64(-65189.58482073532), np.float64(-78135.74532201467), np.float64(-78930.1667125758), np.float64(-55107.475638407304), np.float64(-86775.41548419125), np.float64(-92229.10343120265), np.float64(-90905.71853637588), np.float64(-78483.11206220373), np.float64(-100382.48481445071), np.float64(-74546.76953822667), np.float64(-89217.45565284303), np.float64(-74201.67410980993), np.float64(-65066.680238158304), np.float64(-98025.58691012242), np.float64(-86909.86077778618), np.float64(-64638.24644903665), np.float64(-96200.53721616337), np.float64(-92779.6264414257), np.float64(-60004.228769955494), np.float64(-98134.0960508659), np.float64(-56149.353681772176), np.float64(-96410.73466313002), np.float64(-70625.62037298232), np.float64(-101091.77591914), np.float64(-84112.78812074396), np.float64(-100945.74578241384), np.float64(-61300.586144913694), np.float64(-97896.63875999137), np.float64(-98878.81586535418), np.float64(-96729.97380799113), np.float64(-52387.031022050534), np.float64(-75984.29850048469), np.float64(-62810.75877086865), np.float64(-74197.17881853646), np.float64(-97766.00116583359), np.float64(-75528.94383764068), np.float64(-87477.17496006507), np.float64(-80364.54353044124), np.float64(-59786.68472664352), np.float64(-56660.1925640736), np.float64(-54815.53798997693), np.float64(-81915.38760176512), np.float64(-81879.15736047708), np.float64(-91536.39461000687), np.float64(-83931.06646156628), np.float64(-61810.04152629745), np.float64(-67988.5777600029), np.float64(-95491.68350907379), np.float64(-93335.3703313435), np.float64(-62365.64466950753), np.float64(-91903.7882475543), np.float64(-70526.08473770862), np.float64(-99801.57039246675), np.float64(-84701.89080986004), np.float64(-64703.553077227785), np.float64(-84290.75273414094), np.float64(-78984.51091506016)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.34466817964153096), 'mean_inference_ms': np.float64(4.092324769606651), 'mean_action_processing_ms': np.float64(0.2254131601206389), 'mean_env_wait_ms': np.float64(1.7888257528266371), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0071566104888916016), 'StateBufferConnector_ms': np.float64(0.005002498626708984), 'ViewRequirementAgentConnector_ms': np.float64(0.13195562362670898)}, 'num_episodes': 16, 'episode_return_max': np.float64(-52387.031022050534), 'episode_return_min': np.float64(-104337.82694058561), 'episode_return_mean': np.float64(-78225.52627374204), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 15100000, 'num_agent_steps_trained': 15100000, 'num_env_steps_sampled': 15100000, 'num_env_steps_trained': 15100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2076.6866887862166, 'num_env_steps_trained_throughput_per_sec': 2076.6866887862166, 'timesteps_total': 15100000, 'num_env_steps_sampled_lifetime': 15100000, 'num_agent_steps_sampled_lifetime': 15100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 15100000, 'timers': {'training_iteration_time_ms': 48778.077, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48778.044, 'sample_time_ms': 47152.692, 'load_time_ms': 165.714, 'load_throughput': 603448.182, 'learn_time_ms': 1437.932, 'learn_throughput': 69544.323, 'synch_weights_time_ms': 20.643}, 'counters': {'num_env_steps_sampled': 15100000, 'num_env_steps_trained': 15100000, 'num_agent_steps_sampled': 15100000, 'num_agent_steps_trained': 15100000}, 'done': False, 'training_iteration': 151, 'trial_id': 'default', 'date': '2025-04-01_12-56-27', 'timestamp': 1743479787, 'time_this_iter_s': 48.16435790061951, 'time_total_s': 7376.1352553367615, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 7376.1352553367615, 'iterations_since_restore': 151, 'perf': {'cpu_util_percent': np.float64(64.4676923076923), 'ram_util_percent': np.float64(60.03692307692308), 'gpu_util_percent0': np.float64(0.28307692307692306), 'vram_util_percent0': np.float64(0.11088115985576923)}})\n",
      "151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_4), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.564333777427674), 'policy_loss': np.float64(-0.14825093356805155), 'vf_loss': np.float64(6.997818517684936), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.009976716895192795), 'entropy': np.float64(23.702677898406982), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(20050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 20100000, 'num_env_steps_trained': 20100000, 'num_agent_steps_sampled': 20100000, 'num_agent_steps_trained': 20100000}, 'env_runners': {'episode_reward_max': np.float64(-42428.473549888404), 'episode_reward_min': np.float64(-102659.02123460514), 'episode_reward_mean': np.float64(-78386.68559669294), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-102659.02123460514)}, 'policy_reward_max': {'default_policy': np.float64(-42428.473549888404)}, 'policy_reward_mean': {'default_policy': np.float64(-78386.68559669294)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-85043.95255332185), np.float64(-100790.69206783226), np.float64(-100153.9928751381), np.float64(-60885.94894511234), np.float64(-70074.34647683024), np.float64(-60351.6749870723), np.float64(-72599.81164109411), np.float64(-53595.15969424008), np.float64(-48265.82880062225), np.float64(-76018.69976378107), np.float64(-93471.77566662907), np.float64(-98733.53609388978), np.float64(-57210.90943950021), np.float64(-62329.407183808515), np.float64(-63085.51210857582), np.float64(-72114.84835453918), np.float64(-96559.57749638816), np.float64(-95185.71531642927), np.float64(-94752.31543668521), np.float64(-57067.34123784856), np.float64(-62328.38178732624), np.float64(-68810.46400526697), np.float64(-73043.86160677463), np.float64(-99157.09854933571), np.float64(-95622.37207800467), np.float64(-58100.04291657612), np.float64(-85287.97176378386), np.float64(-86536.45852471172), np.float64(-77186.93762946842), np.float64(-93798.22484368303), np.float64(-61153.40818584954), np.float64(-72603.63607988843), np.float64(-83786.66981943313), np.float64(-99940.8026672233), np.float64(-65609.67721647743), np.float64(-83752.93490089891), np.float64(-91111.12576366669), np.float64(-94023.2039347917), np.float64(-74464.94111190973), np.float64(-99510.50162255873), np.float64(-70090.55868771969), np.float64(-72195.41499729686), np.float64(-84873.90709621353), np.float64(-78849.30808343613), np.float64(-90274.74641273876), np.float64(-68930.95248940817), np.float64(-82375.66587491012), np.float64(-98365.50280691561), np.float64(-83538.34434097278), np.float64(-91847.72782521548), np.float64(-81680.75952771037), np.float64(-94643.53071611543), np.float64(-79164.56577298873), np.float64(-101204.68888752762), np.float64(-97826.21764455823), np.float64(-60075.46885781492), np.float64(-76508.79355917285), np.float64(-85607.78878746904), np.float64(-95543.11229087933), np.float64(-57646.94045812101), np.float64(-94668.9900339848), np.float64(-95010.63728816819), np.float64(-68366.53876659251), np.float64(-72929.77109400337), np.float64(-77841.13059618462), np.float64(-62038.41029633171), np.float64(-89565.14551204657), np.float64(-59239.423213273345), np.float64(-54005.222045091476), np.float64(-98797.56780375536), np.float64(-69611.07298783182), np.float64(-64455.70881306981), np.float64(-102659.02123460514), np.float64(-67598.77669281291), np.float64(-61856.62393301543), np.float64(-65828.91925247527), np.float64(-63752.88279214519), np.float64(-73602.71566737392), np.float64(-82001.67229351739), np.float64(-42428.473549888404), np.float64(-96323.20476222782), np.float64(-94498.16493145812), np.float64(-55310.30130215061), np.float64(-90851.83166139232), np.float64(-62912.154460267775), np.float64(-77134.98552773864), np.float64(-63297.08230911004), np.float64(-90407.55049729183), np.float64(-99308.87206111447), np.float64(-58291.64655585434), np.float64(-79417.0434952722), np.float64(-86296.70204318542), np.float64(-61614.96445432477), np.float64(-63682.08040679002), np.float64(-100720.7208559429), np.float64(-88449.78422920912), np.float64(-57399.38307360662), np.float64(-74543.38969636118), np.float64(-81240.22985900562), np.float64(-95346.007356672)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-85043.95255332185), np.float64(-100790.69206783226), np.float64(-100153.9928751381), np.float64(-60885.94894511234), np.float64(-70074.34647683024), np.float64(-60351.6749870723), np.float64(-72599.81164109411), np.float64(-53595.15969424008), np.float64(-48265.82880062225), np.float64(-76018.69976378107), np.float64(-93471.77566662907), np.float64(-98733.53609388978), np.float64(-57210.90943950021), np.float64(-62329.407183808515), np.float64(-63085.51210857582), np.float64(-72114.84835453918), np.float64(-96559.57749638816), np.float64(-95185.71531642927), np.float64(-94752.31543668521), np.float64(-57067.34123784856), np.float64(-62328.38178732624), np.float64(-68810.46400526697), np.float64(-73043.86160677463), np.float64(-99157.09854933571), np.float64(-95622.37207800467), np.float64(-58100.04291657612), np.float64(-85287.97176378386), np.float64(-86536.45852471172), np.float64(-77186.93762946842), np.float64(-93798.22484368303), np.float64(-61153.40818584954), np.float64(-72603.63607988843), np.float64(-83786.66981943313), np.float64(-99940.8026672233), np.float64(-65609.67721647743), np.float64(-83752.93490089891), np.float64(-91111.12576366669), np.float64(-94023.2039347917), np.float64(-74464.94111190973), np.float64(-99510.50162255873), np.float64(-70090.55868771969), np.float64(-72195.41499729686), np.float64(-84873.90709621353), np.float64(-78849.30808343613), np.float64(-90274.74641273876), np.float64(-68930.95248940817), np.float64(-82375.66587491012), np.float64(-98365.50280691561), np.float64(-83538.34434097278), np.float64(-91847.72782521548), np.float64(-81680.75952771037), np.float64(-94643.53071611543), np.float64(-79164.56577298873), np.float64(-101204.68888752762), np.float64(-97826.21764455823), np.float64(-60075.46885781492), np.float64(-76508.79355917285), np.float64(-85607.78878746904), np.float64(-95543.11229087933), np.float64(-57646.94045812101), np.float64(-94668.9900339848), np.float64(-95010.63728816819), np.float64(-68366.53876659251), np.float64(-72929.77109400337), np.float64(-77841.13059618462), np.float64(-62038.41029633171), np.float64(-89565.14551204657), np.float64(-59239.423213273345), np.float64(-54005.222045091476), np.float64(-98797.56780375536), np.float64(-69611.07298783182), np.float64(-64455.70881306981), np.float64(-102659.02123460514), np.float64(-67598.77669281291), np.float64(-61856.62393301543), np.float64(-65828.91925247527), np.float64(-63752.88279214519), np.float64(-73602.71566737392), np.float64(-82001.67229351739), np.float64(-42428.473549888404), np.float64(-96323.20476222782), np.float64(-94498.16493145812), np.float64(-55310.30130215061), np.float64(-90851.83166139232), np.float64(-62912.154460267775), np.float64(-77134.98552773864), np.float64(-63297.08230911004), np.float64(-90407.55049729183), np.float64(-99308.87206111447), np.float64(-58291.64655585434), np.float64(-79417.0434952722), np.float64(-86296.70204318542), np.float64(-61614.96445432477), np.float64(-63682.08040679002), np.float64(-100720.7208559429), np.float64(-88449.78422920912), np.float64(-57399.38307360662), np.float64(-74543.38969636118), np.float64(-81240.22985900562), np.float64(-95346.007356672)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3447704819923121), 'mean_inference_ms': np.float64(4.089885724256891), 'mean_action_processing_ms': np.float64(0.22536099076644617), 'mean_env_wait_ms': np.float64(1.7881495832566043), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.011171102523803711), 'StateBufferConnector_ms': np.float64(0.0053920745849609375), 'ViewRequirementAgentConnector_ms': np.float64(0.14340710639953613)}, 'num_episodes': 16, 'episode_return_max': np.float64(-42428.473549888404), 'episode_return_min': np.float64(-102659.02123460514), 'episode_return_mean': np.float64(-78386.68559669294), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20100000, 'num_agent_steps_trained': 20100000, 'num_env_steps_sampled': 20100000, 'num_env_steps_trained': 20100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2041.1571303529547, 'num_env_steps_trained_throughput_per_sec': 2041.1571303529547, 'timesteps_total': 20100000, 'num_env_steps_sampled_lifetime': 20100000, 'num_agent_steps_sampled_lifetime': 20100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 20100000, 'timers': {'training_iteration_time_ms': 48903.387, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48903.355, 'sample_time_ms': 47265.823, 'load_time_ms': 167.666, 'load_throughput': 596423.397, 'learn_time_ms': 1447.078, 'learn_throughput': 69104.763, 'synch_weights_time_ms': 21.856}, 'counters': {'num_env_steps_sampled': 20100000, 'num_env_steps_trained': 20100000, 'num_agent_steps_sampled': 20100000, 'num_agent_steps_trained': 20100000}, 'done': False, 'training_iteration': 201, 'trial_id': 'default', 'date': '2025-04-01_13-37-46', 'timestamp': 1743482266, 'time_this_iter_s': 49.00069284439087, 'time_total_s': 9818.709084272385, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 9818.709084272385, 'iterations_since_restore': 201, 'perf': {'cpu_util_percent': np.float64(65.89696969696969), 'ram_util_percent': np.float64(60.02575757575758), 'gpu_util_percent0': np.float64(0.2507575757575758), 'vram_util_percent0': np.float64(0.11532993509311869)}})\n",
      "201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_5), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.507508068084717), 'policy_loss': np.float64(-0.17980825713835658), 'vf_loss': np.float64(6.984763789176941), 'vf_explained_var': np.float64(-0.3650175577402115), 'kl': np.float64(0.01053698487916222), 'entropy': np.float64(25.602868003845217), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(25050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 25100000, 'num_env_steps_trained': 25100000, 'num_agent_steps_sampled': 25100000, 'num_agent_steps_trained': 25100000}, 'env_runners': {'episode_reward_max': np.float64(-52402.12209303555), 'episode_reward_min': np.float64(-102351.12164985394), 'episode_reward_mean': np.float64(-78108.7057405319), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-102351.12164985394)}, 'policy_reward_max': {'default_policy': np.float64(-52402.12209303555)}, 'policy_reward_mean': {'default_policy': np.float64(-78108.7057405319)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-90669.85515012631), np.float64(-93607.12030752597), np.float64(-84297.35811898814), np.float64(-57516.36170686049), np.float64(-97563.66179667893), np.float64(-81585.7056769599), np.float64(-73627.12470815149), np.float64(-89126.929476838), np.float64(-75873.18215879537), np.float64(-82753.58226758776), np.float64(-70494.76847249929), np.float64(-98215.3797496174), np.float64(-84308.8588640342), np.float64(-80457.4333184787), np.float64(-94322.70879159468), np.float64(-61602.66998524436), np.float64(-62128.37363367497), np.float64(-72866.31251899168), np.float64(-93503.78134479756), np.float64(-69480.01740454673), np.float64(-93311.27397790448), np.float64(-91100.6191950405), np.float64(-54756.832598448), np.float64(-87931.16926076166), np.float64(-85159.61582182824), np.float64(-59819.83558049718), np.float64(-84007.1435812078), np.float64(-56093.48208437657), np.float64(-91350.599548864), np.float64(-67007.08042365852), np.float64(-67003.32155011172), np.float64(-102351.12164985394), np.float64(-60760.73336488921), np.float64(-84618.90096500584), np.float64(-58507.079881831494), np.float64(-62515.98796835389), np.float64(-101910.29131381233), np.float64(-70016.40159512161), np.float64(-84260.50296409092), np.float64(-90709.96271524251), np.float64(-93551.61786261396), np.float64(-64033.71929227294), np.float64(-102122.83657853272), np.float64(-82788.52144858254), np.float64(-75272.60682062151), np.float64(-76491.76308228061), np.float64(-80745.76587000131), np.float64(-68948.81487866025), np.float64(-73253.87589287484), np.float64(-55165.10911436978), np.float64(-63580.37490373322), np.float64(-52402.12209303555), np.float64(-79015.9861833841), np.float64(-69610.6333013749), np.float64(-82387.95665399068), np.float64(-93609.36695424591), np.float64(-70689.84941936267), np.float64(-74043.58770201929), np.float64(-88768.23986688034), np.float64(-64791.3618476157), np.float64(-71159.71303333042), np.float64(-79198.96954648732), np.float64(-67389.9978187424), np.float64(-59400.45500657242), np.float64(-66711.41228303252), np.float64(-60131.66243348494), np.float64(-87303.17388181323), np.float64(-61812.50049772301), np.float64(-84811.02615905856), np.float64(-61196.284609447786), np.float64(-86962.04289080025), np.float64(-101635.60431182978), np.float64(-81913.67014200182), np.float64(-57727.83180081016), np.float64(-90511.84529418909), np.float64(-101801.82324006078), np.float64(-67658.08726161245), np.float64(-70609.1261486188), np.float64(-86935.52239717449), np.float64(-85429.15866976681), np.float64(-97305.70054998038), np.float64(-61033.04243993881), np.float64(-69389.64718567692), np.float64(-100872.95660972172), np.float64(-70603.4637001724), np.float64(-90762.31333504494), np.float64(-94008.08240112352), np.float64(-83958.51206062757), np.float64(-66630.52351522198), np.float64(-94946.0203830672), np.float64(-74392.55634241394), np.float64(-64267.12783989667), np.float64(-81871.20910307566), np.float64(-79352.4996025588), np.float64(-65464.467069610386), np.float64(-80630.50642912592), np.float64(-82617.54339516768), np.float64(-93872.10013796347), np.float64(-90258.8662198471), np.float64(-59866.27704705161)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-90669.85515012631), np.float64(-93607.12030752597), np.float64(-84297.35811898814), np.float64(-57516.36170686049), np.float64(-97563.66179667893), np.float64(-81585.7056769599), np.float64(-73627.12470815149), np.float64(-89126.929476838), np.float64(-75873.18215879537), np.float64(-82753.58226758776), np.float64(-70494.76847249929), np.float64(-98215.3797496174), np.float64(-84308.8588640342), np.float64(-80457.4333184787), np.float64(-94322.70879159468), np.float64(-61602.66998524436), np.float64(-62128.37363367497), np.float64(-72866.31251899168), np.float64(-93503.78134479756), np.float64(-69480.01740454673), np.float64(-93311.27397790448), np.float64(-91100.6191950405), np.float64(-54756.832598448), np.float64(-87931.16926076166), np.float64(-85159.61582182824), np.float64(-59819.83558049718), np.float64(-84007.1435812078), np.float64(-56093.48208437657), np.float64(-91350.599548864), np.float64(-67007.08042365852), np.float64(-67003.32155011172), np.float64(-102351.12164985394), np.float64(-60760.73336488921), np.float64(-84618.90096500584), np.float64(-58507.079881831494), np.float64(-62515.98796835389), np.float64(-101910.29131381233), np.float64(-70016.40159512161), np.float64(-84260.50296409092), np.float64(-90709.96271524251), np.float64(-93551.61786261396), np.float64(-64033.71929227294), np.float64(-102122.83657853272), np.float64(-82788.52144858254), np.float64(-75272.60682062151), np.float64(-76491.76308228061), np.float64(-80745.76587000131), np.float64(-68948.81487866025), np.float64(-73253.87589287484), np.float64(-55165.10911436978), np.float64(-63580.37490373322), np.float64(-52402.12209303555), np.float64(-79015.9861833841), np.float64(-69610.6333013749), np.float64(-82387.95665399068), np.float64(-93609.36695424591), np.float64(-70689.84941936267), np.float64(-74043.58770201929), np.float64(-88768.23986688034), np.float64(-64791.3618476157), np.float64(-71159.71303333042), np.float64(-79198.96954648732), np.float64(-67389.9978187424), np.float64(-59400.45500657242), np.float64(-66711.41228303252), np.float64(-60131.66243348494), np.float64(-87303.17388181323), np.float64(-61812.50049772301), np.float64(-84811.02615905856), np.float64(-61196.284609447786), np.float64(-86962.04289080025), np.float64(-101635.60431182978), np.float64(-81913.67014200182), np.float64(-57727.83180081016), np.float64(-90511.84529418909), np.float64(-101801.82324006078), np.float64(-67658.08726161245), np.float64(-70609.1261486188), np.float64(-86935.52239717449), np.float64(-85429.15866976681), np.float64(-97305.70054998038), np.float64(-61033.04243993881), np.float64(-69389.64718567692), np.float64(-100872.95660972172), np.float64(-70603.4637001724), np.float64(-90762.31333504494), np.float64(-94008.08240112352), np.float64(-83958.51206062757), np.float64(-66630.52351522198), np.float64(-94946.0203830672), np.float64(-74392.55634241394), np.float64(-64267.12783989667), np.float64(-81871.20910307566), np.float64(-79352.4996025588), np.float64(-65464.467069610386), np.float64(-80630.50642912592), np.float64(-82617.54339516768), np.float64(-93872.10013796347), np.float64(-90258.8662198471), np.float64(-59866.27704705161)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.34288672100476014), 'mean_inference_ms': np.float64(4.074870536762377), 'mean_action_processing_ms': np.float64(0.22422683050431796), 'mean_env_wait_ms': np.float64(1.7795826646102413), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.0080108642578125), 'StateBufferConnector_ms': np.float64(0.005337238311767578), 'ViewRequirementAgentConnector_ms': np.float64(0.14584851264953613)}, 'num_episodes': 16, 'episode_return_max': np.float64(-52402.12209303555), 'episode_return_min': np.float64(-102351.12164985394), 'episode_return_mean': np.float64(-78108.7057405319), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 25100000, 'num_agent_steps_trained': 25100000, 'num_env_steps_sampled': 25100000, 'num_env_steps_trained': 25100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2081.790375141266, 'num_env_steps_trained_throughput_per_sec': 2081.790375141266, 'timesteps_total': 25100000, 'num_env_steps_sampled_lifetime': 25100000, 'num_agent_steps_sampled_lifetime': 25100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 25100000, 'timers': {'training_iteration_time_ms': 47631.413, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 47631.383, 'sample_time_ms': 46086.335, 'load_time_ms': 169.852, 'load_throughput': 588747.457, 'learn_time_ms': 1353.25, 'learn_throughput': 73896.193, 'synch_weights_time_ms': 20.915}, 'counters': {'num_env_steps_sampled': 25100000, 'num_env_steps_trained': 25100000, 'num_agent_steps_sampled': 25100000, 'num_agent_steps_trained': 25100000}, 'done': False, 'training_iteration': 251, 'trial_id': 'default', 'date': '2025-04-01_14-18-21', 'timestamp': 1743484701, 'time_this_iter_s': 48.04525947570801, 'time_total_s': 12216.802032709122, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 12216.802032709122, 'iterations_since_restore': 251, 'perf': {'cpu_util_percent': np.float64(60.136923076923075), 'ram_util_percent': np.float64(60.761538461538464), 'gpu_util_percent0': np.float64(0.20446153846153847), 'vram_util_percent0': np.float64(0.10294596354166666)}})\n",
      "251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_6), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.498548226356506), 'policy_loss': np.float64(-0.19265941345802276), 'vf_loss': np.float64(6.988794374465942), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.011191610777382266), 'entropy': np.float64(25.831425743103026), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(30050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 30100000, 'num_env_steps_trained': 30100000, 'num_agent_steps_sampled': 30100000, 'num_agent_steps_trained': 30100000}, 'env_runners': {'episode_reward_max': np.float64(-50929.78609263704), 'episode_reward_min': np.float64(-102942.25952561355), 'episode_reward_mean': np.float64(-78480.73881392844), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-102942.25952561355)}, 'policy_reward_max': {'default_policy': np.float64(-50929.78609263704)}, 'policy_reward_mean': {'default_policy': np.float64(-78480.73881392844)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-102521.19425675682), np.float64(-86138.07369282914), np.float64(-95954.34792935725), np.float64(-68423.03262845379), np.float64(-79811.77341458811), np.float64(-58194.55935586075), np.float64(-71213.26272787697), np.float64(-61883.23964900101), np.float64(-98865.29780581009), np.float64(-96074.8939451198), np.float64(-53855.24768135664), np.float64(-60105.725282049156), np.float64(-86992.17201073862), np.float64(-67014.5376958317), np.float64(-98320.75259540943), np.float64(-97693.08556536394), np.float64(-86979.22285483094), np.float64(-88450.42844740995), np.float64(-58937.11265488848), np.float64(-79988.92742677909), np.float64(-87239.22665466563), np.float64(-52139.93601508087), np.float64(-66159.69030577224), np.float64(-58852.793266540444), np.float64(-87943.53297903643), np.float64(-58637.644807728044), np.float64(-93336.59129789517), np.float64(-58263.91886863835), np.float64(-99631.22344467042), np.float64(-81103.48764586015), np.float64(-69171.72017512994), np.float64(-63285.51959491279), np.float64(-77418.74220369865), np.float64(-69753.53401337865), np.float64(-59295.059679215665), np.float64(-97001.11751828415), np.float64(-90982.56995049989), np.float64(-64188.42168566196), np.float64(-90293.5843472903), np.float64(-100964.8832001334), np.float64(-78777.43578301245), np.float64(-94693.56858605653), np.float64(-87070.42656107218), np.float64(-102942.25952561355), np.float64(-82898.43075022924), np.float64(-92010.3847730874), np.float64(-62041.36633537598), np.float64(-94634.98263651029), np.float64(-73714.55164442207), np.float64(-85201.14058123695), np.float64(-75886.85804972633), np.float64(-66172.7826298981), np.float64(-90231.05764701635), np.float64(-70924.77487975694), np.float64(-69040.39000859117), np.float64(-53191.915390058806), np.float64(-61899.080690057825), np.float64(-93810.08577389625), np.float64(-56876.5333904041), np.float64(-90061.87666952655), np.float64(-72823.88768618647), np.float64(-67050.8141759987), np.float64(-64322.11916068395), np.float64(-101883.83884346134), np.float64(-100769.3796645752), np.float64(-89497.46039041069), np.float64(-62526.80101803201), np.float64(-93352.32676541628), np.float64(-87744.23919961278), np.float64(-81427.35213605533), np.float64(-65628.21919016632), np.float64(-99215.68697847656), np.float64(-85105.05420672477), np.float64(-69213.4935655338), np.float64(-59513.67418168804), np.float64(-88001.39608183784), np.float64(-101382.16747421017), np.float64(-99850.97016280857), np.float64(-99790.42797955974), np.float64(-90568.5065212886), np.float64(-94629.34102673786), np.float64(-54760.1929708169), np.float64(-83970.9241660289), np.float64(-69530.37284713467), np.float64(-56948.925691369484), np.float64(-57494.55006075338), np.float64(-63393.30981799007), np.float64(-64490.33304693053), np.float64(-92466.94897855437), np.float64(-55600.475528977906), np.float64(-62650.66314547094), np.float64(-61266.407852197626), np.float64(-97512.2478395017), np.float64(-82300.08291318928), np.float64(-92351.56116075075), np.float64(-80834.6195977816), np.float64(-82195.11229877062), np.float64(-64855.05027591034), np.float64(-95065.17311865899), np.float64(-50929.78609263704)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-102521.19425675682), np.float64(-86138.07369282914), np.float64(-95954.34792935725), np.float64(-68423.03262845379), np.float64(-79811.77341458811), np.float64(-58194.55935586075), np.float64(-71213.26272787697), np.float64(-61883.23964900101), np.float64(-98865.29780581009), np.float64(-96074.8939451198), np.float64(-53855.24768135664), np.float64(-60105.725282049156), np.float64(-86992.17201073862), np.float64(-67014.5376958317), np.float64(-98320.75259540943), np.float64(-97693.08556536394), np.float64(-86979.22285483094), np.float64(-88450.42844740995), np.float64(-58937.11265488848), np.float64(-79988.92742677909), np.float64(-87239.22665466563), np.float64(-52139.93601508087), np.float64(-66159.69030577224), np.float64(-58852.793266540444), np.float64(-87943.53297903643), np.float64(-58637.644807728044), np.float64(-93336.59129789517), np.float64(-58263.91886863835), np.float64(-99631.22344467042), np.float64(-81103.48764586015), np.float64(-69171.72017512994), np.float64(-63285.51959491279), np.float64(-77418.74220369865), np.float64(-69753.53401337865), np.float64(-59295.059679215665), np.float64(-97001.11751828415), np.float64(-90982.56995049989), np.float64(-64188.42168566196), np.float64(-90293.5843472903), np.float64(-100964.8832001334), np.float64(-78777.43578301245), np.float64(-94693.56858605653), np.float64(-87070.42656107218), np.float64(-102942.25952561355), np.float64(-82898.43075022924), np.float64(-92010.3847730874), np.float64(-62041.36633537598), np.float64(-94634.98263651029), np.float64(-73714.55164442207), np.float64(-85201.14058123695), np.float64(-75886.85804972633), np.float64(-66172.7826298981), np.float64(-90231.05764701635), np.float64(-70924.77487975694), np.float64(-69040.39000859117), np.float64(-53191.915390058806), np.float64(-61899.080690057825), np.float64(-93810.08577389625), np.float64(-56876.5333904041), np.float64(-90061.87666952655), np.float64(-72823.88768618647), np.float64(-67050.8141759987), np.float64(-64322.11916068395), np.float64(-101883.83884346134), np.float64(-100769.3796645752), np.float64(-89497.46039041069), np.float64(-62526.80101803201), np.float64(-93352.32676541628), np.float64(-87744.23919961278), np.float64(-81427.35213605533), np.float64(-65628.21919016632), np.float64(-99215.68697847656), np.float64(-85105.05420672477), np.float64(-69213.4935655338), np.float64(-59513.67418168804), np.float64(-88001.39608183784), np.float64(-101382.16747421017), np.float64(-99850.97016280857), np.float64(-99790.42797955974), np.float64(-90568.5065212886), np.float64(-94629.34102673786), np.float64(-54760.1929708169), np.float64(-83970.9241660289), np.float64(-69530.37284713467), np.float64(-56948.925691369484), np.float64(-57494.55006075338), np.float64(-63393.30981799007), np.float64(-64490.33304693053), np.float64(-92466.94897855437), np.float64(-55600.475528977906), np.float64(-62650.66314547094), np.float64(-61266.407852197626), np.float64(-97512.2478395017), np.float64(-82300.08291318928), np.float64(-92351.56116075075), np.float64(-80834.6195977816), np.float64(-82195.11229877062), np.float64(-64855.05027591034), np.float64(-95065.17311865899), np.float64(-50929.78609263704)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.34185961557143074), 'mean_inference_ms': np.float64(4.059963615455572), 'mean_action_processing_ms': np.float64(0.22359507966553738), 'mean_env_wait_ms': np.float64(1.7740819911872217), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.010457754135131836), 'StateBufferConnector_ms': np.float64(0.005579710006713867), 'ViewRequirementAgentConnector_ms': np.float64(0.1512765884399414)}, 'num_episodes': 16, 'episode_return_max': np.float64(-50929.78609263704), 'episode_return_min': np.float64(-102942.25952561355), 'episode_return_mean': np.float64(-78480.73881392844), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 30100000, 'num_agent_steps_trained': 30100000, 'num_env_steps_sampled': 30100000, 'num_env_steps_trained': 30100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2050.06082163894, 'num_env_steps_trained_throughput_per_sec': 2050.06082163894, 'timesteps_total': 30100000, 'num_env_steps_sampled_lifetime': 30100000, 'num_agent_steps_sampled_lifetime': 30100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 30100000, 'timers': {'training_iteration_time_ms': 48058.848, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48058.82, 'sample_time_ms': 46474.242, 'load_time_ms': 173.09, 'load_throughput': 577734.986, 'learn_time_ms': 1389.658, 'learn_throughput': 71960.176, 'synch_weights_time_ms': 20.968}, 'counters': {'num_env_steps_sampled': 30100000, 'num_env_steps_trained': 30100000, 'num_agent_steps_sampled': 30100000, 'num_agent_steps_trained': 30100000}, 'done': False, 'training_iteration': 301, 'trial_id': 'default', 'date': '2025-04-01_14-58-55', 'timestamp': 1743487135, 'time_this_iter_s': 48.78805375099182, 'time_total_s': 14614.76818394661, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 14614.76818394661, 'iterations_since_restore': 301, 'perf': {'cpu_util_percent': np.float64(60.97727272727273), 'ram_util_percent': np.float64(60.64242424242425), 'gpu_util_percent0': np.float64(0.25818181818181823), 'vram_util_percent0': np.float64(0.1043701171875)}})\n",
      "301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_7), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(5.125781250000001), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.4781776666641235), 'policy_loss': np.float64(-0.2053712617632118), 'vf_loss': np.float64(6.995508828163147), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.012954859151618621), 'entropy': np.float64(27.971111640930175), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(35050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 35100000, 'num_env_steps_trained': 35100000, 'num_agent_steps_sampled': 35100000, 'num_agent_steps_trained': 35100000}, 'env_runners': {'episode_reward_max': np.float64(-49886.95614170385), 'episode_reward_min': np.float64(-101573.9191329537), 'episode_reward_mean': np.float64(-78977.71388337303), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101573.9191329537)}, 'policy_reward_max': {'default_policy': np.float64(-49886.95614170385)}, 'policy_reward_mean': {'default_policy': np.float64(-78977.71388337303)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-80229.3807297953), np.float64(-93938.9496128385), np.float64(-76214.73845572055), np.float64(-98663.08887302311), np.float64(-99556.22064066805), np.float64(-88299.25136006867), np.float64(-73961.86483001595), np.float64(-58380.85200102307), np.float64(-94040.05567339073), np.float64(-99858.36632901352), np.float64(-96924.23498821654), np.float64(-84873.8648999897), np.float64(-92989.04757695502), np.float64(-73275.88259342666), np.float64(-96939.47822665809), np.float64(-97224.5283669107), np.float64(-77883.519879898), np.float64(-66968.35660506434), np.float64(-59022.552137085164), np.float64(-88434.23677067953), np.float64(-86979.814965697), np.float64(-95002.84867892247), np.float64(-55482.834762986306), np.float64(-72844.69577496404), np.float64(-64932.36516659751), np.float64(-100572.19236971557), np.float64(-49886.95614170385), np.float64(-101573.9191329537), np.float64(-85947.72732184059), np.float64(-89113.73847861166), np.float64(-83746.38969298356), np.float64(-58359.93679051298), np.float64(-61817.47170669795), np.float64(-66678.78522611596), np.float64(-78088.25293672425), np.float64(-96352.78371770121), np.float64(-83172.9296511064), np.float64(-82749.78055215678), np.float64(-60114.27714170584), np.float64(-69069.23298341161), np.float64(-59262.998848318006), np.float64(-69007.10783400382), np.float64(-75803.37646264622), np.float64(-93816.29837710263), np.float64(-58222.485825806805), np.float64(-85011.55799407362), np.float64(-100535.9926116068), np.float64(-61351.46927880584), np.float64(-79505.23741350629), np.float64(-74156.52170610483), np.float64(-62183.5137319016), np.float64(-85850.76147234465), np.float64(-63289.23835906804), np.float64(-95163.74132032353), np.float64(-66050.15686773944), np.float64(-80253.25277265877), np.float64(-68385.59105515358), np.float64(-88957.2056471075), np.float64(-97236.69755741085), np.float64(-60078.74832603648), np.float64(-88640.93088348617), np.float64(-52396.291608577005), np.float64(-57258.6727400666), np.float64(-65545.34197047525), np.float64(-83624.42875040928), np.float64(-83860.73166018147), np.float64(-80936.57368335193), np.float64(-76133.49179372647), np.float64(-82299.5085538552), np.float64(-89369.64889186466), np.float64(-74933.36442553681), np.float64(-76718.23820743064), np.float64(-90298.04178365546), np.float64(-81482.04373619086), np.float64(-97933.6126727473), np.float64(-83443.63412530482), np.float64(-68994.48106224411), np.float64(-70327.93805273977), np.float64(-97839.30756808225), np.float64(-83135.4661041095), np.float64(-96216.54185430234), np.float64(-72943.5008135793), np.float64(-93762.96936689105), np.float64(-61734.27293453098), np.float64(-85223.22809365006), np.float64(-64415.20011312258), np.float64(-94004.44224823188), np.float64(-61255.7919424802), np.float64(-60472.65299828587), np.float64(-76113.8457635128), np.float64(-69314.64630887358), np.float64(-86306.488969994), np.float64(-95509.71422987759), np.float64(-62310.705120475206), np.float64(-57686.95260155501), np.float64(-61394.63535188764), np.float64(-91992.69747530334), np.float64(-94437.40990361512), np.float64(-77644.14602829344), np.float64(-85572.44073953672)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-80229.3807297953), np.float64(-93938.9496128385), np.float64(-76214.73845572055), np.float64(-98663.08887302311), np.float64(-99556.22064066805), np.float64(-88299.25136006867), np.float64(-73961.86483001595), np.float64(-58380.85200102307), np.float64(-94040.05567339073), np.float64(-99858.36632901352), np.float64(-96924.23498821654), np.float64(-84873.8648999897), np.float64(-92989.04757695502), np.float64(-73275.88259342666), np.float64(-96939.47822665809), np.float64(-97224.5283669107), np.float64(-77883.519879898), np.float64(-66968.35660506434), np.float64(-59022.552137085164), np.float64(-88434.23677067953), np.float64(-86979.814965697), np.float64(-95002.84867892247), np.float64(-55482.834762986306), np.float64(-72844.69577496404), np.float64(-64932.36516659751), np.float64(-100572.19236971557), np.float64(-49886.95614170385), np.float64(-101573.9191329537), np.float64(-85947.72732184059), np.float64(-89113.73847861166), np.float64(-83746.38969298356), np.float64(-58359.93679051298), np.float64(-61817.47170669795), np.float64(-66678.78522611596), np.float64(-78088.25293672425), np.float64(-96352.78371770121), np.float64(-83172.9296511064), np.float64(-82749.78055215678), np.float64(-60114.27714170584), np.float64(-69069.23298341161), np.float64(-59262.998848318006), np.float64(-69007.10783400382), np.float64(-75803.37646264622), np.float64(-93816.29837710263), np.float64(-58222.485825806805), np.float64(-85011.55799407362), np.float64(-100535.9926116068), np.float64(-61351.46927880584), np.float64(-79505.23741350629), np.float64(-74156.52170610483), np.float64(-62183.5137319016), np.float64(-85850.76147234465), np.float64(-63289.23835906804), np.float64(-95163.74132032353), np.float64(-66050.15686773944), np.float64(-80253.25277265877), np.float64(-68385.59105515358), np.float64(-88957.2056471075), np.float64(-97236.69755741085), np.float64(-60078.74832603648), np.float64(-88640.93088348617), np.float64(-52396.291608577005), np.float64(-57258.6727400666), np.float64(-65545.34197047525), np.float64(-83624.42875040928), np.float64(-83860.73166018147), np.float64(-80936.57368335193), np.float64(-76133.49179372647), np.float64(-82299.5085538552), np.float64(-89369.64889186466), np.float64(-74933.36442553681), np.float64(-76718.23820743064), np.float64(-90298.04178365546), np.float64(-81482.04373619086), np.float64(-97933.6126727473), np.float64(-83443.63412530482), np.float64(-68994.48106224411), np.float64(-70327.93805273977), np.float64(-97839.30756808225), np.float64(-83135.4661041095), np.float64(-96216.54185430234), np.float64(-72943.5008135793), np.float64(-93762.96936689105), np.float64(-61734.27293453098), np.float64(-85223.22809365006), np.float64(-64415.20011312258), np.float64(-94004.44224823188), np.float64(-61255.7919424802), np.float64(-60472.65299828587), np.float64(-76113.8457635128), np.float64(-69314.64630887358), np.float64(-86306.488969994), np.float64(-95509.71422987759), np.float64(-62310.705120475206), np.float64(-57686.95260155501), np.float64(-61394.63535188764), np.float64(-91992.69747530334), np.float64(-94437.40990361512), np.float64(-77644.14602829344), np.float64(-85572.44073953672)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.3410113868217024), 'mean_inference_ms': np.float64(4.0501871846788635), 'mean_action_processing_ms': np.float64(0.2230193538918913), 'mean_env_wait_ms': np.float64(1.7695242206819446), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.00841069221496582), 'StateBufferConnector_ms': np.float64(0.005567073822021484), 'ViewRequirementAgentConnector_ms': np.float64(0.1509850025177002)}, 'num_episodes': 16, 'episode_return_max': np.float64(-49886.95614170385), 'episode_return_min': np.float64(-101573.9191329537), 'episode_return_mean': np.float64(-78977.71388337303), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 35100000, 'num_agent_steps_trained': 35100000, 'num_env_steps_sampled': 35100000, 'num_env_steps_trained': 35100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2136.9226412375338, 'num_env_steps_trained_throughput_per_sec': 2136.9226412375338, 'timesteps_total': 35100000, 'num_env_steps_sampled_lifetime': 35100000, 'num_agent_steps_sampled_lifetime': 35100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 35100000, 'timers': {'training_iteration_time_ms': 47860.579, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 47860.549, 'sample_time_ms': 46288.28, 'load_time_ms': 174.137, 'load_throughput': 574259.093, 'learn_time_ms': 1375.741, 'learn_throughput': 72688.085, 'synch_weights_time_ms': 21.252}, 'counters': {'num_env_steps_sampled': 35100000, 'num_env_steps_trained': 35100000, 'num_agent_steps_sampled': 35100000, 'num_agent_steps_trained': 35100000}, 'done': False, 'training_iteration': 351, 'trial_id': 'default', 'date': '2025-04-01_15-39-29', 'timestamp': 1743489569, 'time_this_iter_s': 46.80517053604126, 'time_total_s': 17012.3363571167, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 17012.3363571167, 'iterations_since_restore': 351, 'perf': {'cpu_util_percent': np.float64(61.357142857142854), 'ram_util_percent': np.float64(60.72698412698412), 'gpu_util_percent0': np.float64(0.19206349206349213), 'vram_util_percent0': np.float64(0.1099039713541667)}})\n",
      "351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_8), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(7.688671874999996), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.490961723327636), 'policy_loss': np.float64(-0.18516219145152718), 'vf_loss': np.float64(7.0), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.008929427269599728), 'entropy': np.float64(29.25314880371094), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(40050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 40100000, 'num_env_steps_trained': 40100000, 'num_agent_steps_sampled': 40100000, 'num_agent_steps_trained': 40100000}, 'env_runners': {'episode_reward_max': np.float64(-51219.81037072546), 'episode_reward_min': np.float64(-101626.39042700236), 'episode_reward_mean': np.float64(-77149.038396566), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101626.39042700236)}, 'policy_reward_max': {'default_policy': np.float64(-51219.81037072546)}, 'policy_reward_mean': {'default_policy': np.float64(-77149.038396566)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-73556.55162526757), np.float64(-84166.15875185838), np.float64(-92866.03833212395), np.float64(-86908.39554121824), np.float64(-60819.83758850803), np.float64(-90344.85980844336), np.float64(-97088.93165899275), np.float64(-96500.94062760568), np.float64(-101626.39042700236), np.float64(-85936.70911567322), np.float64(-64046.655135139205), np.float64(-75667.88600519538), np.float64(-96211.44287382995), np.float64(-55228.2462304005), np.float64(-97718.26861707731), np.float64(-55018.812882577266), np.float64(-93453.87750186955), np.float64(-74406.2523888285), np.float64(-81163.60638785234), np.float64(-95191.75319512532), np.float64(-87933.25627979798), np.float64(-68249.56682037027), np.float64(-66294.84547918125), np.float64(-84470.5674071222), np.float64(-84932.7572921827), np.float64(-65450.83591738973), np.float64(-95207.40746951319), np.float64(-71348.36789553461), np.float64(-77892.02551073856), np.float64(-61646.54576208512), np.float64(-97706.15553304882), np.float64(-94808.28967057589), np.float64(-59545.756424715844), np.float64(-62311.13218947957), np.float64(-83765.24114463046), np.float64(-81322.26038271646), np.float64(-89698.8819307332), np.float64(-98264.48806374124), np.float64(-92899.6207240559), np.float64(-53670.753115551786), np.float64(-69600.31332470826), np.float64(-60010.12245153978), np.float64(-82293.8861908537), np.float64(-54773.840841409634), np.float64(-73507.43143243965), np.float64(-87770.25612067003), np.float64(-82402.8867689826), np.float64(-72701.39983416839), np.float64(-96718.56073730015), np.float64(-80515.78535777517), np.float64(-99021.90597567185), np.float64(-75019.34169157955), np.float64(-65396.02639267787), np.float64(-101101.90671788933), np.float64(-54997.85177598892), np.float64(-92649.47347757596), np.float64(-70388.38181655445), np.float64(-81434.06801250491), np.float64(-77744.0659810911), np.float64(-64695.640262816705), np.float64(-59597.495837899616), np.float64(-76389.89572687294), np.float64(-58867.348912883404), np.float64(-75349.71226190591), np.float64(-67303.8944714184), np.float64(-69787.86704959066), np.float64(-64190.31709178094), np.float64(-70772.77735287309), np.float64(-62477.19634888996), np.float64(-67084.39949603696), np.float64(-61167.31066003433), np.float64(-57840.464591027274), np.float64(-62107.09761251437), np.float64(-51219.81037072546), np.float64(-55927.58143452274), np.float64(-65314.00707852307), np.float64(-70614.70052307041), np.float64(-88255.1568245462), np.float64(-55737.721711545135), np.float64(-66126.84933999798), np.float64(-86581.08405765837), np.float64(-88261.78619918208), np.float64(-94878.96379921358), np.float64(-96384.80193094541), np.float64(-91244.48725367979), np.float64(-84400.73146785979), np.float64(-63740.91342272633), np.float64(-77158.11134323396), np.float64(-87309.28365476096), np.float64(-96558.75160992095), np.float64(-75080.4382510119), np.float64(-54667.04462765015), np.float64(-99418.41442693202), np.float64(-89368.40262218106), np.float64(-95948.93619954013), np.float64(-68280.38911209223), np.float64(-91275.23773207057), np.float64(-60244.34060114613), np.float64(-73788.94258798817), np.float64(-56097.6591881971)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-73556.55162526757), np.float64(-84166.15875185838), np.float64(-92866.03833212395), np.float64(-86908.39554121824), np.float64(-60819.83758850803), np.float64(-90344.85980844336), np.float64(-97088.93165899275), np.float64(-96500.94062760568), np.float64(-101626.39042700236), np.float64(-85936.70911567322), np.float64(-64046.655135139205), np.float64(-75667.88600519538), np.float64(-96211.44287382995), np.float64(-55228.2462304005), np.float64(-97718.26861707731), np.float64(-55018.812882577266), np.float64(-93453.87750186955), np.float64(-74406.2523888285), np.float64(-81163.60638785234), np.float64(-95191.75319512532), np.float64(-87933.25627979798), np.float64(-68249.56682037027), np.float64(-66294.84547918125), np.float64(-84470.5674071222), np.float64(-84932.7572921827), np.float64(-65450.83591738973), np.float64(-95207.40746951319), np.float64(-71348.36789553461), np.float64(-77892.02551073856), np.float64(-61646.54576208512), np.float64(-97706.15553304882), np.float64(-94808.28967057589), np.float64(-59545.756424715844), np.float64(-62311.13218947957), np.float64(-83765.24114463046), np.float64(-81322.26038271646), np.float64(-89698.8819307332), np.float64(-98264.48806374124), np.float64(-92899.6207240559), np.float64(-53670.753115551786), np.float64(-69600.31332470826), np.float64(-60010.12245153978), np.float64(-82293.8861908537), np.float64(-54773.840841409634), np.float64(-73507.43143243965), np.float64(-87770.25612067003), np.float64(-82402.8867689826), np.float64(-72701.39983416839), np.float64(-96718.56073730015), np.float64(-80515.78535777517), np.float64(-99021.90597567185), np.float64(-75019.34169157955), np.float64(-65396.02639267787), np.float64(-101101.90671788933), np.float64(-54997.85177598892), np.float64(-92649.47347757596), np.float64(-70388.38181655445), np.float64(-81434.06801250491), np.float64(-77744.0659810911), np.float64(-64695.640262816705), np.float64(-59597.495837899616), np.float64(-76389.89572687294), np.float64(-58867.348912883404), np.float64(-75349.71226190591), np.float64(-67303.8944714184), np.float64(-69787.86704959066), np.float64(-64190.31709178094), np.float64(-70772.77735287309), np.float64(-62477.19634888996), np.float64(-67084.39949603696), np.float64(-61167.31066003433), np.float64(-57840.464591027274), np.float64(-62107.09761251437), np.float64(-51219.81037072546), np.float64(-55927.58143452274), np.float64(-65314.00707852307), np.float64(-70614.70052307041), np.float64(-88255.1568245462), np.float64(-55737.721711545135), np.float64(-66126.84933999798), np.float64(-86581.08405765837), np.float64(-88261.78619918208), np.float64(-94878.96379921358), np.float64(-96384.80193094541), np.float64(-91244.48725367979), np.float64(-84400.73146785979), np.float64(-63740.91342272633), np.float64(-77158.11134323396), np.float64(-87309.28365476096), np.float64(-96558.75160992095), np.float64(-75080.4382510119), np.float64(-54667.04462765015), np.float64(-99418.41442693202), np.float64(-89368.40262218106), np.float64(-95948.93619954013), np.float64(-68280.38911209223), np.float64(-91275.23773207057), np.float64(-60244.34060114613), np.float64(-73788.94258798817), np.float64(-56097.6591881971)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.33938685045543077), 'mean_inference_ms': np.float64(4.038451854107205), 'mean_action_processing_ms': np.float64(0.22205710949119642), 'mean_env_wait_ms': np.float64(1.7626613393752926), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.008275747299194336), 'StateBufferConnector_ms': np.float64(0.00537419319152832), 'ViewRequirementAgentConnector_ms': np.float64(0.1472458839416504)}, 'num_episodes': 16, 'episode_return_max': np.float64(-51219.81037072546), 'episode_return_min': np.float64(-101626.39042700236), 'episode_return_mean': np.float64(-77149.038396566), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 40100000, 'num_agent_steps_trained': 40100000, 'num_env_steps_sampled': 40100000, 'num_env_steps_trained': 40100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2119.7552469641128, 'num_env_steps_trained_throughput_per_sec': 2119.7552469641128, 'timesteps_total': 40100000, 'num_env_steps_sampled_lifetime': 40100000, 'num_agent_steps_sampled_lifetime': 40100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 40100000, 'timers': {'training_iteration_time_ms': 47510.289, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 47510.258, 'sample_time_ms': 45953.531, 'load_time_ms': 174.616, 'load_throughput': 572684.649, 'learn_time_ms': 1360.445, 'learn_throughput': 73505.373, 'synch_weights_time_ms': 20.755}, 'counters': {'num_env_steps_sampled': 40100000, 'num_env_steps_trained': 40100000, 'num_agent_steps_sampled': 40100000, 'num_agent_steps_trained': 40100000}, 'done': False, 'training_iteration': 401, 'trial_id': 'default', 'date': '2025-04-01_16-19-41', 'timestamp': 1743491981, 'time_this_iter_s': 47.1847825050354, 'time_total_s': 19387.469937086105, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 19387.469937086105, 'iterations_since_restore': 401, 'perf': {'cpu_util_percent': np.float64(61.33593750000001), 'ram_util_percent': np.float64(65.590625), 'gpu_util_percent0': np.float64(0.1928125), 'vram_util_percent0': np.float64(0.10600789388020833)}})\n",
      "401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=PPO_OldAPI_WINDOW_YPR_401_9), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'cur_kl_coeff': np.float64(7.688671874999996), 'cur_lr': np.float64(0.0005000000000000001), 'total_loss': np.float64(4.504318456649781), 'policy_loss': np.float64(-0.18352610180620105), 'vf_loss': np.float64(7.0), 'vf_explained_var': np.float64(-1.0), 'kl': np.float64(0.00963792296262568), 'entropy': np.float64(28.625828247070313), 'entropy_coeff': np.float64(0.009999999999999998)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(45050.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(49.5)}}, 'num_env_steps_sampled': 45100000, 'num_env_steps_trained': 45100000, 'num_agent_steps_sampled': 45100000, 'num_agent_steps_trained': 45100000}, 'env_runners': {'episode_reward_max': np.float64(-50412.73641669444), 'episode_reward_min': np.float64(-103622.24183096654), 'episode_reward_mean': np.float64(-79645.25367582818), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-103622.24183096654)}, 'policy_reward_max': {'default_policy': np.float64(-50412.73641669444)}, 'policy_reward_mean': {'default_policy': np.float64(-79645.25367582818)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-81405.77252506059), np.float64(-88197.30325457068), np.float64(-97275.58405517064), np.float64(-66519.88147698842), np.float64(-68906.12146271947), np.float64(-86299.98749855597), np.float64(-94124.52424508803), np.float64(-67195.27603524043), np.float64(-91521.72005181684), np.float64(-63466.96008376779), np.float64(-56168.99947967876), np.float64(-80257.70978076821), np.float64(-90437.40614335917), np.float64(-67923.76844552737), np.float64(-91554.10299308745), np.float64(-61910.92604453276), np.float64(-77656.662681397), np.float64(-64599.59943105854), np.float64(-78327.02565410765), np.float64(-96704.71829643166), np.float64(-63133.55861624088), np.float64(-72928.29259426093), np.float64(-67856.67914539063), np.float64(-57729.30330536248), np.float64(-96492.64628168156), np.float64(-95992.63961544912), np.float64(-57556.084827506675), np.float64(-101425.61602888658), np.float64(-86349.62411553213), np.float64(-98866.5083579479), np.float64(-94726.57981274408), np.float64(-87914.09286354308), np.float64(-79238.08085095372), np.float64(-67885.43995996751), np.float64(-68649.28988332223), np.float64(-51164.125527766206), np.float64(-77562.38221171462), np.float64(-82733.36435962567), np.float64(-88011.07530949754), np.float64(-68210.25932016959), np.float64(-88062.17854434506), np.float64(-81700.37326448045), np.float64(-60141.83511555025), np.float64(-94717.10904165916), np.float64(-82375.12867224707), np.float64(-99432.32697563076), np.float64(-103622.24183096654), np.float64(-95903.34388467018), np.float64(-87846.07193618186), np.float64(-93108.2060486586), np.float64(-66806.73754864682), np.float64(-63590.166571328926), np.float64(-69279.62813218839), np.float64(-69046.58034458719), np.float64(-86099.54354303422), np.float64(-76619.48258340436), np.float64(-94315.41190090193), np.float64(-57653.4975912932), np.float64(-59837.7758843372), np.float64(-55899.59155392437), np.float64(-77870.63109953185), np.float64(-74288.4422769509), np.float64(-100431.45874767742), np.float64(-62831.4936323864), np.float64(-61771.16188582316), np.float64(-103289.39790047544), np.float64(-56374.03716579366), np.float64(-62804.71601852409), np.float64(-77738.53496505137), np.float64(-78820.20949703171), np.float64(-84282.0337141169), np.float64(-55357.12780706869), np.float64(-56797.525724586376), np.float64(-83078.63162260708), np.float64(-60665.815435688644), np.float64(-97472.20707426094), np.float64(-98719.76259232611), np.float64(-85208.12153840634), np.float64(-86762.11785232392), np.float64(-101089.96479304436), np.float64(-50412.73641669444), np.float64(-97170.02378253161), np.float64(-98447.37836017563), np.float64(-93769.10974984738), np.float64(-60239.529192388254), np.float64(-95876.27423023358), np.float64(-92030.78678766992), np.float64(-64105.88807303547), np.float64(-86702.15219469582), np.float64(-61883.29101596099), np.float64(-102035.68274287213), np.float64(-60598.64171506633), np.float64(-95046.3021308979), np.float64(-96456.82062500127), np.float64(-90756.22662266069), np.float64(-81174.71566218654), np.float64(-91004.96197894082), np.float64(-76618.31947055903), np.float64(-89967.75491226722), np.float64(-93638.45698092863)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-81405.77252506059), np.float64(-88197.30325457068), np.float64(-97275.58405517064), np.float64(-66519.88147698842), np.float64(-68906.12146271947), np.float64(-86299.98749855597), np.float64(-94124.52424508803), np.float64(-67195.27603524043), np.float64(-91521.72005181684), np.float64(-63466.96008376779), np.float64(-56168.99947967876), np.float64(-80257.70978076821), np.float64(-90437.40614335917), np.float64(-67923.76844552737), np.float64(-91554.10299308745), np.float64(-61910.92604453276), np.float64(-77656.662681397), np.float64(-64599.59943105854), np.float64(-78327.02565410765), np.float64(-96704.71829643166), np.float64(-63133.55861624088), np.float64(-72928.29259426093), np.float64(-67856.67914539063), np.float64(-57729.30330536248), np.float64(-96492.64628168156), np.float64(-95992.63961544912), np.float64(-57556.084827506675), np.float64(-101425.61602888658), np.float64(-86349.62411553213), np.float64(-98866.5083579479), np.float64(-94726.57981274408), np.float64(-87914.09286354308), np.float64(-79238.08085095372), np.float64(-67885.43995996751), np.float64(-68649.28988332223), np.float64(-51164.125527766206), np.float64(-77562.38221171462), np.float64(-82733.36435962567), np.float64(-88011.07530949754), np.float64(-68210.25932016959), np.float64(-88062.17854434506), np.float64(-81700.37326448045), np.float64(-60141.83511555025), np.float64(-94717.10904165916), np.float64(-82375.12867224707), np.float64(-99432.32697563076), np.float64(-103622.24183096654), np.float64(-95903.34388467018), np.float64(-87846.07193618186), np.float64(-93108.2060486586), np.float64(-66806.73754864682), np.float64(-63590.166571328926), np.float64(-69279.62813218839), np.float64(-69046.58034458719), np.float64(-86099.54354303422), np.float64(-76619.48258340436), np.float64(-94315.41190090193), np.float64(-57653.4975912932), np.float64(-59837.7758843372), np.float64(-55899.59155392437), np.float64(-77870.63109953185), np.float64(-74288.4422769509), np.float64(-100431.45874767742), np.float64(-62831.4936323864), np.float64(-61771.16188582316), np.float64(-103289.39790047544), np.float64(-56374.03716579366), np.float64(-62804.71601852409), np.float64(-77738.53496505137), np.float64(-78820.20949703171), np.float64(-84282.0337141169), np.float64(-55357.12780706869), np.float64(-56797.525724586376), np.float64(-83078.63162260708), np.float64(-60665.815435688644), np.float64(-97472.20707426094), np.float64(-98719.76259232611), np.float64(-85208.12153840634), np.float64(-86762.11785232392), np.float64(-101089.96479304436), np.float64(-50412.73641669444), np.float64(-97170.02378253161), np.float64(-98447.37836017563), np.float64(-93769.10974984738), np.float64(-60239.529192388254), np.float64(-95876.27423023358), np.float64(-92030.78678766992), np.float64(-64105.88807303547), np.float64(-86702.15219469582), np.float64(-61883.29101596099), np.float64(-102035.68274287213), np.float64(-60598.64171506633), np.float64(-95046.3021308979), np.float64(-96456.82062500127), np.float64(-90756.22662266069), np.float64(-81174.71566218654), np.float64(-91004.96197894082), np.float64(-76618.31947055903), np.float64(-89967.75491226722), np.float64(-93638.45698092863)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.33926697579681636), 'mean_inference_ms': np.float64(4.03790109173428), 'mean_action_processing_ms': np.float64(0.2219592582305898), 'mean_env_wait_ms': np.float64(1.761927092169779), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.008801460266113281), 'StateBufferConnector_ms': np.float64(0.00580906867980957), 'ViewRequirementAgentConnector_ms': np.float64(0.15668535232543945)}, 'num_episodes': 16, 'episode_return_max': np.float64(-50412.73641669444), 'episode_return_min': np.float64(-103622.24183096654), 'episode_return_mean': np.float64(-79645.25367582818), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 45100000, 'num_agent_steps_trained': 45100000, 'num_env_steps_sampled': 45100000, 'num_env_steps_trained': 45100000, 'num_env_steps_sampled_this_iter': 100000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 2071.215412123228, 'num_env_steps_trained_throughput_per_sec': 2071.215412123228, 'timesteps_total': 45100000, 'num_env_steps_sampled_lifetime': 45100000, 'num_agent_steps_sampled_lifetime': 45100000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 45100000, 'timers': {'training_iteration_time_ms': 48913.351, 'restore_workers_time_ms': 0.008, 'training_step_time_ms': 48913.32, 'sample_time_ms': 47282.02, 'load_time_ms': 176.124, 'load_throughput': 567780.405, 'learn_time_ms': 1432.214, 'learn_throughput': 69821.951, 'synch_weights_time_ms': 21.802}, 'counters': {'num_env_steps_sampled': 45100000, 'num_env_steps_trained': 45100000, 'num_agent_steps_sampled': 45100000, 'num_agent_steps_trained': 45100000}, 'done': False, 'training_iteration': 451, 'trial_id': 'default', 'date': '2025-04-01_17-00-43', 'timestamp': 1743494443, 'time_this_iter_s': 48.28870940208435, 'time_total_s': 21812.512345552444, 'pid': 48227, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 8, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 0, 'num_gpus_per_learner': 1, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': 0.0005, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': None, 'train_batch_size': 100000, 'num_epochs': 10, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'swish', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x731d4ac73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'lr_schedule': None, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.7, 'entropy_coeff': 0.01, 'entropy_coeff_schedule': None, 'clip_param': 0.3, 'vf_clip_param': 7, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 1.0, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 21812.512345552444, 'iterations_since_restore': 451, 'perf': {'cpu_util_percent': np.float64(63.956923076923076), 'ram_util_percent': np.float64(65.56615384615385), 'gpu_util_percent0': np.float64(0.23246153846153844), 'vram_util_percent0': np.float64(0.10739683493589743)}})\n",
      "451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m save_name = \u001b[33m\"\u001b[39m\u001b[33mPPO_OldAPI_WINDOW_YPR_401\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     result = \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# result.pop(\"config\")\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# pprint(result)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:328\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m start = time.time()\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    330\u001b[39m     skipped = skip_exceptions(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:933\u001b[39m, in \u001b[36mAlgorithm.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    923\u001b[39m     (\n\u001b[32m    924\u001b[39m         train_results,\n\u001b[32m    925\u001b[39m         eval_results,\n\u001b[32m    926\u001b[39m         train_iter_ctx,\n\u001b[32m    927\u001b[39m     ) = \u001b[38;5;28mself\u001b[39m._run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[32m    929\u001b[39m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m     train_results, train_iter_ctx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.evaluation_parallel_to_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:3498\u001b[39m, in \u001b[36mAlgorithm._run_one_training_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3494\u001b[39m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timers[TRAINING_STEP_TIMER]:\n\u001b[32m   3496\u001b[39m     \u001b[38;5;66;03m# TODO (sven): Should we reduce the different\u001b[39;00m\n\u001b[32m   3497\u001b[39m     \u001b[38;5;66;03m#  `training_step_results` over time with MetricsLogger.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3498\u001b[39m     training_step_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_step_results:\n\u001b[32m   3501\u001b[39m     results = training_step_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/ppo/ppo.py:417\u001b[39m, in \u001b[36mPPO.training_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._training_step_new_api_stack()\n\u001b[32m    414\u001b[39m \u001b[38;5;66;03m# Old API stack (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_training_step_old_api_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/ppo/ppo.py:528\u001b[39m, in \u001b[36mPPO._training_step_old_api_stack\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    522\u001b[39m     train_batch = synchronous_parallel_sample(\n\u001b[32m    523\u001b[39m         worker_set=\u001b[38;5;28mself\u001b[39m.env_runner_group,\n\u001b[32m    524\u001b[39m         max_agent_steps=\u001b[38;5;28mself\u001b[39m.config.total_train_batch_size,\n\u001b[32m    525\u001b[39m         sample_timeout_s=\u001b[38;5;28mself\u001b[39m.config.sample_timeout_s,\n\u001b[32m    526\u001b[39m     )\n\u001b[32m    527\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m528\u001b[39m     train_batch = \u001b[43msynchronous_parallel_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    529\u001b[39m \u001b[43m        \u001b[49m\u001b[43mworker_set\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv_runner_group\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    530\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_env_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    531\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    532\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    533\u001b[39m \u001b[38;5;66;03m# Return early if all our workers failed.\u001b[39;00m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m train_batch:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/execution/rollout_ops.py:106\u001b[39m, in \u001b[36msynchronous_parallel_sample\u001b[39m\u001b[34m(worker_set, max_agent_steps, max_env_steps, concat, sample_timeout_s, random_actions, _uses_new_env_runners, _return_metrics)\u001b[39m\n\u001b[32m    103\u001b[39m         stats_dicts = [worker_set.local_env_runner.get_metrics()]\n\u001b[32m    104\u001b[39m \u001b[38;5;66;03m# Loop over remote workers' `sample()` method in parallel.\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     sampled_data = \u001b[43mworker_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforeach_worker\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrandom_action_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_return_metrics\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrandom_action_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_env_runner\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_timeout_s\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Nothing was returned (maybe all workers are stalling) or no healthy\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# remote workers left: Break.\u001b[39;00m\n\u001b[32m    117\u001b[39m     \u001b[38;5;66;03m# There is no point staying in this loop, since we will not be able to\u001b[39;00m\n\u001b[32m    118\u001b[39m     \u001b[38;5;66;03m# get any new samples if we don't have any healthy remote workers left.\u001b[39;00m\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sampled_data \u001b[38;5;129;01mor\u001b[39;00m worker_set.num_healthy_remote_workers() <= \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/env/env_runner_group.py:896\u001b[39m, in \u001b[36mEnvRunnerGroup.foreach_worker\u001b[39m\u001b[34m(self, func, local_env_runner, healthy_only, remote_worker_ids, timeout_seconds, return_obj_refs, mark_healthy, local_worker)\u001b[39m\n\u001b[32m    893\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._worker_manager.actor_ids():\n\u001b[32m    894\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m local_result\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m remote_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_worker_manager\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforeach_actor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    898\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhealthy_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    899\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_worker_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    900\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    901\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    902\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    905\u001b[39m FaultTolerantActorManager.handle_remote_call_result_errors(\n\u001b[32m    906\u001b[39m     remote_results, ignore_ray_errors=\u001b[38;5;28mself\u001b[39m._ignore_ray_errors_on_env_runners\n\u001b[32m    907\u001b[39m )\n\u001b[32m    909\u001b[39m \u001b[38;5;66;03m# With application errors handled, return good results.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/actor_manager.py:452\u001b[39m, in \u001b[36mFaultTolerantActorManager.foreach_actor\u001b[39m\u001b[34m(self, func, healthy_only, remote_actor_ids, timeout_seconds, return_obj_refs, mark_healthy)\u001b[39m\n\u001b[32m    446\u001b[39m remote_calls = \u001b[38;5;28mself\u001b[39m._call_actors(\n\u001b[32m    447\u001b[39m     func=func,\n\u001b[32m    448\u001b[39m     remote_actor_ids=remote_actor_ids,\n\u001b[32m    449\u001b[39m )\n\u001b[32m    451\u001b[39m \u001b[38;5;66;03m# Collect remote request results (if available given timeout and/or errors).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m452\u001b[39m _, remote_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fetch_result\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_actor_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m    \u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mremote_calls\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_obj_refs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmark_healthy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m remote_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/actor_manager.py:792\u001b[39m, in \u001b[36mFaultTolerantActorManager._fetch_result\u001b[39m\u001b[34m(self, remote_actor_ids, remote_calls, tags, timeout_seconds, return_obj_refs, mark_healthy)\u001b[39m\n\u001b[32m    790\u001b[39m \u001b[38;5;66;03m# Try getting the ready results.\u001b[39;00m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m792\u001b[39m     result = \u001b[43mray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mready\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[38;5;66;03m# Any error type other than `RayError` happening during ray.get() ->\u001b[39;00m\n\u001b[32m    795\u001b[39m \u001b[38;5;66;03m# Throw exception right here (we don't know how to handle these non-remote\u001b[39;00m\n\u001b[32m    796\u001b[39m \u001b[38;5;66;03m# worker issues and should therefore crash).\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m RayError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    798\u001b[39m     \u001b[38;5;66;03m# Return error to the user.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/auto_init_hook.py:21\u001b[39m, in \u001b[36mwrap_auto_init.<locals>.auto_init_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(fn)\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_init_wrapper\u001b[39m(*args, **kwargs):\n\u001b[32m     20\u001b[39m     auto_init_ray()\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/client_mode_hook.py:103\u001b[39m, in \u001b[36mclient_mode_hook.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m func.\u001b[34m__name__\u001b[39m != \u001b[33m\"\u001b[39m\u001b[33minit\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m is_client_mode_enabled_by_default:\n\u001b[32m    102\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ray, func.\u001b[34m__name__\u001b[39m)(*args, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/worker.py:2753\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(object_refs, timeout)\u001b[39m\n\u001b[32m   2747\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   2748\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid type of object refs, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(object_refs)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, is given. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2749\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mobject_refs\u001b[39m\u001b[33m'\u001b[39m\u001b[33m must either be an ObjectRef or a list of ObjectRefs. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2750\u001b[39m     )\n\u001b[32m   2752\u001b[39m \u001b[38;5;66;03m# TODO(ujvl): Consider how to allow user to retrieve the ready objects.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2753\u001b[39m values, debugger_breakpoint = \u001b[43mworker\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2754\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n\u001b[32m   2755\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, RayError):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/worker.py:896\u001b[39m, in \u001b[36mWorker.get_objects\u001b[39m\u001b[34m(self, object_refs, timeout, return_exceptions)\u001b[39m\n\u001b[32m    890\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(metadata_fields) >= \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m metadata_fields[\u001b[32m1\u001b[39m].startswith(\n\u001b[32m    891\u001b[39m             ray_constants.OBJECT_METADATA_DEBUG_PREFIX\n\u001b[32m    892\u001b[39m         ):\n\u001b[32m    893\u001b[39m             debugger_breakpoint = metadata_fields[\u001b[32m1\u001b[39m][\n\u001b[32m    894\u001b[39m                 \u001b[38;5;28mlen\u001b[39m(ray_constants.OBJECT_METADATA_DEBUG_PREFIX) :\n\u001b[32m    895\u001b[39m             ]\n\u001b[32m--> \u001b[39m\u001b[32m896\u001b[39m values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_metadata_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_exceptions:\n\u001b[32m    898\u001b[39m     \u001b[38;5;66;03m# Raise exceptions instead of returning them to the user.\u001b[39;00m\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(values):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/worker.py:841\u001b[39m, in \u001b[36mWorker.deserialize_objects\u001b[39m\u001b[34m(self, data_metadata_pairs, object_refs)\u001b[39m\n\u001b[32m    839\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_actor_manager.lock:\n\u001b[32m    840\u001b[39m     context = \u001b[38;5;28mself\u001b[39m.get_serialization_context()\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_objects\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_metadata_pairs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_refs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/serialization.py:460\u001b[39m, in \u001b[36mSerializationContext.deserialize_objects\u001b[39m\u001b[34m(self, data_metadata_pairs, object_refs)\u001b[39m\n\u001b[32m    456\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    457\u001b[39m     \u001b[38;5;66;03m# Push the object ref to the stack, so the object under\u001b[39;00m\n\u001b[32m    458\u001b[39m     \u001b[38;5;66;03m# the object ref knows where it comes from.\u001b[39;00m\n\u001b[32m    459\u001b[39m     \u001b[38;5;28mself\u001b[39m._thread_local.object_ref_stack.append(object_ref)\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m     obj = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deserialize_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_ref\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    462\u001b[39m     logger.exception(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/serialization.py:317\u001b[39m, in \u001b[36mSerializationContext._deserialize_object\u001b[39m\u001b[34m(self, data, metadata, object_ref)\u001b[39m\n\u001b[32m    312\u001b[39m metadata_fields = metadata.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_fields[\u001b[32m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[32m    314\u001b[39m     ray_constants.OBJECT_METADATA_TYPE_CROSS_LANGUAGE,\n\u001b[32m    315\u001b[39m     ray_constants.OBJECT_METADATA_TYPE_PYTHON,\n\u001b[32m    316\u001b[39m ]:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deserialize_msgpack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# Check if the object should be returned as raw bytes.\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_fields[\u001b[32m0\u001b[39m] == ray_constants.OBJECT_METADATA_TYPE_RAW:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/serialization.py:272\u001b[39m, in \u001b[36mSerializationContext._deserialize_msgpack_data\u001b[39m\u001b[34m(self, data, metadata_fields)\u001b[39m\n\u001b[32m    269\u001b[39m msgpack_data, pickle5_data = split_buffer(data)\n\u001b[32m    271\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m metadata_fields[\u001b[32m0\u001b[39m] == ray_constants.OBJECT_METADATA_TYPE_PYTHON:\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     python_objects = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_deserialize_pickle5_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickle5_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     python_objects = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/_private/serialization.py:260\u001b[39m, in \u001b[36mSerializationContext._deserialize_pickle5_data\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    258\u001b[39m in_band, buffers = unpack_pickle5_buffers(data)\n\u001b[32m    259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffers) > \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m     obj = \u001b[43mpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_band\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffers\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    262\u001b[39m     obj = pickle.loads(in_band)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/numpy/_core/numeric.py:1923\u001b[39m, in \u001b[36m_frombuffer\u001b[39m\u001b[34m(buf, dtype, shape, order)\u001b[39m\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m function(*args, **kwargs)\n\u001b[32m   1920\u001b[39m _fromfunction_with_like = array_function_dispatch()(fromfunction)\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_frombuffer\u001b[39m(buf, dtype, shape, order):\n\u001b[32m   1924\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m frombuffer(buf, dtype=dtype).reshape(shape, order=order)\n\u001b[32m   1927\u001b[39m \u001b[38;5;129m@set_module\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   1928\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misscalar\u001b[39m(element):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import datetime\n",
    "from scipy.io import savemat\n",
    "\n",
    "n_iter = 3000\n",
    "save_iter = 0\n",
    "save_name = \"PPO_OldAPI_WINDOW_YPR_401\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}\", end=\", \")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%50 == 0:\n",
    "        checkpoint_dir = algo.save(save_name + \"_\" + str(save_iter))\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "\n",
    "        # Record Validation Env\n",
    "        env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "        obs = env.reset()[0]\n",
    "        env_done = False\n",
    "        init_prev_a = prev_a = np.array([0]*14)\n",
    "        lstm_cell_size = config[\"model\"][\"lstm_cell_size\"]\n",
    "\n",
    "        if algo.config.enable_rl_module_and_learner:\n",
    "            init_state = state = algo.get_policy().model.get_initial_state()\n",
    "        else:\n",
    "            init_state = state = [np.zeros([lstm_cell_size], np.float32) for _ in range(2)]\n",
    "\n",
    "        rew_return = 0\n",
    "        frames = []\n",
    "        info = []\n",
    "\n",
    "        for i in range(3000):\n",
    "            act, _state_out, _ = algo.compute_single_action(observation=obs, state=state, prev_action=prev_a)\n",
    "            obs, _step_rew, _, env_done, env_info = env.step(act)\n",
    "            pixels = env.render()\n",
    "            frames.append(pixels)\n",
    "            info.append(env_info)\n",
    "            rew_return += _step_rew\n",
    "            state = _state_out\n",
    "            prev_a = act\n",
    "\n",
    "        _video_base_name = 'rl-video'\n",
    "\n",
    "        _f_name, _full_path = get_unique_filename(f\"./video/{_video_base_name}\")\n",
    "        rew_dict = get_data_from_info(info)\n",
    "        rew_dict['rew_return'] = rew_return\n",
    "\n",
    "        # Save Video\n",
    "        save_video(frames, \"./video/\", name_prefix=_f_name, fps=env.metadata['render_fps'])\n",
    "\n",
    "        # Save Video Info\n",
    "        _f_video_info = open(f\"./video/joy_input.txt\", 'a')\n",
    "        _f_video_info.write(f'File creation time: {datetime.datetime.now()}\\n')\n",
    "        _f_video_info.write(f'Video file name: {_f_name}, Joy input: {info[0][\"joy_input\"]}, Friction: {info[0][\"friction_coeff\"]}\\n')\n",
    "        _f_video_info.close()\n",
    "\n",
    "        # Save Reward Info mat file\n",
    "        savemat(f\"./data/{save_name}_{_f_name}.mat\", rew_dict)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "\n",
    "algo.save(save_name + str(\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record Validation Env\n",
    "env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "obs = env.reset()[0]\n",
    "env_done = False\n",
    "init_prev_a = prev_a = np.array([0]*14)\n",
    "lstm_cell_size = config[\"model\"][\"lstm_cell_size\"]\n",
    "\n",
    "if algo.config.enable_rl_module_and_learner:\n",
    "    init_state = state = algo.get_policy().model.get_initial_state()\n",
    "    # init_state = state = algo.get_module().get_initial_state()\n",
    "else:\n",
    "    init_state = state = [np.zeros([lstm_cell_size], np.float32) for _ in range(2)]\n",
    "\n",
    "rew_return = 0\n",
    "frames = []\n",
    "info = []\n",
    "\n",
    "for i in range(3000):\n",
    "    act, _state_out, _ = algo.compute_single_action(observation=obs, state=state, prev_action=prev_a)\n",
    "    # act, _state_out, _ = algo.get_module().forward_inference({'obs':obs})\n",
    "\n",
    "    obs, _step_rew, _, env_done, env_info = env.step(act)\n",
    "    pixels = env.render()\n",
    "    frames.append(pixels)\n",
    "    info.append(env_info)\n",
    "    rew_return += _step_rew\n",
    "    state = _state_out\n",
    "    prev_a = act\n",
    "\n",
    "_video_base_name = 'rl-video'\n",
    "\n",
    "_f_name, _full_path = get_unique_filename(f\"./video/{_video_base_name}\")\n",
    "rew_dict = get_data_from_info(info)\n",
    "rew_dict['rew_return'] = rew_return\n",
    "\n",
    "# Save Video\n",
    "save_video(frames, \"./video/\", name_prefix=_f_name, fps=env.metadata['render_fps'])\n",
    "\n",
    "# Save Video Info\n",
    "_f_video_info = open(f\"./video/joy_input.txt\", 'a')\n",
    "_f_video_info.write(f'File creation time: {datetime.datetime.now()}\\n')\n",
    "_f_video_info.write(f'Video file name: {_f_name}, Joy input: {info[0][\"joy_input\"]}, Friction: {info[0][\"friction_coeff\"]}\\n')\n",
    "_f_video_info.close()\n",
    "\n",
    "# Save Reward Info mat file\n",
    "savemat(f\"./data/{save_name}_{_f_name}.mat\", rew_dict)\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46573140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algo.get_module().input_specs_train\n",
    "# algo.get_module().input_specs_inference()\n",
    "\n",
    "\n",
    "algo.get_policy().model.get_initial_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdf445a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd239",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
