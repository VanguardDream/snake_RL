{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 전 Ray tune을 통한 하이퍼파라미터 튜닝 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "import horcrux_terrain_v2\n",
    "from horcrux_terrain_v2.envs import PlaneJoyWorld\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "# Ray 초기화\n",
    "# ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Env 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"gait_sampling_interval\": 0.01,\n",
    "    \"forward_reward_weight\": 200.0,\n",
    "    \"rotation_reward_weight\": 100.0,\n",
    "    \"unhealthy_max_steps\": 80.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-30,30),\n",
    "    \"terminating_roll_range\": (-80,80),\n",
    "    \"rotation_norm_cost_weight\": 8.0,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 0.05,\n",
    "}\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     rotation_reward_weight=env_config[\"rotation_reward_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                     use_imu_window=env_config[\"use_imu_window\"],\n",
    "                                                     ctrl_cost_weight=env_config[\"ctrl_cost_weight\"],\n",
    "                                                   )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 알고리즘 설정 진행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_config = PPOConfig().to_dict()\n",
    "\"\"\"\n",
    "Tunable config sets\n",
    "    gamma=0.95,\n",
    "    lr=0.0005,\n",
    "    train_batch_size = 100000,\n",
    "    minibatch_size = 10000,\n",
    "    num_epochs = 10,\n",
    "    entropy_coeff = 0.01,\n",
    "    vf_loss_coeff = 0.7, #이 값 튜닝 진행해야함. (기본값 : 1.0)\n",
    "    vf_clip_param = 7,\n",
    "\"\"\"\n",
    "algo_config['framework'] = 'torch'\n",
    "algo_config['env'] = 'joy-v1'\n",
    "algo_config['lr'] = tune.loguniform(1e-5, 1e-2)\n",
    "algo_config['gamma'] = tune.uniform(0.9, 0.99)\n",
    "algo_config['num_epochs'] = tune.choice([30, 35, 40, 45, 50])\n",
    "algo_config['minibatch_size'] = tune.choice([5000, 7000, 10000, 15000])\n",
    "algo_config['shuffle_batch_per_epoch'] = False\n",
    "algo_config['lambda'] = tune.uniform(0.95, 0.99)\n",
    "algo_config['kl_coeff'] = tune.uniform(0.1, 0.5)\n",
    "algo_config['vf_loss_coeff'] = tune.uniform(0.5, 1.5)\n",
    "algo_config['entropy_coeff'] = tune.uniform(0.01, 0.1)\n",
    "algo_config['clip_param'] = tune.uniform(0.1, 0.3)\n",
    "algo_config['vf_clip_param'] = tune.uniform(5, 10)\n",
    "algo_config['train_batch_size'] = tune.choice([100000, 150000, 200000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_name = '401-ex1'\n",
    "ray.tune.TuneConfig.trial_dirname_creator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.rllib.connectors.env_to_module import FlattenObservations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-04-02 01:06:58</td></tr>\n",
       "<tr><td>Running for: </td><td>08:01:58.68        </td></tr>\n",
       "<tr><td>Memory:      </td><td>22.1/63.9 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 3.0/32 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name            </th><th>status  </th><th>loc            </th><th style=\"text-align: right;\">  clip_param</th><th style=\"text-align: right;\">  entropy_coeff</th><th style=\"text-align: right;\">   gamma</th><th style=\"text-align: right;\">  kl_coeff</th><th style=\"text-align: right;\">  lambda</th><th style=\"text-align: right;\">        lr</th><th style=\"text-align: right;\">  minibatch_size</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  train_batch_size</th><th style=\"text-align: right;\">  vf_clip_param</th><th style=\"text-align: right;\">  vf_loss_coeff</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_joy-v1_02123_00000</td><td>RUNNING </td><td>127.0.0.1:36348</td><td style=\"text-align: right;\">    0.156614</td><td style=\"text-align: right;\">      0.0348509</td><td style=\"text-align: right;\">0.977361</td><td style=\"text-align: right;\">  0.480443</td><td style=\"text-align: right;\">0.988087</td><td style=\"text-align: right;\">0.00527696</td><td style=\"text-align: right;\">           10000</td><td style=\"text-align: right;\">          40</td><td style=\"text-align: right;\">            150000</td><td style=\"text-align: right;\">        5.60548</td><td style=\"text-align: right;\">       0.657777</td><td style=\"text-align: right;\">   409</td><td style=\"text-align: right;\">         28862.3</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 17:04:59,932\tWARNING ppo.py:305 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-04-01 17:04:59,933\tWARNING ppo.py:305 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-04-01 17:06:27,208\tWARNING trial.py:863 -- Stopping criterion 'episode_reward_mean' not found in result dict! Available keys are ['done', 'training_iteration', 'trial_id', 'date', 'timestamp', 'time_this_iter_s', 'time_total_s', 'pid', 'hostname', 'node_ip', 'time_since_restore', 'iterations_since_restore', 'timers/training_iteration_time_sec', 'timers/restore_workers_time_sec', 'timers/training_step_time_sec', 'fault_tolerance/num_healthy_workers', 'fault_tolerance/num_in_flight_async_reqs', 'fault_tolerance/num_remote_worker_restarts', 'config/placement_strategy', 'config/num_gpus', 'config/_fake_gpus', 'config/num_cpus_for_main_process', 'config/eager_tracing', 'config/eager_max_retraces', 'config/torch_compile_learner', 'config/torch_compile_learner_what_to_compile', 'config/torch_compile_learner_dynamo_backend', 'config/torch_compile_learner_dynamo_mode', 'config/torch_compile_worker', 'config/torch_compile_worker_dynamo_backend', 'config/torch_compile_worker_dynamo_mode', 'config/torch_skip_nan_gradients', 'config/enable_rl_module_and_learner', 'config/enable_env_runner_and_connector_v2', 'config/env', 'config/observation_space', 'config/action_space', 'config/clip_rewards', 'config/normalize_actions', 'config/clip_actions', 'config/_is_atari', 'config/disable_env_checking', 'config/env_task_fn', 'config/render_env', 'config/action_mask_key', 'config/env_runner_cls', 'config/num_env_runners', 'config/num_envs_per_env_runner', 'config/num_cpus_per_env_runner', 'config/num_gpus_per_env_runner', 'config/validate_env_runners_after_construction', 'config/max_requests_in_flight_per_env_runner', 'config/sample_timeout_s', 'config/_env_to_module_connector', 'config/add_default_connectors_to_env_to_module_pipeline', 'config/_module_to_env_connector', 'config/add_default_connectors_to_module_to_env_pipeline', 'config/episode_lookback_horizon', 'config/rollout_fragment_length', 'config/batch_mode', 'config/compress_observations', 'config/remote_worker_envs', 'config/remote_env_batch_wait_ms', 'config/enable_tf1_exec_eagerly', 'config/sample_collector', 'config/preprocessor_pref', 'config/observation_filter', 'config/update_worker_filter_stats', 'config/use_worker_filter_stats', 'config/sampler_perf_stats_ema_coef', 'config/num_learners', 'config/num_gpus_per_learner', 'config/num_cpus_per_learner', 'config/local_gpu_idx', 'config/gamma', 'config/lr', 'config/grad_clip', 'config/grad_clip_by', 'config/train_batch_size_per_learner', 'config/train_batch_size', 'config/num_epochs', 'config/minibatch_size', 'config/shuffle_batch_per_epoch', 'config/_learner_connector', 'config/add_default_connectors_to_learner_pipeline', 'config/_learner_class', 'config/explore', 'config/count_steps_by', 'config/policy_map_capacity', 'config/policy_mapping_fn', 'config/policies_to_train', 'config/policy_states_are_swappable', 'config/observation_fn', 'config/input_read_method', 'config/input_read_episodes', 'config/input_read_sample_batches', 'config/input_read_batch_size', 'config/input_filesystem', 'config/input_compress_columns', 'config/input_spaces_jsonable', 'config/materialize_data', 'config/materialize_mapped_data', 'config/prelearner_class', 'config/prelearner_buffer_class', 'config/prelearner_module_synch_period', 'config/dataset_num_iters_per_learner', 'config/actions_in_input_normalized', 'config/postprocess_inputs', 'config/shuffle_buffer_size', 'config/output', 'config/output_compress_columns', 'config/output_max_file_size', 'config/output_max_rows_per_file', 'config/output_write_method', 'config/output_filesystem', 'config/output_write_episodes', 'config/offline_sampling', 'config/evaluation_interval', 'config/evaluation_duration', 'config/evaluation_duration_unit', 'config/evaluation_sample_timeout_s', 'config/evaluation_parallel_to_training', 'config/evaluation_force_reset_envs_before_iteration', 'config/evaluation_config', 'config/ope_split_batch_by_episode', 'config/evaluation_num_env_runners', 'config/in_evaluation', 'config/sync_filters_on_rollout_workers_timeout_s', 'config/keep_per_episode_custom_metrics', 'config/metrics_episode_collection_timeout_s', 'config/metrics_num_episodes_for_smoothing', 'config/min_time_s_per_iteration', 'config/min_train_timesteps_per_iteration', 'config/min_sample_timesteps_per_iteration', 'config/log_gradients', 'config/export_native_model_files', 'config/checkpoint_trainable_policies_only', 'config/logger_creator', 'config/logger_config', 'config/log_level', 'config/log_sys_usage', 'config/fake_sampler', 'config/seed', 'config/_run_training_always_in_thread', 'config/_evaluation_parallel_to_training_wo_thread', 'config/restart_failed_env_runners', 'config/ignore_env_runner_failures', 'config/max_num_env_runner_restarts', 'config/delay_between_env_runner_restarts_s', 'config/restart_failed_sub_environments', 'config/num_consecutive_env_runner_failures_tolerance', 'config/env_runner_health_probe_timeout_s', 'config/env_runner_restore_timeout_s', 'config/_rl_module_spec', 'config/_torch_grad_scaler_class', 'config/_torch_lr_scheduler_classes', 'config/_tf_policy_handles_more_than_one_loss', 'config/_disable_preprocessor_api', 'config/_disable_action_flattening', 'config/_disable_initialize_loss_from_dummy_batch', 'config/_dont_auto_sync_env_runner_states', 'config/enable_connectors', 'config/simple_optimizer', 'config/policy_map_cache', 'config/worker_cls', 'config/synchronize_filters', 'config/enable_async_evaluation', 'config/custom_async_evaluation_function', 'config/_enable_rl_module_api', 'config/auto_wrap_old_gym_envs', 'config/always_attach_evaluation_results', 'config/replay_sequence_length', 'config/_disable_execution_plan_api', 'config/lr_schedule', 'config/use_critic', 'config/use_gae', 'config/use_kl_loss', 'config/kl_coeff', 'config/kl_target', 'config/vf_loss_coeff', 'config/entropy_coeff', 'config/entropy_coeff_schedule', 'config/clip_param', 'config/vf_clip_param', 'config/sgd_minibatch_size', 'config/vf_share_layers', 'config/__stdout_file__', 'config/__stderr_file__', 'config/lambda', 'config/input', 'config/callbacks', 'config/create_env_on_driver', 'config/custom_eval_function', 'config/framework', 'perf/cpu_util_percent', 'perf/ram_util_percent', 'perf/gpu_util_percent0', 'perf/vram_util_percent0', 'config/tf_session_args/intra_op_parallelism_threads', 'config/tf_session_args/inter_op_parallelism_threads', 'config/tf_session_args/log_device_placement', 'config/tf_session_args/allow_soft_placement', 'config/local_tf_session_args/intra_op_parallelism_threads', 'config/local_tf_session_args/inter_op_parallelism_threads', 'config/model/fcnet_hiddens', 'config/model/fcnet_activation', 'config/model/fcnet_weights_initializer', 'config/model/fcnet_weights_initializer_config', 'config/model/fcnet_bias_initializer', 'config/model/fcnet_bias_initializer_config', 'config/model/conv_filters', 'config/model/conv_activation', 'config/model/conv_kernel_initializer', 'config/model/conv_kernel_initializer_config', 'config/model/conv_bias_initializer', 'config/model/conv_bias_initializer_config', 'config/model/conv_transpose_kernel_initializer', 'config/model/conv_transpose_kernel_initializer_config', 'config/model/conv_transpose_bias_initializer', 'config/model/conv_transpose_bias_initializer_config', 'config/model/post_fcnet_hiddens', 'config/model/post_fcnet_activation', 'config/model/post_fcnet_weights_initializer', 'config/model/post_fcnet_weights_initializer_config', 'config/model/post_fcnet_bias_initializer', 'config/model/post_fcnet_bias_initializer_config', 'config/model/free_log_std', 'config/model/log_std_clip_param', 'config/model/no_final_linear', 'config/model/vf_share_layers', 'config/model/use_lstm', 'config/model/max_seq_len', 'config/model/lstm_cell_size', 'config/model/lstm_use_prev_action', 'config/model/lstm_use_prev_reward', 'config/model/lstm_weights_initializer', 'config/model/lstm_weights_initializer_config', 'config/model/lstm_bias_initializer', 'config/model/lstm_bias_initializer_config', 'config/model/_time_major', 'config/model/use_attention', 'config/model/attention_num_transformer_units', 'config/model/attention_dim', 'config/model/attention_num_heads', 'config/model/attention_head_dim', 'config/model/attention_memory_inference', 'config/model/attention_memory_training', 'config/model/attention_position_wise_mlp_dim', 'config/model/attention_init_gru_gate_bias', 'config/model/attention_use_n_prev_actions', 'config/model/attention_use_n_prev_rewards', 'config/model/framestack', 'config/model/dim', 'config/model/grayscale', 'config/model/zero_mean', 'config/model/custom_model', 'config/model/custom_action_dist', 'config/model/custom_preprocessor', 'config/model/encoder_latent_dim', 'config/model/always_check_shapes', 'config/model/lstm_use_prev_action_reward', 'config/model/_use_default_native_models', 'config/model/_disable_preprocessor_api', 'config/model/_disable_action_flattening', 'config/_AlgorithmConfig__prior_exploration_config/type', 'config/policies/default_policy', 'config/tf_session_args/gpu_options/allow_growth', 'config/tf_session_args/device_count/CPU']. If 'episode_reward_mean' is never reported, the run will continue until training is finished.\n",
      "2025-04-02 01:06:58,597\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-04-02 01:06:58,602\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to 'C:/Users/doore/ray_results/401-ex1' in 0.0050s.\n",
      "2025-04-02 01:07:08,681\tINFO tune.py:1041 -- Total run time: 28928.76 seconds (28918.67 seconds for the tuning loop).\n",
      "2025-04-02 01:07:08,681\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: tune.run(..., resume=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ray.tune.analysis.experiment_analysis.ExperimentAnalysis at 0x1b8aa62c740>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 실험 실행\n",
    "def short_dirname(trial):\n",
    "    return \"trial401_\" + str(trial.trial_id)\n",
    "\n",
    "import ray.tune\n",
    "\n",
    "tune.run(\n",
    "    \"PPO\",\n",
    "    name=ex_name,\n",
    "    config=algo_config,\n",
    "    stop={\"episode_reward_mean\": 195},  # 또는 원하는 조건으로 변경\n",
    "    num_samples=1,  # GridSearch, Choice 등을 활용하면 num_samples는 보통 1\n",
    "    checkpoint_at_end=True,\n",
    "    trial_dirname_creator=short_dirname,\n",
    "    storage_path='~/ray_results',\n",
    "    verbose=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd239",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
