{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada3dd6c-e196-4236-87e2-59bd12ee93c9",
   "metadata": {},
   "source": [
    "# Horcrux Joystick 입력 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d86890-4e2f-4c3e-a30c-b281c5de415b",
   "metadata": {},
   "source": [
    "## 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9f4abf-b333-49c3-9ea6-22f049e2eb51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 조이스틱 환경 삽입\n",
    "import horcrux_terrain_v2\n",
    "from horcrux_terrain_v2.envs import PlaneJoyWorld\n",
    "\n",
    "# Ray 패키지 삽입\n",
    "import ray\n",
    "import os\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import mediapy as media\n",
    "\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf2442",
   "metadata": {},
   "source": [
    "# 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e9cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_filename(base_path, ext=\".mp4\"):\n",
    "    \"\"\"중복된 파일명이 존재하면 숫자를 증가하여 새로운 경로를 반환\"\"\"\n",
    "    if not base_path.endswith(ext):\n",
    "        base_path += ext  # 확장자 자동 추가\n",
    "\n",
    "    file_name, file_ext = os.path.splitext(base_path)  # 파일명과 확장자 분리\n",
    "    count = 0\n",
    "    new_path = f\"{file_name}-episode-0\"+file_ext\n",
    "\n",
    "    while os.path.exists(new_path):  # 파일 존재 여부 확인\n",
    "        new_path = f\"{file_name}{count}-episode-0{file_ext}\"\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    return f\"rl-video{count-1}\", new_path\n",
    "\n",
    "\n",
    "def default_plot(x, y, f_name='default_plot', legends=['acc_x', 'acc_y', 'acc_z'], title=''):\n",
    "    colors = plt.get_cmap(\"tab10\").colors\n",
    "    fig, ax = plt.subplots(figsize=(15/2.54, 10/2.54))\n",
    "    ax.set_facecolor((0.95, 0.95, 0.95)) \n",
    "\n",
    "    n_column = len(np.shape(y))\n",
    "    if n_column>2:\n",
    "        print(\"The dimmension of data must be less than 3. (1D or 2D)\")\n",
    "        return -1\n",
    "    \n",
    "    n_data = np.shape(y)[1]\n",
    "\n",
    "    for i in range(n_data):\n",
    "        # **Plot**\n",
    "        ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[i], label=legends[i])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[1], label=legends[1])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[2], label=legends[2])\n",
    "\n",
    "    # **Grid 설정**\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=1, color=\"#202020\", alpha=0.7)  # 주요 그리드\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, color=\"#404040\", alpha=0.5)  # 보조 그리드\n",
    "\n",
    "    # **Axis 스타일 설정**\n",
    "    ax.spines[\"top\"].set_linewidth(1.0)\n",
    "    ax.spines[\"right\"].set_linewidth(1.0)\n",
    "    ax.spines[\"left\"].set_linewidth(1.0)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.0)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", labelsize=11, width=1.0)  # 폰트 크기 및 라인 두께\n",
    "    ax.xaxis.label.set_size(12)\n",
    "    ax.yaxis.label.set_size(12)\n",
    "\n",
    "    # **폰트 및 제목 설정**\n",
    "    plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    ax.set_xlabel(\"X-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Y-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # **Legend (MATLAB 스타일 적용)**\n",
    "    ax.legend(loc=\"upper right\", ncol=3, fontsize=10, frameon=True)\n",
    "\n",
    "    # **비율 설정 (MATLAB의 `pbaspect([2.1 1 1])`과 비슷한 효과)**\n",
    "    fig.set_size_inches(2.1 * 5, 5)  # 비율 2.1:1 (기본 높이 5inch 기준)\n",
    "\n",
    "    # **Save Figure (MATLAB saveas와 유사)**\n",
    "    plt.savefig(f\"./figs/{f_name}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, kernel, mode='same')  # 'valid'는 경계 제외\n",
    "\n",
    "\n",
    "def get_data_from_info(info):\n",
    "    # Status info\n",
    "    stat_init_rpy = np.array([_info['init_rpy'] for _info in info])\n",
    "    stat_init_com = np.array([_info['init_com'] for _info in info])\n",
    "    stat_xy_vel = np.array([[_info['x_velocity'], _info['y_velocity']] for _info in info])\n",
    "    stat_yaw_vel = np.array([_info['yaw_velocity'] for _info in info])\n",
    "    stat_quat = np.array([_info['head_quat'] for _info in info])\n",
    "    stat_ang_vel = np.array([_info['head_ang_vel'] for _info in info])\n",
    "    stat_lin_acc = np.array([_info['head_lin_acc'] for _info in info])\n",
    "    stat_motion_vector = np.array([_info['motion_vector'] for _info in info])\n",
    "    stat_com_pos = np.array([_info['com_pos'] for _info in info])\n",
    "    stat_com_ypr = np.array([_info['com_ypr'] for _info in info])\n",
    "    stat_step_ypr = np.array([_info['step_ypr'] for _info in info])\n",
    "    \n",
    "\n",
    "    # Rew info\n",
    "    rew_linear_movement = np.array([_info['reward_linear_movement'] for _info in info])\n",
    "    reward_angular_movement = np.array([_info['reward_angular_movement'] for _info in info])\n",
    "    reward_efficiency = np.array([_info['reward_efficiency'] for _info in info])\n",
    "    reward_healthy = np.array([_info['reward_healthy'] for _info in info])\n",
    "    cost_ctrl = np.array([_info['cost_ctrl'] for _info in info])\n",
    "    cost_unhealthy = np.array([_info['cost_unhealthy'] for _info in info])\n",
    "    cost_orientation = np.array([_info['cost_orientation'] for _info in info])\n",
    "    cost_yaw_vel = np.array([_info['cost_yaw_vel'] for _info in info])\n",
    "    direction_similarity = np.array([_info['direction_similarity'] for _info in info])\n",
    "    rotation_alignment = np.array([_info['rotation_alignment'] for _info in info])\n",
    "\n",
    "    # Input info\n",
    "    input_joy = np.array([_info['joy_input'] for _info in info])\n",
    "\n",
    "    data_dict = {\n",
    "        'stat_init_rpy': stat_init_rpy,\n",
    "        'stat_init_com': stat_init_com,\n",
    "        'stat_xy_vel': stat_xy_vel,\n",
    "        'stat_yaw_vel': stat_yaw_vel,\n",
    "        'stat_quat': stat_quat,\n",
    "        'stat_ang_vel': stat_ang_vel,\n",
    "        'stat_lin_acc': stat_lin_acc,\n",
    "        'stat_motion_vector': stat_motion_vector,\n",
    "        'stat_com_pos': stat_com_pos,\n",
    "        'stat_com_ypr': stat_com_ypr,\n",
    "        'stat_step_ypr': stat_step_ypr,\n",
    "\n",
    "        'rew_linear_movement': rew_linear_movement,\n",
    "        'reward_angular_movement': reward_angular_movement,\n",
    "        'reward_efficiency': reward_efficiency,\n",
    "        'reward_healthy': reward_healthy,\n",
    "        'cost_ctrl': cost_ctrl,\n",
    "        'cost_unhealthy': cost_unhealthy,\n",
    "        'cost_orientation': cost_orientation,\n",
    "        'cost_yaw_vel': cost_yaw_vel,\n",
    "        'direction_similarity': direction_similarity,\n",
    "        'rotation_alignment': rotation_alignment,\n",
    "\n",
    "        'input_joy': input_joy,\n",
    "    }\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517ec57-16da-4789-a76f-2c77998e7a5e",
   "metadata": {},
   "source": [
    "## Ray 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31cbbe-264f-4298-a2f1-471cf823d906",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407944-23a9-42b0-854b-c19f1c43bcdc",
   "metadata": {},
   "source": [
    "## Gym 환경 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6809e905-5daf-45c4-919f-98e53d97572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"forward_reward_weight\": 150.0,\n",
    "    \"rotation_reward_weight\": 100.0,\n",
    "    \"unhealthy_max_steps\": 80.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-30,30),\n",
    "    \"terminating_roll_range\": (-80,80),\n",
    "    \"rotation_norm_cost_weight\": 8.0,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 0.05,\n",
    "}\n",
    "\n",
    "render_env_config = {\n",
    "    \"forward_reward_weight\": 60.0,\n",
    "    \"rotation_reward_weight\": 40.0,\n",
    "    \"unhealthy_max_steps\": 100.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-35,35),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 1.5,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"render_mode\": \"rgb_array\",\n",
    "    \"render_camera_name\": 'ceiling',\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 1.5,\n",
    "}\n",
    "\n",
    "# env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     rotation_reward_weight=env_config[\"rotation_reward_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                     use_imu_window=env_config[\"use_imu_window\"],\n",
    "                                                     ctrl_cost_weight=env_config[\"ctrl_cost_weight\"],\n",
    "                                                   )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf2134-3167-46f1-b28b-7d305065f559",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436edebc-bcaa-45fa-9941-58ad2868655b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SACConfig()\n",
    "\n",
    "# 구형 API 구조 사용\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "\n",
    "config.environment(\"joy-v1\")\n",
    "config.framework(\"torch\")\n",
    "\n",
    "# 병렬 CPU 사용 설정\n",
    "total_workers = 16\n",
    "config.resources(num_gpus=1)\n",
    "config.env_runners(num_env_runners = total_workers, num_cpus_per_env_runner = 1, num_gpus_per_env_runner = 0.3/(total_workers), rollout_fragment_length = 1000)\n",
    "config.training(\n",
    "    gamma=0.95,\n",
    "    replay_buffer_config={\n",
    "    \"_enable_replay_buffer_api\": True,\n",
    "    \"capacity\": int(1000000),\n",
    "    \"type\": \"MultiAgentReplayBuffer\",\n",
    "    \"replay_batch_size\": 10000,\n",
    "    # If True prioritized replay buffer will be used.\n",
    "    # \"prioritized_replay\": False,\n",
    "    # \"prioritized_replay_alpha\": 0.6,\n",
    "    # \"prioritized_replay_beta\": 0.4,\n",
    "    # \"prioritized_replay_eps\": 1e-6,\n",
    "    # Whether to compute priorities already on the remote worker side.\n",
    "    # \"worker_side_prioritization\": False,\n",
    "    },\n",
    "\n",
    "    q_model_config = {\n",
    "            \"fcnet_hiddens\": [100, 100, 256, 256, 100, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "    policy_model_config = {\n",
    "            \"fcnet_hiddens\": [100, 100, 256, 256, 100, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define a custom policy model.\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "\n",
    "    train_batch_size = 100000,\n",
    "    num_steps_sampled_before_learning_starts = 200000,\n",
    ")\n",
    "\n",
    "algo = config.build()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae756f-bb08-4813-bf07-c019392dac99",
   "metadata": {},
   "source": [
    "## 학습시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae0dfe-e461-442b-b090-cc437723543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import datetime\n",
    "from scipy.io import savemat\n",
    "\n",
    "n_iter = 6000\n",
    "save_iter = 0\n",
    "save_name = \"SAC_layer_small_friction_joy_imu_rot0_326\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}\", end=\", \")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%100 == 0:\n",
    "        checkpoint_dir = algo.save(save_name+\"_\"+str(save_iter))\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "\n",
    "        # Record Validation Env\n",
    "        env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "        obs = env.reset()[0]\n",
    "        env_done = False\n",
    "\n",
    "        _video_base_name = 'rl-video'\n",
    "\n",
    "        rew_return = 0\n",
    "        frames = []\n",
    "        info = []\n",
    "\n",
    "        for i in range(1000):\n",
    "            act = algo.compute_single_action(observation=obs)\n",
    "            obs, _step_rew, _, env_done, env_info = env.step(act)\n",
    "            pixels = env.render()\n",
    "            frames.append(pixels)\n",
    "            info.append(env_info)\n",
    "            rew_return += _step_rew\n",
    "\n",
    "        _f_name, _full_path = get_unique_filename(f\"./video/{_video_base_name}\")\n",
    "        rew_dict = get_data_from_info(info)\n",
    "        rew_dict['rew_return'] = rew_return\n",
    "\n",
    "        # Save Video\n",
    "        save_video(frames, \"./video/\", name_prefix=_f_name, fps=env.metadata['render_fps'])\n",
    "\n",
    "        # Save Video Info\n",
    "        _f_video_info = open(f\"./video/joy_input.txt\", 'a')\n",
    "        _f_video_info.write(f'File creation time: {datetime.datetime.now()}\\n')\n",
    "        _f_video_info.write(f'Video file name: {_f_name}, Joy input: {info[0][\"joy_input\"]}, Friction: {info[0][\"friction_coeff\"]}\\n')\n",
    "        _f_video_info.close()\n",
    "\n",
    "        # Save Reward Info mat file\n",
    "        savemat(f\"./data/{save_name}_{_f_name}.mat\", rew_dict)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "\n",
    "algo.save(save_name+str(\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055f640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd239",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
