{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada3dd6c-e196-4236-87e2-59bd12ee93c9",
   "metadata": {},
   "source": [
    "# Horcrux Joystick 입력 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d86890-4e2f-4c3e-a30c-b281c5de415b",
   "metadata": {},
   "source": [
    "## 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca9f4abf-b333-49c3-9ea6-22f049e2eb51",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 조이스틱 환경 삽입\n",
    "import horcrux_terrain_v2\n",
    "from horcrux_terrain_v2.envs import PlaneJoyWorld\n",
    "\n",
    "# Ray 패키지 삽입\n",
    "import ray\n",
    "import os\n",
    "from ray.rllib.algorithms.algorithm import Algorithm\n",
    "from ray.rllib.algorithms.sac import SACConfig\n",
    "\n",
    "from ray.tune.registry import register_env\n",
    "\n",
    "import mediapy as media\n",
    "\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from gymnasium.utils.save_video import save_video\n",
    "\n",
    "from IPython.display import Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93044ef8",
   "metadata": {},
   "source": [
    "# 사용자 구성 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfe50062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from ray.rllib.models.torch.torch_modelv2 import TorchModelV2\n",
    "from ray.rllib.models.torch.fcnet import FullyConnectedNetwork\n",
    "from ray.rllib.models import ModelCatalog\n",
    "\n",
    "class CustomSACModel(TorchModelV2, nn.Module):\n",
    "    def __init__(self, obs_space, action_space, num_outputs, model_config, name):\n",
    "        TorchModelV2.__init__(self, obs_space, action_space, num_outputs, model_config, name)\n",
    "        nn.Module.__init__(self)\n",
    "\n",
    "        model_shape = model_config['fcnet_hiddens']\n",
    "        print(model_config)\n",
    "\n",
    "        # Shared actor trunk\n",
    "        self.shared = FullyConnectedNetwork(\n",
    "            obs_space, action_space, model_shape[-1], model_config, name + \"_shared\"\n",
    "        )\n",
    "\n",
    "        # Value network head 확장\n",
    "        self.value_branch = nn.Sequential(\n",
    "            nn.Linear(model_shape[-1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "        self._value_out = None\n",
    "\n",
    "    def forward(self, input_dict, state, seq_lens):\n",
    "        features, _ = self.shared(input_dict, state, seq_lens)\n",
    "        self._value_out = self.value_branch(features)\n",
    "        return features, state\n",
    "\n",
    "    def value_function(self):\n",
    "        return self._value_out.squeeze(1)\n",
    "    \n",
    "    \n",
    "ModelCatalog.register_custom_model(\"custom_sac_model\", CustomSACModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdf2442",
   "metadata": {},
   "source": [
    "# 필요 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e9cde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_filename(base_path, ext=\".mp4\"):\n",
    "    \"\"\"중복된 파일명이 존재하면 숫자를 증가하여 새로운 경로를 반환\"\"\"\n",
    "    if not base_path.endswith(ext):\n",
    "        base_path += ext  # 확장자 자동 추가\n",
    "\n",
    "    file_name, file_ext = os.path.splitext(base_path)  # 파일명과 확장자 분리\n",
    "    count = 0\n",
    "    new_path = f\"{file_name}-episode-0\"+file_ext\n",
    "\n",
    "    while os.path.exists(new_path):  # 파일 존재 여부 확인\n",
    "        new_path = f\"{file_name}{count}-episode-0{file_ext}\"\n",
    "        count += 1\n",
    "\n",
    "\n",
    "    return f\"rl-video{count-1}\", new_path\n",
    "\n",
    "\n",
    "def default_plot(x, y, f_name='default_plot', legends=['acc_x', 'acc_y', 'acc_z'], title=''):\n",
    "    colors = plt.get_cmap(\"tab10\").colors\n",
    "    fig, ax = plt.subplots(figsize=(15/2.54, 10/2.54))\n",
    "    ax.set_facecolor((0.95, 0.95, 0.95)) \n",
    "\n",
    "    n_column = len(np.shape(y))\n",
    "    if n_column>2:\n",
    "        print(\"The dimmension of data must be less than 3. (1D or 2D)\")\n",
    "        return -1\n",
    "    \n",
    "    n_data = np.shape(y)[1]\n",
    "\n",
    "    for i in range(n_data):\n",
    "        # **Plot**\n",
    "        ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[i], label=legends[i])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[1], label=legends[1])\n",
    "        # ax.plot(x, y[:,i], linewidth=1.5, linestyle=\"-\", color=colors[2], label=legends[2])\n",
    "\n",
    "    # **Grid 설정**\n",
    "    ax.grid(True, linestyle=\"--\", linewidth=1, color=\"#202020\", alpha=0.7)  # 주요 그리드\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.5, color=\"#404040\", alpha=0.5)  # 보조 그리드\n",
    "\n",
    "    # **Axis 스타일 설정**\n",
    "    ax.spines[\"top\"].set_linewidth(1.0)\n",
    "    ax.spines[\"right\"].set_linewidth(1.0)\n",
    "    ax.spines[\"left\"].set_linewidth(1.0)\n",
    "    ax.spines[\"bottom\"].set_linewidth(1.0)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", labelsize=11, width=1.0)  # 폰트 크기 및 라인 두께\n",
    "    ax.xaxis.label.set_size(12)\n",
    "    ax.yaxis.label.set_size(12)\n",
    "\n",
    "    # **폰트 및 제목 설정**\n",
    "    plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "    ax.set_xlabel(\"X-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_ylabel(\"Y-Axis\", fontsize=12, fontweight=\"bold\")\n",
    "    ax.set_title(title, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "    # **Legend (MATLAB 스타일 적용)**\n",
    "    ax.legend(loc=\"upper right\", ncol=3, fontsize=10, frameon=True)\n",
    "\n",
    "    # **비율 설정 (MATLAB의 `pbaspect([2.1 1 1])`과 비슷한 효과)**\n",
    "    fig.set_size_inches(2.1 * 5, 5)  # 비율 2.1:1 (기본 높이 5inch 기준)\n",
    "\n",
    "    # **Save Figure (MATLAB saveas와 유사)**\n",
    "    plt.savefig(f\"./figs/{f_name}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def moving_average(data, window_size):\n",
    "    kernel = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, kernel, mode='same')  # 'valid'는 경계 제외\n",
    "\n",
    "\n",
    "def get_data_from_info(info):\n",
    "    # Status info\n",
    "    stat_init_rpy = np.array([_info['init_rpy'] for _info in info])\n",
    "    stat_init_com = np.array([_info['init_com'] for _info in info])\n",
    "    stat_xy_vel = np.array([[_info['x_velocity'], _info['y_velocity']] for _info in info])\n",
    "    stat_yaw_vel = np.array([_info['yaw_velocity'] for _info in info])\n",
    "    stat_quat = np.array([_info['head_quat'] for _info in info])\n",
    "    stat_ang_vel = np.array([_info['head_ang_vel'] for _info in info])\n",
    "    stat_lin_acc = np.array([_info['head_lin_acc'] for _info in info])\n",
    "    stat_motion_vector = np.array([_info['motion_vector'] for _info in info])\n",
    "    stat_com_pos = np.array([_info['com_pos'] for _info in info])\n",
    "    stat_com_ypr = np.array([_info['com_ypr'] for _info in info])\n",
    "    stat_step_ypr = np.array([_info['step_ypr'] for _info in info])\n",
    "    \n",
    "\n",
    "    # Rew info\n",
    "    rew_linear_movement = np.array([_info['reward_linear_movement'] for _info in info])\n",
    "    reward_angular_movement = np.array([_info['reward_angular_movement'] for _info in info])\n",
    "    reward_efficiency = np.array([_info['reward_efficiency'] for _info in info])\n",
    "    reward_healthy = np.array([_info['reward_healthy'] for _info in info])\n",
    "    cost_ctrl = np.array([_info['cost_ctrl'] for _info in info])\n",
    "    cost_unhealthy = np.array([_info['cost_unhealthy'] for _info in info])\n",
    "    cost_orientation = np.array([_info['cost_orientation'] for _info in info])\n",
    "    cost_yaw_vel = np.array([_info['cost_yaw_vel'] for _info in info])\n",
    "    direction_similarity = np.array([_info['direction_similarity'] for _info in info])\n",
    "    rotation_alignment = np.array([_info['rotation_alignment'] for _info in info])\n",
    "\n",
    "    # Input info\n",
    "    input_joy = np.array([_info['joy_input'] for _info in info])\n",
    "\n",
    "    data_dict = {\n",
    "        'stat_init_rpy': stat_init_rpy,\n",
    "        'stat_init_com': stat_init_com,\n",
    "        'stat_xy_vel': stat_xy_vel,\n",
    "        'stat_yaw_vel': stat_yaw_vel,\n",
    "        'stat_quat': stat_quat,\n",
    "        'stat_ang_vel': stat_ang_vel,\n",
    "        'stat_lin_acc': stat_lin_acc,\n",
    "        'stat_motion_vector': stat_motion_vector,\n",
    "        'stat_com_pos': stat_com_pos,\n",
    "        'stat_com_ypr': stat_com_ypr,\n",
    "        'stat_step_ypr': stat_step_ypr,\n",
    "\n",
    "        'rew_linear_movement': rew_linear_movement,\n",
    "        'reward_angular_movement': reward_angular_movement,\n",
    "        'reward_efficiency': reward_efficiency,\n",
    "        'reward_healthy': reward_healthy,\n",
    "        'cost_ctrl': cost_ctrl,\n",
    "        'cost_unhealthy': cost_unhealthy,\n",
    "        'cost_orientation': cost_orientation,\n",
    "        'cost_yaw_vel': cost_yaw_vel,\n",
    "        'direction_similarity': direction_similarity,\n",
    "        'rotation_alignment': rotation_alignment,\n",
    "\n",
    "        'input_joy': input_joy,\n",
    "    }\n",
    "    \n",
    "    return data_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6517ec57-16da-4789-a76f-2c77998e7a5e",
   "metadata": {},
   "source": [
    "## Ray 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df31cbbe-264f-4298-a2f1-471cf823d906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:14:48,139\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://10.130.6.78:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fcb82d38ba34804833eec3202c3f923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.12.9</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.39.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.130.6.78:8265\" target=\"_blank\">http://10.130.6.78:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='10.130.6.78:8265', python_version='3.12.9', ray_version='2.39.0', ray_commit='5a6c33536df3f6ed5e987a169b82739bb7e3d80e')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m [2025-03-28 09:47:48,746 E 5316 5316] (raylet) node_manager.cc:3069: 1 Workers (tasks / actors) killed due to memory pressure (OOM), 0 Workers crashed due to other reasons at node (ID: e4a10df36715847ab63558bbfa56d4a9b0ea7bbd45032987c3bf7c8d, IP: 10.130.6.78) over the last time period. To see more information about the Workers killed on this node, use `ray logs raylet.out -ip 10.130.6.78`\n",
      "\u001b[33m(raylet)\u001b[0m \n",
      "\u001b[33m(raylet)\u001b[0m Refer to the documentation on how to address the out of memory issue: https://docs.ray.io/en/latest/ray-core/scheduling/ray-oom-prevention.html. Consider provisioning more memory on this node or reducing task parallelism by requesting more CPUs per task. To adjust the kill threshold, set the environment variable `RAY_memory_usage_threshold` when starting Ray. To disable worker killing, set the environment variable `RAY_memory_monitor_refresh_ms` to zero.\n"
     ]
    }
   ],
   "source": [
    "ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39407944-23a9-42b0-854b-c19f1c43bcdc",
   "metadata": {},
   "source": [
    "## Gym 환경 등록하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6809e905-5daf-45c4-919f-98e53d97572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"gait_sampling_interval\": 0.01,\n",
    "    \"forward_reward_weight\": 200.0,\n",
    "    \"rotation_reward_weight\": 100.0,\n",
    "    \"unhealthy_max_steps\": 80.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-30,30),\n",
    "    \"terminating_roll_range\": (-80,80),\n",
    "    \"rotation_norm_cost_weight\": 8.0,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 0.05,\n",
    "}\n",
    "\n",
    "render_env_config = {\n",
    "    \"forward_reward_weight\": 60.0,\n",
    "    \"rotation_reward_weight\": 40.0,\n",
    "    \"unhealthy_max_steps\": 100.0,\n",
    "    \"healthy_reward\": 3.0,\n",
    "    \"healthy_roll_range\": (-35,35),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 1.5,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 40, 40, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "    \"render_mode\": \"rgb_array\",\n",
    "    \"render_camera_name\": 'ceiling',\n",
    "    \"use_imu_window\": True,\n",
    "    \"ctrl_cost_weight\": 1.5,\n",
    "}\n",
    "\n",
    "# env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     rotation_reward_weight=env_config[\"rotation_reward_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                     use_imu_window=env_config[\"use_imu_window\"],\n",
    "                                                     ctrl_cost_weight=env_config[\"ctrl_cost_weight\"],\n",
    "                                                   )\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbf2134-3167-46f1-b28b-7d305065f559",
   "metadata": {},
   "source": [
    "## 학습 알고리즘 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "436edebc-bcaa-45fa-9941-58ad2868655b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:567: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-03-27 16:15:01,640\tINFO trainable.py:161 -- Trainable.setup took 12.960 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = SACConfig()\n",
    "\n",
    "# 구형 API 구조 사용\n",
    "config.api_stack(\n",
    "    enable_rl_module_and_learner=False,\n",
    "    enable_env_runner_and_connector_v2=False,\n",
    ")\n",
    "\n",
    "config.environment(\"joy-v1\")\n",
    "config.framework(\"torch\")\n",
    "\n",
    "# 병렬 CPU 사용 설정\n",
    "total_workers = 16\n",
    "config.resources(num_gpus=1)\n",
    "config.learners(num_learners = 1, num_gpus_per_learner=0.6)\n",
    "config.env_runners(num_env_runners = total_workers, num_cpus_per_env_runner = 1, num_gpus_per_env_runner = 0.3/(total_workers), rollout_fragment_length = 5000)\n",
    "config.training(\n",
    "    gamma=0.95,\n",
    "    replay_buffer_config={\n",
    "    \"_enable_replay_buffer_api\": True,\n",
    "    \"capacity\": int(1000000),\n",
    "    \"type\": \"MultiAgentPrioritizedReplayBuffer\",\n",
    "    \"replay_batch_size\": 10000,\n",
    "    # If True prioritized replay buffer will be used.\n",
    "    \"prioritized_replay\": True,\n",
    "    \"prioritized_replay_alpha\": 0.6,\n",
    "    \"prioritized_replay_beta\": 0.4,\n",
    "    \"prioritized_replay_eps\": 1e-6,\n",
    "    # Whether to compute priorities already on the remote worker side.\n",
    "    # \"worker_side_prioritization\": False,\n",
    "    },\n",
    "\n",
    "    # Custom model 사용 (잘 안됨)\n",
    "    # model={\n",
    "    #     \"custom_model\": \"custom_sac_model\",  # ValueNetwork MLP 사용\n",
    "    #     \"custom_model_config\": {},\n",
    "    #     \"fcnet_hiddens\": [512, 512, 512, 512, 512, 32],\n",
    "    #     \"fcnet_activation\": \"tanh\",\n",
    "    #     \"post_fcnet_hiddens\": [],\n",
    "    #     \"post_fcnet_activation\": None,\n",
    "    #     \"vf_share_layers\": False,\n",
    "    # },\n",
    "\n",
    "    q_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 512],\n",
    "            \"fcnet_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": \"tanh\",\n",
    "            \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "    policy_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 512],\n",
    "            \"fcnet_activation\": \"relu\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": \"tanh\",\n",
    "            \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "            \"custom_model_config\": {},\n",
    "    },\n",
    "\n",
    "    minibatch_size = 10000,\n",
    "    train_batch_size = 100000,\n",
    "    num_steps_sampled_before_learning_starts = 200000,\n",
    ")\n",
    "\n",
    "algo = config.build()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eefac126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_AlgorithmConfig__prior_exploration_config': None,\n",
      " '_deterministic_loss': False,\n",
      " '_disable_action_flattening': False,\n",
      " '_disable_execution_plan_api': -1,\n",
      " '_disable_initialize_loss_from_dummy_batch': False,\n",
      " '_disable_preprocessor_api': False,\n",
      " '_dont_auto_sync_env_runner_states': False,\n",
      " '_enable_rl_module_api': -1,\n",
      " '_env_to_module_connector': None,\n",
      " '_evaluation_parallel_to_training_wo_thread': False,\n",
      " '_fake_gpus': False,\n",
      " '_is_atari': None,\n",
      " '_learner_class': None,\n",
      " '_learner_connector': None,\n",
      " '_model_config': {},\n",
      " '_module_to_env_connector': None,\n",
      " '_per_module_overrides': {},\n",
      " '_rl_module_spec': None,\n",
      " '_run_training_always_in_thread': False,\n",
      " '_tf_policy_handles_more_than_one_loss': False,\n",
      " '_torch_grad_scaler_class': None,\n",
      " '_torch_lr_scheduler_classes': None,\n",
      " '_use_beta_distribution': False,\n",
      " 'action_mask_key': 'action_mask',\n",
      " 'action_space': None,\n",
      " 'actions_in_input_normalized': False,\n",
      " 'actor_lr': 3e-05,\n",
      " 'add_default_connectors_to_env_to_module_pipeline': True,\n",
      " 'add_default_connectors_to_learner_pipeline': True,\n",
      " 'add_default_connectors_to_module_to_env_pipeline': True,\n",
      " 'algorithm_config_overrides_per_module': {},\n",
      " 'alpha_lr': 0.0003,\n",
      " 'always_attach_evaluation_results': -1,\n",
      " 'auto_wrap_old_gym_envs': -1,\n",
      " 'batch_mode': 'truncate_episodes',\n",
      " 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>,\n",
      " 'checkpoint_trainable_policies_only': False,\n",
      " 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>,\n",
      " 'clip_actions': False,\n",
      " 'clip_rewards': None,\n",
      " 'compress_observations': False,\n",
      " 'count_steps_by': 'env_steps',\n",
      " 'create_env_on_driver': False,\n",
      " 'critic_lr': 0.0003,\n",
      " 'custom_async_evaluation_function': -1,\n",
      " 'custom_eval_function': None,\n",
      " 'custom_resources_per_env_runner': {},\n",
      " 'dataset_num_iters_per_learner': None,\n",
      " 'delay_between_env_runner_restarts_s': 60.0,\n",
      " 'disable_env_checking': False,\n",
      " 'eager_max_retraces': 20,\n",
      " 'eager_tracing': True,\n",
      " 'enable_async_evaluation': -1,\n",
      " 'enable_connectors': -1,\n",
      " 'enable_env_runner_and_connector_v2': False,\n",
      " 'enable_rl_module_and_learner': False,\n",
      " 'enable_tf1_exec_eagerly': False,\n",
      " 'env': 'joy-v1',\n",
      " 'env_config': {},\n",
      " 'env_runner_cls': None,\n",
      " 'env_runner_health_probe_timeout_s': 30.0,\n",
      " 'env_runner_restore_timeout_s': 1800.0,\n",
      " 'env_task_fn': None,\n",
      " 'episode_lookback_horizon': 1,\n",
      " 'evaluation_config': None,\n",
      " 'evaluation_duration': 10,\n",
      " 'evaluation_duration_unit': 'episodes',\n",
      " 'evaluation_force_reset_envs_before_iteration': True,\n",
      " 'evaluation_interval': None,\n",
      " 'evaluation_num_env_runners': 0,\n",
      " 'evaluation_parallel_to_training': False,\n",
      " 'evaluation_sample_timeout_s': 120.0,\n",
      " 'exploration_config': {'type': 'StochasticSampling'},\n",
      " 'explore': True,\n",
      " 'export_native_model_files': False,\n",
      " 'extra_python_environs_for_driver': {},\n",
      " 'extra_python_environs_for_worker': {},\n",
      " 'fake_sampler': False,\n",
      " 'framework': 'torch',\n",
      " 'gamma': 0.95,\n",
      " 'grad_clip': None,\n",
      " 'grad_clip_by': 'global_norm',\n",
      " 'ignore_env_runner_failures': False,\n",
      " 'in_evaluation': False,\n",
      " 'initial_alpha': 1.0,\n",
      " 'input': 'sampler',\n",
      " 'input_compress_columns': ['obs', 'new_obs'],\n",
      " 'input_config': {},\n",
      " 'input_filesystem': None,\n",
      " 'input_filesystem_kwargs': {},\n",
      " 'input_read_batch_size': None,\n",
      " 'input_read_episodes': False,\n",
      " 'input_read_method': 'read_parquet',\n",
      " 'input_read_method_kwargs': {},\n",
      " 'input_read_sample_batches': False,\n",
      " 'input_read_schema': {},\n",
      " 'input_spaces_jsonable': True,\n",
      " 'iter_batches_kwargs': {},\n",
      " 'keep_per_episode_custom_metrics': False,\n",
      " 'learner_config_dict': {},\n",
      " 'local_gpu_idx': 0,\n",
      " 'local_tf_session_args': {'inter_op_parallelism_threads': 8,\n",
      "                           'intra_op_parallelism_threads': 8},\n",
      " 'log_gradients': True,\n",
      " 'log_level': 'WARN',\n",
      " 'log_sys_usage': True,\n",
      " 'logger_config': None,\n",
      " 'logger_creator': None,\n",
      " 'lr': None,\n",
      " 'map_batches_kwargs': {},\n",
      " 'materialize_data': False,\n",
      " 'materialize_mapped_data': True,\n",
      " 'max_num_env_runner_restarts': 1000,\n",
      " 'max_requests_in_flight_per_env_runner': 2,\n",
      " 'metrics_episode_collection_timeout_s': 60.0,\n",
      " 'metrics_num_episodes_for_smoothing': 100,\n",
      " 'min_sample_timesteps_per_iteration': 100,\n",
      " 'min_time_s_per_iteration': 1,\n",
      " 'min_train_timesteps_per_iteration': 0,\n",
      " 'minibatch_size': 10000,\n",
      " 'model': {'_disable_action_flattening': False,\n",
      "           '_disable_preprocessor_api': False,\n",
      "           '_time_major': False,\n",
      "           '_use_default_native_models': -1,\n",
      "           'always_check_shapes': False,\n",
      "           'attention_dim': 64,\n",
      "           'attention_head_dim': 32,\n",
      "           'attention_init_gru_gate_bias': 2.0,\n",
      "           'attention_memory_inference': 50,\n",
      "           'attention_memory_training': 50,\n",
      "           'attention_num_heads': 1,\n",
      "           'attention_num_transformer_units': 1,\n",
      "           'attention_position_wise_mlp_dim': 32,\n",
      "           'attention_use_n_prev_actions': 0,\n",
      "           'attention_use_n_prev_rewards': 0,\n",
      "           'conv_activation': 'relu',\n",
      "           'conv_bias_initializer': None,\n",
      "           'conv_bias_initializer_config': None,\n",
      "           'conv_filters': None,\n",
      "           'conv_kernel_initializer': None,\n",
      "           'conv_kernel_initializer_config': None,\n",
      "           'conv_transpose_bias_initializer': None,\n",
      "           'conv_transpose_bias_initializer_config': None,\n",
      "           'conv_transpose_kernel_initializer': None,\n",
      "           'conv_transpose_kernel_initializer_config': None,\n",
      "           'custom_action_dist': None,\n",
      "           'custom_model': None,\n",
      "           'custom_model_config': {},\n",
      "           'custom_preprocessor': None,\n",
      "           'dim': 84,\n",
      "           'encoder_latent_dim': None,\n",
      "           'fcnet_activation': 'tanh',\n",
      "           'fcnet_bias_initializer': None,\n",
      "           'fcnet_bias_initializer_config': None,\n",
      "           'fcnet_hiddens': [256, 256],\n",
      "           'fcnet_weights_initializer': None,\n",
      "           'fcnet_weights_initializer_config': None,\n",
      "           'framestack': True,\n",
      "           'free_log_std': False,\n",
      "           'grayscale': False,\n",
      "           'log_std_clip_param': 20.0,\n",
      "           'lstm_bias_initializer': None,\n",
      "           'lstm_bias_initializer_config': None,\n",
      "           'lstm_cell_size': 256,\n",
      "           'lstm_use_prev_action': False,\n",
      "           'lstm_use_prev_action_reward': -1,\n",
      "           'lstm_use_prev_reward': False,\n",
      "           'lstm_weights_initializer': None,\n",
      "           'lstm_weights_initializer_config': None,\n",
      "           'max_seq_len': 20,\n",
      "           'no_final_linear': False,\n",
      "           'post_fcnet_activation': 'relu',\n",
      "           'post_fcnet_bias_initializer': None,\n",
      "           'post_fcnet_bias_initializer_config': None,\n",
      "           'post_fcnet_hiddens': [],\n",
      "           'post_fcnet_weights_initializer': None,\n",
      "           'post_fcnet_weights_initializer_config': None,\n",
      "           'use_attention': False,\n",
      "           'use_lstm': False,\n",
      "           'vf_share_layers': True,\n",
      "           'zero_mean': True},\n",
      " 'n_step': 1,\n",
      " 'normalize_actions': True,\n",
      " 'num_consecutive_env_runner_failures_tolerance': 100,\n",
      " 'num_cpus_for_main_process': 1,\n",
      " 'num_cpus_per_env_runner': 1,\n",
      " 'num_cpus_per_learner': 1,\n",
      " 'num_env_runners': 16,\n",
      " 'num_envs_per_env_runner': 1,\n",
      " 'num_epochs': 1,\n",
      " 'num_gpus': 1,\n",
      " 'num_gpus_per_env_runner': 0.01875,\n",
      " 'num_gpus_per_learner': 0.6,\n",
      " 'num_learners': 1,\n",
      " 'num_steps_sampled_before_learning_starts': 200000,\n",
      " 'observation_filter': 'NoFilter',\n",
      " 'observation_fn': None,\n",
      " 'observation_space': None,\n",
      " 'off_policy_estimation_methods': {},\n",
      " 'offline_sampling': False,\n",
      " 'ope_split_batch_by_episode': True,\n",
      " 'optimization': {'actor_learning_rate': 0.0003,\n",
      "                  'critic_learning_rate': 0.0003,\n",
      "                  'entropy_learning_rate': 0.0003},\n",
      " 'optimizer': {},\n",
      " 'output': None,\n",
      " 'output_compress_columns': ['obs', 'new_obs'],\n",
      " 'output_config': {},\n",
      " 'output_filesystem': None,\n",
      " 'output_filesystem_kwargs': {},\n",
      " 'output_max_file_size': 67108864,\n",
      " 'output_max_rows_per_file': None,\n",
      " 'output_write_episodes': True,\n",
      " 'output_write_method': 'write_parquet',\n",
      " 'output_write_method_kwargs': {},\n",
      " 'placement_strategy': 'PACK',\n",
      " 'policies': {'default_policy': (None, None, None, None)},\n",
      " 'policies_to_train': None,\n",
      " 'policy_map_cache': -1,\n",
      " 'policy_map_capacity': 100,\n",
      " 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>,\n",
      " 'policy_model_config': {'custom_model': None,\n",
      "                         'custom_model_config': {},\n",
      "                         'fcnet_activation': 'relu',\n",
      "                         'fcnet_hiddens': [512, 512, 512, 512, 512, 512],\n",
      "                         'post_fcnet_activation': 'tanh',\n",
      "                         'post_fcnet_hiddens': []},\n",
      " 'policy_states_are_swappable': False,\n",
      " 'postprocess_inputs': False,\n",
      " 'prelearner_buffer_class': None,\n",
      " 'prelearner_buffer_kwargs': {},\n",
      " 'prelearner_class': None,\n",
      " 'prelearner_module_synch_period': 10,\n",
      " 'preprocessor_pref': 'deepmind',\n",
      " 'q_model_config': {'custom_model': None,\n",
      "                    'custom_model_config': {},\n",
      "                    'fcnet_activation': 'relu',\n",
      "                    'fcnet_hiddens': [512, 512, 512, 512, 512, 512],\n",
      "                    'post_fcnet_activation': 'tanh',\n",
      "                    'post_fcnet_hiddens': []},\n",
      " 'remote_env_batch_wait_ms': 0,\n",
      " 'remote_worker_envs': False,\n",
      " 'render_env': False,\n",
      " 'replay_buffer_config': {'_enable_replay_buffer_api': True,\n",
      "                          'capacity': 1000000,\n",
      "                          'prioritized_replay': True,\n",
      "                          'prioritized_replay_alpha': 0.6,\n",
      "                          'prioritized_replay_beta': 0.4,\n",
      "                          'prioritized_replay_eps': 1e-06,\n",
      "                          'replay_batch_size': 10000,\n",
      "                          'type': 'MultiAgentPrioritizedReplayBuffer'},\n",
      " 'replay_sequence_length': None,\n",
      " 'restart_failed_env_runners': True,\n",
      " 'restart_failed_sub_environments': False,\n",
      " 'rollout_fragment_length': 5000,\n",
      " 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>,\n",
      " 'sample_timeout_s': 60.0,\n",
      " 'sampler_perf_stats_ema_coef': None,\n",
      " 'seed': None,\n",
      " 'shuffle_batch_per_epoch': False,\n",
      " 'shuffle_buffer_size': 0,\n",
      " 'simple_optimizer': False,\n",
      " 'store_buffer_in_checkpoints': False,\n",
      " 'sync_filters_on_rollout_workers_timeout_s': 10.0,\n",
      " 'synchronize_filters': -1,\n",
      " 'target_entropy': 'auto',\n",
      " 'target_network_update_freq': 0,\n",
      " 'tau': 0.005,\n",
      " 'tf_session_args': {'allow_soft_placement': True,\n",
      "                     'device_count': {'CPU': 1},\n",
      "                     'gpu_options': {'allow_growth': True},\n",
      "                     'inter_op_parallelism_threads': 2,\n",
      "                     'intra_op_parallelism_threads': 2,\n",
      "                     'log_device_placement': False},\n",
      " 'torch_compile_learner': False,\n",
      " 'torch_compile_learner_dynamo_backend': 'inductor',\n",
      " 'torch_compile_learner_dynamo_mode': None,\n",
      " 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>,\n",
      " 'torch_compile_worker': False,\n",
      " 'torch_compile_worker_dynamo_backend': 'onnxrt',\n",
      " 'torch_compile_worker_dynamo_mode': None,\n",
      " 'torch_ddp_kwargs': {},\n",
      " 'torch_skip_nan_gradients': False,\n",
      " 'train_batch_size': 100000,\n",
      " 'train_batch_size_per_learner': 256,\n",
      " 'training_intensity': None,\n",
      " 'twin_q': True,\n",
      " 'update_worker_filter_stats': True,\n",
      " 'use_state_preprocessor': -1,\n",
      " 'use_worker_filter_stats': True,\n",
      " 'validate_env_runners_after_construction': True,\n",
      " 'worker_cls': -1,\n",
      " 'worker_side_prioritization': -1}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(algo.get_config().to_dict())\n",
    "# algo.get_default_policy_class(config)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ae756f-bb08-4813-bf07-c019392dac99",
   "metadata": {},
   "source": [
    "## 학습시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2ae0dfe-e461-442b-b090-cc437723543f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:15:54,478\tWARNING multi_agent_prioritized_replay_buffer.py:215 -- Adding batches with column `weights` to this buffer while providing weights as a call argument to the add method results in the column being overwritten.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_0), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {}, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 0}, 'env_runners': {'episode_reward_max': nan, 'episode_reward_min': nan, 'episode_reward_mean': nan, 'episode_len_mean': nan, 'episode_media': {}, 'episodes_timesteps_total': 0, 'policy_reward_min': {}, 'policy_reward_max': {}, 'policy_reward_mean': {}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [], 'episode_lengths': []}, 'sampler_perf': {}, 'num_faulty_episodes': 0, 'connector_metrics': {}, 'num_episodes': 0, 'episode_return_max': nan, 'episode_return_min': nan, 'episode_return_mean': nan, 'episodes_this_iter': 0}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 0, 'num_env_steps_sampled': 80000, 'num_env_steps_trained': 0, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 0, 'num_env_steps_sampled_throughput_per_sec': 1489.6991211456618, 'num_env_steps_trained_throughput_per_sec': 0.0, 'timesteps_total': 80000, 'num_env_steps_sampled_lifetime': 80000, 'num_agent_steps_sampled_lifetime': 80000, 'num_steps_trained_this_iter': 0, 'agent_timesteps_total': 80000, 'timers': {'training_iteration_time_ms': 53702.127, 'restore_workers_time_ms': 0.016, 'training_step_time_ms': 53702.081, 'sample_time_ms': 50722.085}, 'counters': {'num_env_steps_sampled': 80000, 'num_env_steps_trained': 0, 'num_agent_steps_sampled': 80000, 'num_agent_steps_trained': 0}, 'done': False, 'training_iteration': 1, 'trial_id': 'default', 'date': '2025-03-27_16-15-55', 'timestamp': 1743059755, 'time_this_iter_s': 53.710174798965454, 'time_total_s': 53.710174798965454, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 53.710174798965454, 'iterations_since_restore': 1, 'perf': {'cpu_util_percent': np.float64(63.595945945945935), 'ram_util_percent': np.float64(44.118918918918915), 'gpu_util_percent0': np.float64(0.8920270270270271), 'vram_util_percent0': np.float64(0.29873519759994366)}})\n",
      "001, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-27 16:18:30,266\tWARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.train_ops.multi_gpu_train_one_step` has been deprecated. This will raise an error in the future!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "002, 003, 004, 005, 006, 007, 008, 009, 010, 011, 012, 013, 014, 015, 016, 017, 018, 019, 020, 021, 022, 023, 024, 025, 026, 027, 028, 029, 030, 031, 032, 033, 034, 035, 036, 037, 038, 039, 040, 041, 042, 043, 044, 045, 046, 047, 048, 049, 050, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_1), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'actor_loss': np.float64(0.7749482184648514), 'critic_loss': np.float64(0.9278041958808899), 'alpha_loss': np.float64(-3.4243703126907348), 'alpha_value': np.float32(0.864443), 'log_alpha_value': np.float32(-0.14567028), 'target_entropy': np.float32(-14.0), 'policy_t': np.float64(0.0030787271447479726), 'mean_q': np.float64(-8.72304801940918), 'max_q': np.float64(28.158403396606445), 'min_q': np.float64(-17.704904556274414)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(485.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(484.5), 'td_error': array([1.2440228 , 0.84618473, 0.32734346, ..., 1.3279166 , 1.6553845 ,\n",
      "       0.9288058 ], shape=(100000,), dtype=float32), 'mean_td_error': np.float64(5.959125757217407)}}, 'num_env_steps_sampled': 4080000, 'num_env_steps_trained': 4900000, 'num_agent_steps_sampled': 4080000, 'num_agent_steps_trained': 4900000, 'last_target_update_ts': 4080000, 'num_target_updates': 49}, 'env_runners': {'episode_reward_max': np.float64(-53910.99949313206), 'episode_reward_min': np.float64(-101891.097294789), 'episode_reward_mean': np.float64(-77304.07708046357), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101891.097294789)}, 'policy_reward_max': {'default_policy': np.float64(-53910.99949313206)}, 'policy_reward_mean': {'default_policy': np.float64(-77304.07708046357)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-77975.56004238222), np.float64(-92223.47053212032), np.float64(-86287.43040735222), np.float64(-62473.0656021764), np.float64(-78662.4893812208), np.float64(-80795.72898697258), np.float64(-100394.28476590809), np.float64(-87276.23987521141), np.float64(-80622.35042046609), np.float64(-61154.453261840674), np.float64(-81324.1933914761), np.float64(-67159.34081856918), np.float64(-70271.53607385072), np.float64(-86127.98144562481), np.float64(-71899.77005501019), np.float64(-97423.42788224966), np.float64(-61783.190992413794), np.float64(-81629.53978500763), np.float64(-97277.26249666855), np.float64(-95564.60821180197), np.float64(-75559.2795550715), np.float64(-67627.61345596449), np.float64(-70429.11626669645), np.float64(-88576.00874463057), np.float64(-60639.55433945679), np.float64(-61951.26718029249), np.float64(-65651.4655142377), np.float64(-79666.96201429618), np.float64(-74617.76172764918), np.float64(-92109.132908015), np.float64(-68202.47768160321), np.float64(-77385.6497842148), np.float64(-77504.65345904086), np.float64(-60139.34324474952), np.float64(-76803.58722722628), np.float64(-61240.87829577453), np.float64(-85429.39655513637), np.float64(-53910.99949313206), np.float64(-60058.54325276387), np.float64(-96987.96867076779), np.float64(-87789.8409492566), np.float64(-65485.001352779174), np.float64(-76029.20225773507), np.float64(-71570.39211101091), np.float64(-95479.73309487282), np.float64(-69051.74990065744), np.float64(-96283.1819037549), np.float64(-89529.1768775893), np.float64(-68965.8189317914), np.float64(-75344.47586793269), np.float64(-101891.097294789), np.float64(-71875.66939095978), np.float64(-85955.89998565313), np.float64(-64718.52728769084), np.float64(-74339.23028717554), np.float64(-84976.1324382276), np.float64(-77710.06929997705), np.float64(-77657.31974649601), np.float64(-78652.45480737743), np.float64(-74342.112520931), np.float64(-79886.68381492278), np.float64(-83263.3183280941), np.float64(-90124.07009306179), np.float64(-78445.87357903772), np.float64(-87256.0480048379), np.float64(-95606.84021854427), np.float64(-69039.0523456504), np.float64(-88802.93601583595), np.float64(-77876.07010123577), np.float64(-72324.40416529593), np.float64(-75184.39197980113), np.float64(-65156.95026377096), np.float64(-74838.35720860258), np.float64(-85785.1411312973), np.float64(-79200.94916552247), np.float64(-79555.40171889393), np.float64(-78062.60886927239), np.float64(-63433.36055311468), np.float64(-57381.339975730916), np.float64(-73429.68255852301), np.float64(-81364.45474000851), np.float64(-98259.63344150662), np.float64(-79673.76097703532), np.float64(-57600.81887398524), np.float64(-69290.3843175946), np.float64(-71684.57050041051), np.float64(-78997.6077179873), np.float64(-77126.1588056121), np.float64(-85993.01244569282), np.float64(-91814.25710480304), np.float64(-72246.08583697598), np.float64(-68317.55924754436), np.float64(-66987.53477993053), np.float64(-76810.66067795601), np.float64(-66692.60617974486), np.float64(-70382.33170876741), np.float64(-65620.9602417602), np.float64(-90846.87024194634), np.float64(-77888.01654676055), np.float64(-67692.27346358825)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-77975.56004238222), np.float64(-92223.47053212032), np.float64(-86287.43040735222), np.float64(-62473.0656021764), np.float64(-78662.4893812208), np.float64(-80795.72898697258), np.float64(-100394.28476590809), np.float64(-87276.23987521141), np.float64(-80622.35042046609), np.float64(-61154.453261840674), np.float64(-81324.1933914761), np.float64(-67159.34081856918), np.float64(-70271.53607385072), np.float64(-86127.98144562481), np.float64(-71899.77005501019), np.float64(-97423.42788224966), np.float64(-61783.190992413794), np.float64(-81629.53978500763), np.float64(-97277.26249666855), np.float64(-95564.60821180197), np.float64(-75559.2795550715), np.float64(-67627.61345596449), np.float64(-70429.11626669645), np.float64(-88576.00874463057), np.float64(-60639.55433945679), np.float64(-61951.26718029249), np.float64(-65651.4655142377), np.float64(-79666.96201429618), np.float64(-74617.76172764918), np.float64(-92109.132908015), np.float64(-68202.47768160321), np.float64(-77385.6497842148), np.float64(-77504.65345904086), np.float64(-60139.34324474952), np.float64(-76803.58722722628), np.float64(-61240.87829577453), np.float64(-85429.39655513637), np.float64(-53910.99949313206), np.float64(-60058.54325276387), np.float64(-96987.96867076779), np.float64(-87789.8409492566), np.float64(-65485.001352779174), np.float64(-76029.20225773507), np.float64(-71570.39211101091), np.float64(-95479.73309487282), np.float64(-69051.74990065744), np.float64(-96283.1819037549), np.float64(-89529.1768775893), np.float64(-68965.8189317914), np.float64(-75344.47586793269), np.float64(-101891.097294789), np.float64(-71875.66939095978), np.float64(-85955.89998565313), np.float64(-64718.52728769084), np.float64(-74339.23028717554), np.float64(-84976.1324382276), np.float64(-77710.06929997705), np.float64(-77657.31974649601), np.float64(-78652.45480737743), np.float64(-74342.112520931), np.float64(-79886.68381492278), np.float64(-83263.3183280941), np.float64(-90124.07009306179), np.float64(-78445.87357903772), np.float64(-87256.0480048379), np.float64(-95606.84021854427), np.float64(-69039.0523456504), np.float64(-88802.93601583595), np.float64(-77876.07010123577), np.float64(-72324.40416529593), np.float64(-75184.39197980113), np.float64(-65156.95026377096), np.float64(-74838.35720860258), np.float64(-85785.1411312973), np.float64(-79200.94916552247), np.float64(-79555.40171889393), np.float64(-78062.60886927239), np.float64(-63433.36055311468), np.float64(-57381.339975730916), np.float64(-73429.68255852301), np.float64(-81364.45474000851), np.float64(-98259.63344150662), np.float64(-79673.76097703532), np.float64(-57600.81887398524), np.float64(-69290.3843175946), np.float64(-71684.57050041051), np.float64(-78997.6077179873), np.float64(-77126.1588056121), np.float64(-85993.01244569282), np.float64(-91814.25710480304), np.float64(-72246.08583697598), np.float64(-68317.55924754436), np.float64(-66987.53477993053), np.float64(-76810.66067795601), np.float64(-66692.60617974486), np.float64(-70382.33170876741), np.float64(-65620.9602417602), np.float64(-90846.87024194634), np.float64(-77888.01654676055), np.float64(-67692.27346358825)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.20046993420533848), 'mean_inference_ms': np.float64(7.351844230018775), 'mean_action_processing_ms': np.float64(0.14826462741459534), 'mean_env_wait_ms': np.float64(1.3617467338531495), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.00443267822265625), 'StateBufferConnector_ms': np.float64(0.0034308433532714844), 'ViewRequirementAgentConnector_ms': np.float64(0.08704638481140137)}, 'num_episodes': 16, 'episode_return_max': np.float64(-53910.99949313206), 'episode_return_min': np.float64(-101891.097294789), 'episode_return_mean': np.float64(-77304.07708046357), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 4080000, 'num_agent_steps_trained': 4900000, 'num_env_steps_sampled': 4080000, 'num_env_steps_trained': 4900000, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1243.9862921845793, 'num_env_steps_trained_throughput_per_sec': 1554.9828652307242, 'timesteps_total': 4080000, 'num_env_steps_sampled_lifetime': 4080000, 'num_agent_steps_sampled_lifetime': 4080000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 4080000, 'timers': {'training_iteration_time_ms': 66588.634, 'restore_workers_time_ms': 0.01, 'training_step_time_ms': 66588.6, 'sample_time_ms': 49366.042, 'load_time_ms': 42.651, 'load_throughput': 2344588.106, 'learn_time_ms': 429.894, 'learn_throughput': 232615.704, 'synch_weights_time_ms': 22.402}, 'counters': {'num_env_steps_sampled': 4080000, 'num_env_steps_trained': 4900000, 'num_agent_steps_sampled': 4080000, 'num_agent_steps_trained': 4900000, 'last_target_update_ts': 4080000, 'num_target_updates': 49}, 'done': False, 'training_iteration': 51, 'trial_id': 'default', 'date': '2025-03-27_17-11-59', 'timestamp': 1743063119, 'time_this_iter_s': 64.36986374855042, 'time_total_s': 3375.318410396576, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 3375.318410396576, 'iterations_since_restore': 51, 'perf': {'cpu_util_percent': np.float64(52.61022727272728), 'ram_util_percent': np.float64(89.50909090909092), 'gpu_util_percent0': np.float64(0.745568181818182), 'vram_util_percent0': np.float64(0.40093624230587127)}})\n",
      "051, 052, 053, 054, 055, 056, 057, 058, 059, 060, 061, 062, 063, 064, 065, 066, 067, 068, 069, 070, 071, 072, 073, 074, 075, 076, 077, 078, 079, 080, 081, 082, 083, 084, 085, 086, 087, 088, 089, 090, 091, 092, 093, 094, 095, 096, 097, 098, 099, 100, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_2), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'actor_loss': np.float64(2.6878675699234007), 'critic_loss': np.float64(0.7482608377933502), 'alpha_loss': np.float64(-6.953276443481445), 'alpha_value': np.float32(0.7440746), 'log_alpha_value': np.float32(-0.29561442), 'target_entropy': np.float32(-14.0), 'policy_t': np.float64(-0.004132021381519735), 'mean_q': np.float64(-9.26662187576294), 'max_q': np.float64(78.1182861328125), 'min_q': np.float64(-18.970726013183594)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(985.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(984.5), 'td_error': array([0.2858472 , 2.589577  , 7.912718  , ..., 1.8605473 , 3.03026   ,\n",
      "       0.66166353], shape=(100000,), dtype=float32), 'mean_td_error': np.float64(5.72558274269104)}}, 'num_env_steps_sampled': 8080000, 'num_env_steps_trained': 9900000, 'num_agent_steps_sampled': 8080000, 'num_agent_steps_trained': 9900000, 'last_target_update_ts': 8080000, 'num_target_updates': 99}, 'env_runners': {'episode_reward_max': np.float64(-57340.87250091556), 'episode_reward_min': np.float64(-98704.35517142041), 'episode_reward_mean': np.float64(-78223.34731364367), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-98704.35517142041)}, 'policy_reward_max': {'default_policy': np.float64(-57340.87250091556)}, 'policy_reward_mean': {'default_policy': np.float64(-78223.34731364367)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-88708.1639925832), np.float64(-86146.50294365715), np.float64(-83279.52465887669), np.float64(-76365.59329962698), np.float64(-66347.93600384897), np.float64(-79088.44990704393), np.float64(-96978.33273714283), np.float64(-82348.58180278368), np.float64(-60779.17927403923), np.float64(-67440.55862622995), np.float64(-82818.7002845613), np.float64(-81481.62216158588), np.float64(-85177.6453746057), np.float64(-79947.42153681026), np.float64(-72435.00138775184), np.float64(-77336.85211334538), np.float64(-57340.87250091556), np.float64(-57573.13905043326), np.float64(-67607.5343042734), np.float64(-76174.81432220245), np.float64(-72360.52419949946), np.float64(-67826.404273242), np.float64(-71937.91291252991), np.float64(-67902.0725219715), np.float64(-84422.64355016625), np.float64(-88145.15620874627), np.float64(-80184.62149575236), np.float64(-72064.33866066339), np.float64(-77922.13682479796), np.float64(-74246.29073317588), np.float64(-81849.54182903306), np.float64(-97776.39047400972), np.float64(-71692.76529521217), np.float64(-78335.35663292342), np.float64(-65218.749049199214), np.float64(-78213.87271574384), np.float64(-67837.09584975688), np.float64(-97111.72204917342), np.float64(-83836.23309959575), np.float64(-82033.10377668333), np.float64(-93442.69624053719), np.float64(-89144.79533314821), np.float64(-87334.39608319999), np.float64(-73369.06167289622), np.float64(-71117.79884054947), np.float64(-84893.38191800904), np.float64(-77822.01015167341), np.float64(-95732.86757155864), np.float64(-86451.92797169904), np.float64(-73450.17290431663), np.float64(-68154.38850080628), np.float64(-79502.7993059925), np.float64(-86739.38448889945), np.float64(-77934.07321973116), np.float64(-94009.86309641978), np.float64(-72269.3293281564), np.float64(-80947.81626709749), np.float64(-86787.58424232519), np.float64(-78205.32076946336), np.float64(-84680.43856559022), np.float64(-64829.80902838362), np.float64(-66714.70162387799), np.float64(-83477.55050920112), np.float64(-92210.01867339484), np.float64(-66364.88014245866), np.float64(-72061.15557376367), np.float64(-84389.43249535891), np.float64(-73353.7258059404), np.float64(-75253.37610952424), np.float64(-61412.9927190903), np.float64(-86449.20450982309), np.float64(-82283.29443617095), np.float64(-74782.44658568362), np.float64(-81376.89641438829), np.float64(-86906.90549259212), np.float64(-98704.35517142041), np.float64(-84347.78719062834), np.float64(-79800.41214085926), np.float64(-70600.77033970621), np.float64(-88727.48494637031), np.float64(-74101.59761926554), np.float64(-81431.23140450529), np.float64(-86714.10155901333), np.float64(-61203.35258743258), np.float64(-76882.09267789511), np.float64(-90287.0329850549), np.float64(-68799.63565958838), np.float64(-90433.75323795852), np.float64(-67647.4057179458), np.float64(-72916.76021909057), np.float64(-92525.6770837541), np.float64(-81502.24760921451), np.float64(-77429.5608373587), np.float64(-80875.14840436039), np.float64(-63525.46233595431), np.float64(-69793.03222728253), np.float64(-57595.086048909085), np.float64(-86257.94754116389), np.float64(-67159.07638111747), np.float64(-72923.86441260179)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-88708.1639925832), np.float64(-86146.50294365715), np.float64(-83279.52465887669), np.float64(-76365.59329962698), np.float64(-66347.93600384897), np.float64(-79088.44990704393), np.float64(-96978.33273714283), np.float64(-82348.58180278368), np.float64(-60779.17927403923), np.float64(-67440.55862622995), np.float64(-82818.7002845613), np.float64(-81481.62216158588), np.float64(-85177.6453746057), np.float64(-79947.42153681026), np.float64(-72435.00138775184), np.float64(-77336.85211334538), np.float64(-57340.87250091556), np.float64(-57573.13905043326), np.float64(-67607.5343042734), np.float64(-76174.81432220245), np.float64(-72360.52419949946), np.float64(-67826.404273242), np.float64(-71937.91291252991), np.float64(-67902.0725219715), np.float64(-84422.64355016625), np.float64(-88145.15620874627), np.float64(-80184.62149575236), np.float64(-72064.33866066339), np.float64(-77922.13682479796), np.float64(-74246.29073317588), np.float64(-81849.54182903306), np.float64(-97776.39047400972), np.float64(-71692.76529521217), np.float64(-78335.35663292342), np.float64(-65218.749049199214), np.float64(-78213.87271574384), np.float64(-67837.09584975688), np.float64(-97111.72204917342), np.float64(-83836.23309959575), np.float64(-82033.10377668333), np.float64(-93442.69624053719), np.float64(-89144.79533314821), np.float64(-87334.39608319999), np.float64(-73369.06167289622), np.float64(-71117.79884054947), np.float64(-84893.38191800904), np.float64(-77822.01015167341), np.float64(-95732.86757155864), np.float64(-86451.92797169904), np.float64(-73450.17290431663), np.float64(-68154.38850080628), np.float64(-79502.7993059925), np.float64(-86739.38448889945), np.float64(-77934.07321973116), np.float64(-94009.86309641978), np.float64(-72269.3293281564), np.float64(-80947.81626709749), np.float64(-86787.58424232519), np.float64(-78205.32076946336), np.float64(-84680.43856559022), np.float64(-64829.80902838362), np.float64(-66714.70162387799), np.float64(-83477.55050920112), np.float64(-92210.01867339484), np.float64(-66364.88014245866), np.float64(-72061.15557376367), np.float64(-84389.43249535891), np.float64(-73353.7258059404), np.float64(-75253.37610952424), np.float64(-61412.9927190903), np.float64(-86449.20450982309), np.float64(-82283.29443617095), np.float64(-74782.44658568362), np.float64(-81376.89641438829), np.float64(-86906.90549259212), np.float64(-98704.35517142041), np.float64(-84347.78719062834), np.float64(-79800.41214085926), np.float64(-70600.77033970621), np.float64(-88727.48494637031), np.float64(-74101.59761926554), np.float64(-81431.23140450529), np.float64(-86714.10155901333), np.float64(-61203.35258743258), np.float64(-76882.09267789511), np.float64(-90287.0329850549), np.float64(-68799.63565958838), np.float64(-90433.75323795852), np.float64(-67647.4057179458), np.float64(-72916.76021909057), np.float64(-92525.6770837541), np.float64(-81502.24760921451), np.float64(-77429.5608373587), np.float64(-80875.14840436039), np.float64(-63525.46233595431), np.float64(-69793.03222728253), np.float64(-57595.086048909085), np.float64(-86257.94754116389), np.float64(-67159.07638111747), np.float64(-72923.86441260179)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.20057833767034844), 'mean_inference_ms': np.float64(7.347914966548903), 'mean_action_processing_ms': np.float64(0.14837402969374833), 'mean_env_wait_ms': np.float64(1.3622241678219766), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.004265785217285156), 'StateBufferConnector_ms': np.float64(0.003631591796875), 'ViewRequirementAgentConnector_ms': np.float64(0.08866190910339355)}, 'num_episodes': 16, 'episode_return_max': np.float64(-57340.87250091556), 'episode_return_min': np.float64(-98704.35517142041), 'episode_return_mean': np.float64(-78223.34731364367), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 8080000, 'num_agent_steps_trained': 9900000, 'num_env_steps_sampled': 8080000, 'num_env_steps_trained': 9900000, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1172.6511305893744, 'num_env_steps_trained_throughput_per_sec': 1465.813913236718, 'timesteps_total': 8080000, 'num_env_steps_sampled_lifetime': 8080000, 'num_agent_steps_sampled_lifetime': 8080000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 8080000, 'timers': {'training_iteration_time_ms': 67438.267, 'restore_workers_time_ms': 0.01, 'training_step_time_ms': 67438.23, 'sample_time_ms': 50040.783, 'load_time_ms': 41.168, 'load_throughput': 2429044.495, 'learn_time_ms': 433.15, 'learn_throughput': 230867.131, 'synch_weights_time_ms': 23.198}, 'counters': {'num_env_steps_sampled': 8080000, 'num_env_steps_trained': 9900000, 'num_agent_steps_sampled': 8080000, 'num_agent_steps_trained': 9900000, 'last_target_update_ts': 8080000, 'num_target_updates': 99}, 'done': False, 'training_iteration': 101, 'trial_id': 'default', 'date': '2025-03-27_18-08-38', 'timestamp': 1743066518, 'time_this_iter_s': 68.283123254776, 'time_total_s': 6735.544969320297, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 6735.544969320297, 'iterations_since_restore': 101, 'perf': {'cpu_util_percent': np.float64(52.402272727272724), 'ram_util_percent': np.float64(89.93409090909091), 'gpu_util_percent0': np.float64(0.7570454545454548), 'vram_util_percent0': np.float64(0.39974189527107007)}})\n",
      "101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_3), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'actor_loss': np.float64(4.186308908462524), 'critic_loss': np.float64(0.6727406322956085), 'alpha_loss': np.float64(-10.476033115386963), 'alpha_value': np.float32(0.6404797), 'log_alpha_value': np.float32(-0.44553822), 'target_entropy': np.float32(-14.0), 'policy_t': np.float64(-0.0033905514790603776), 'mean_q': np.float64(-9.735947322845458), 'max_q': np.float64(97.7802734375), 'min_q': np.float64(-20.732135772705078)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(1485.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(1484.5), 'td_error': array([33.327965  ,  0.39161444,  1.0672021 , ...,  9.59774   ,\n",
      "        1.3196526 ,  0.773211  ], shape=(100000,), dtype=float32), 'mean_td_error': np.float64(4.709593725204468)}}, 'num_env_steps_sampled': 12080000, 'num_env_steps_trained': 14900000, 'num_agent_steps_sampled': 12080000, 'num_agent_steps_trained': 14900000, 'last_target_update_ts': 12080000, 'num_target_updates': 149}, 'env_runners': {'episode_reward_max': np.float64(-56057.50755709878), 'episode_reward_min': np.float64(-101716.77262038481), 'episode_reward_mean': np.float64(-77718.64100245276), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101716.77262038481)}, 'policy_reward_max': {'default_policy': np.float64(-56057.50755709878)}, 'policy_reward_mean': {'default_policy': np.float64(-77718.64100245276)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-86111.80475217827), np.float64(-72111.22006850995), np.float64(-82010.10342161558), np.float64(-68698.52343596963), np.float64(-64059.44868897172), np.float64(-68953.4461693366), np.float64(-73521.77421766761), np.float64(-85198.98595017738), np.float64(-82378.98979818338), np.float64(-60690.93993926373), np.float64(-96672.51604043024), np.float64(-70861.27633629163), np.float64(-73751.94252538389), np.float64(-84385.25306841146), np.float64(-72095.426690816), np.float64(-85021.60000246779), np.float64(-75878.31609759454), np.float64(-80819.42957546307), np.float64(-95135.81873815131), np.float64(-69307.17299628895), np.float64(-67562.80174010574), np.float64(-65125.31336813364), np.float64(-68504.44096936454), np.float64(-96505.30167841232), np.float64(-85711.20848842507), np.float64(-61490.619399702), np.float64(-67967.73605352161), np.float64(-82306.8901165155), np.float64(-62073.77048191436), np.float64(-67119.20842842103), np.float64(-90058.77591076007), np.float64(-77104.9542780142), np.float64(-87915.74648987509), np.float64(-68171.68155107702), np.float64(-83631.77066465098), np.float64(-81159.80396710012), np.float64(-78993.5550648927), np.float64(-76243.2181579562), np.float64(-77358.78409045725), np.float64(-83513.84879713462), np.float64(-85571.22008208293), np.float64(-82564.75281118523), np.float64(-96252.50697333967), np.float64(-83535.07709215603), np.float64(-89488.85347188456), np.float64(-61072.26196670357), np.float64(-84506.11088865713), np.float64(-99467.49370840073), np.float64(-77518.94033658158), np.float64(-71427.75244315447), np.float64(-68110.74539684568), np.float64(-90200.80534837407), np.float64(-101716.77262038481), np.float64(-71584.5925655723), np.float64(-69958.42940705288), np.float64(-78855.25392088141), np.float64(-71607.79687489147), np.float64(-79777.45103316705), np.float64(-65639.80249191877), np.float64(-73484.44489262473), np.float64(-76510.24265793338), np.float64(-73716.20680981841), np.float64(-72326.38530771383), np.float64(-73692.52517234144), np.float64(-86208.48045442476), np.float64(-74389.49062513495), np.float64(-63012.81137635521), np.float64(-97637.05828574124), np.float64(-78133.9720457647), np.float64(-83780.89956254058), np.float64(-78730.40133793165), np.float64(-81212.87756909657), np.float64(-77863.71683152027), np.float64(-56057.50755709878), np.float64(-86291.9304926341), np.float64(-80422.25094940027), np.float64(-81298.66764928716), np.float64(-88015.35206531922), np.float64(-81703.9506687776), np.float64(-87887.99469146667), np.float64(-79403.31831346218), np.float64(-83317.17192812462), np.float64(-91556.87004647004), np.float64(-67300.3255729711), np.float64(-93694.46346021249), np.float64(-83325.97953804868), np.float64(-82393.57398463324), np.float64(-90774.87985025386), np.float64(-66837.53214385084), np.float64(-70639.83641729876), np.float64(-65796.74813390043), np.float64(-63182.1513941128), np.float64(-65646.25394717835), np.float64(-74669.80848192913), np.float64(-64593.29757229376), np.float64(-70610.60941314662), np.float64(-71145.33054526102), np.float64(-64082.50866606703), np.float64(-65220.46947188357), np.float64(-100255.76671841065)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-86111.80475217827), np.float64(-72111.22006850995), np.float64(-82010.10342161558), np.float64(-68698.52343596963), np.float64(-64059.44868897172), np.float64(-68953.4461693366), np.float64(-73521.77421766761), np.float64(-85198.98595017738), np.float64(-82378.98979818338), np.float64(-60690.93993926373), np.float64(-96672.51604043024), np.float64(-70861.27633629163), np.float64(-73751.94252538389), np.float64(-84385.25306841146), np.float64(-72095.426690816), np.float64(-85021.60000246779), np.float64(-75878.31609759454), np.float64(-80819.42957546307), np.float64(-95135.81873815131), np.float64(-69307.17299628895), np.float64(-67562.80174010574), np.float64(-65125.31336813364), np.float64(-68504.44096936454), np.float64(-96505.30167841232), np.float64(-85711.20848842507), np.float64(-61490.619399702), np.float64(-67967.73605352161), np.float64(-82306.8901165155), np.float64(-62073.77048191436), np.float64(-67119.20842842103), np.float64(-90058.77591076007), np.float64(-77104.9542780142), np.float64(-87915.74648987509), np.float64(-68171.68155107702), np.float64(-83631.77066465098), np.float64(-81159.80396710012), np.float64(-78993.5550648927), np.float64(-76243.2181579562), np.float64(-77358.78409045725), np.float64(-83513.84879713462), np.float64(-85571.22008208293), np.float64(-82564.75281118523), np.float64(-96252.50697333967), np.float64(-83535.07709215603), np.float64(-89488.85347188456), np.float64(-61072.26196670357), np.float64(-84506.11088865713), np.float64(-99467.49370840073), np.float64(-77518.94033658158), np.float64(-71427.75244315447), np.float64(-68110.74539684568), np.float64(-90200.80534837407), np.float64(-101716.77262038481), np.float64(-71584.5925655723), np.float64(-69958.42940705288), np.float64(-78855.25392088141), np.float64(-71607.79687489147), np.float64(-79777.45103316705), np.float64(-65639.80249191877), np.float64(-73484.44489262473), np.float64(-76510.24265793338), np.float64(-73716.20680981841), np.float64(-72326.38530771383), np.float64(-73692.52517234144), np.float64(-86208.48045442476), np.float64(-74389.49062513495), np.float64(-63012.81137635521), np.float64(-97637.05828574124), np.float64(-78133.9720457647), np.float64(-83780.89956254058), np.float64(-78730.40133793165), np.float64(-81212.87756909657), np.float64(-77863.71683152027), np.float64(-56057.50755709878), np.float64(-86291.9304926341), np.float64(-80422.25094940027), np.float64(-81298.66764928716), np.float64(-88015.35206531922), np.float64(-81703.9506687776), np.float64(-87887.99469146667), np.float64(-79403.31831346218), np.float64(-83317.17192812462), np.float64(-91556.87004647004), np.float64(-67300.3255729711), np.float64(-93694.46346021249), np.float64(-83325.97953804868), np.float64(-82393.57398463324), np.float64(-90774.87985025386), np.float64(-66837.53214385084), np.float64(-70639.83641729876), np.float64(-65796.74813390043), np.float64(-63182.1513941128), np.float64(-65646.25394717835), np.float64(-74669.80848192913), np.float64(-64593.29757229376), np.float64(-70610.60941314662), np.float64(-71145.33054526102), np.float64(-64082.50866606703), np.float64(-65220.46947188357), np.float64(-100255.76671841065)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.20054253554062082), 'mean_inference_ms': np.float64(7.3413879209499875), 'mean_action_processing_ms': np.float64(0.14829095904804712), 'mean_env_wait_ms': np.float64(1.3613966774465467), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.00441288948059082), 'StateBufferConnector_ms': np.float64(0.003275156021118164), 'ViewRequirementAgentConnector_ms': np.float64(0.08551764488220215)}, 'num_episodes': 0, 'episode_return_max': np.float64(-56057.50755709878), 'episode_return_min': np.float64(-101716.77262038481), 'episode_return_mean': np.float64(-77718.64100245276), 'episodes_this_iter': 0}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 12080000, 'num_agent_steps_trained': 14900000, 'num_env_steps_sampled': 12080000, 'num_env_steps_trained': 14900000, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1165.5942462278883, 'num_env_steps_trained_throughput_per_sec': 1456.9928077848604, 'timesteps_total': 12080000, 'num_env_steps_sampled_lifetime': 12080000, 'num_agent_steps_sampled_lifetime': 12080000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 12080000, 'timers': {'training_iteration_time_ms': 67333.803, 'restore_workers_time_ms': 0.01, 'training_step_time_ms': 67333.764, 'sample_time_ms': 49825.397, 'load_time_ms': 36.964, 'load_throughput': 2705302.693, 'learn_time_ms': 432.618, 'learn_throughput': 231150.949, 'synch_weights_time_ms': 23.035}, 'counters': {'num_env_steps_sampled': 12080000, 'num_env_steps_trained': 14900000, 'num_agent_steps_sampled': 12080000, 'num_agent_steps_trained': 14900000, 'last_target_update_ts': 12080000, 'num_target_updates': 149}, 'done': False, 'training_iteration': 151, 'trial_id': 'default', 'date': '2025-03-27_19-05-19', 'timestamp': 1743069919, 'time_this_iter_s': 68.70813274383545, 'time_total_s': 10097.756484746933, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 10097.756484746933, 'iterations_since_restore': 151, 'perf': {'cpu_util_percent': np.float64(52.17528089887641), 'ram_util_percent': np.float64(90.85730337078651), 'gpu_util_percent0': np.float64(0.7505617977528091), 'vram_util_percent0': np.float64(0.4013447850830993)}})\n",
      "151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_4), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'actor_loss': np.float64(5.731869888305664), 'critic_loss': np.float64(0.6975159466266632), 'alpha_loss': np.float64(-13.97426528930664), 'alpha_value': np.float32(0.55135506), 'log_alpha_value': np.float32(-0.5953766), 'target_entropy': np.float32(-14.0), 'policy_t': np.float64(-0.00869474527426064), 'mean_q': np.float64(-10.237407112121582), 'max_q': np.float64(88.77439880371094), 'min_q': np.float64(-22.331478118896484)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(1985.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(1984.5), 'td_error': array([ 0.43858004,  0.40739107,  0.47309637, ...,  2.771523  ,\n",
      "       16.506014  ,  0.20837736], shape=(100000,), dtype=float32), 'mean_td_error': np.float64(4.495978832244873)}}, 'num_env_steps_sampled': 16080000, 'num_env_steps_trained': 19900000, 'num_agent_steps_sampled': 16080000, 'num_agent_steps_trained': 19900000, 'last_target_update_ts': 16080000, 'num_target_updates': 199}, 'env_runners': {'episode_reward_max': np.float64(-55397.560797288854), 'episode_reward_min': np.float64(-101709.51957233476), 'episode_reward_mean': np.float64(-76823.24214369436), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101709.51957233476)}, 'policy_reward_max': {'default_policy': np.float64(-55397.560797288854)}, 'policy_reward_mean': {'default_policy': np.float64(-76823.24214369436)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-88930.29316856284), np.float64(-77288.81012146622), np.float64(-75832.66546125906), np.float64(-101709.51957233476), np.float64(-75266.02126519315), np.float64(-73126.83738637563), np.float64(-84186.42387634753), np.float64(-55621.0380215312), np.float64(-64316.87721550206), np.float64(-62185.30427265652), np.float64(-81160.29203649124), np.float64(-88415.78256635989), np.float64(-55397.560797288854), np.float64(-67901.74064309539), np.float64(-67153.30236421405), np.float64(-79476.76564706695), np.float64(-77280.11960447235), np.float64(-82449.93977699697), np.float64(-59603.202318245196), np.float64(-82246.07177656863), np.float64(-76060.36454001906), np.float64(-64717.17493122156), np.float64(-96361.3282058614), np.float64(-90840.8211483195), np.float64(-80580.98047004455), np.float64(-60613.28882508092), np.float64(-67251.08223858003), np.float64(-86306.99841969166), np.float64(-69788.70174499297), np.float64(-70617.33950968017), np.float64(-78299.05387419155), np.float64(-64103.38765654707), np.float64(-66629.77459564917), np.float64(-93540.36479659393), np.float64(-67934.05685576427), np.float64(-89674.59927993828), np.float64(-80101.8201478907), np.float64(-66699.42654351801), np.float64(-92832.69723080646), np.float64(-69512.26524093091), np.float64(-80015.08627614354), np.float64(-69149.8452166159), np.float64(-74787.2872499752), np.float64(-94671.08551025206), np.float64(-74524.29750375988), np.float64(-76318.8076759911), np.float64(-66130.28832595298), np.float64(-67983.9239632403), np.float64(-79879.63056455221), np.float64(-74518.33502787403), np.float64(-76823.88902135448), np.float64(-77088.73950103136), np.float64(-79229.50490966497), np.float64(-80654.8919225332), np.float64(-79365.13864487536), np.float64(-81571.4109980233), np.float64(-89329.45932577166), np.float64(-79291.64474308262), np.float64(-73615.77353661842), np.float64(-67908.38324538428), np.float64(-78576.80677776538), np.float64(-90563.71975579123), np.float64(-62821.21851265056), np.float64(-84184.31026047688), np.float64(-60497.02026435056), np.float64(-87038.62213944447), np.float64(-70496.52282997822), np.float64(-84234.81885158528), np.float64(-76366.91619409216), np.float64(-87947.34669102039), np.float64(-97517.84233021729), np.float64(-81874.24871419088), np.float64(-66640.21872670294), np.float64(-72878.74474617734), np.float64(-81867.33214509553), np.float64(-77562.01469007562), np.float64(-71246.4093659768), np.float64(-68662.8431590051), np.float64(-74846.27125428618), np.float64(-76583.98805106299), np.float64(-89027.86016492853), np.float64(-85987.1125950124), np.float64(-78907.84838523886), np.float64(-72477.03165838456), np.float64(-84676.32431081684), np.float64(-69998.88994974796), np.float64(-75796.94607050873), np.float64(-88723.66922779311), np.float64(-81377.15915652733), np.float64(-85564.76400444566), np.float64(-72731.2118789491), np.float64(-92011.01114564751), np.float64(-78037.94712528007), np.float64(-68923.78141670967), np.float64(-67884.05418462957), np.float64(-74121.09696429729), np.float64(-59292.763534804864), np.float64(-75713.24786925846), np.float64(-68838.61836491206), np.float64(-84954.14359154833)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-88930.29316856284), np.float64(-77288.81012146622), np.float64(-75832.66546125906), np.float64(-101709.51957233476), np.float64(-75266.02126519315), np.float64(-73126.83738637563), np.float64(-84186.42387634753), np.float64(-55621.0380215312), np.float64(-64316.87721550206), np.float64(-62185.30427265652), np.float64(-81160.29203649124), np.float64(-88415.78256635989), np.float64(-55397.560797288854), np.float64(-67901.74064309539), np.float64(-67153.30236421405), np.float64(-79476.76564706695), np.float64(-77280.11960447235), np.float64(-82449.93977699697), np.float64(-59603.202318245196), np.float64(-82246.07177656863), np.float64(-76060.36454001906), np.float64(-64717.17493122156), np.float64(-96361.3282058614), np.float64(-90840.8211483195), np.float64(-80580.98047004455), np.float64(-60613.28882508092), np.float64(-67251.08223858003), np.float64(-86306.99841969166), np.float64(-69788.70174499297), np.float64(-70617.33950968017), np.float64(-78299.05387419155), np.float64(-64103.38765654707), np.float64(-66629.77459564917), np.float64(-93540.36479659393), np.float64(-67934.05685576427), np.float64(-89674.59927993828), np.float64(-80101.8201478907), np.float64(-66699.42654351801), np.float64(-92832.69723080646), np.float64(-69512.26524093091), np.float64(-80015.08627614354), np.float64(-69149.8452166159), np.float64(-74787.2872499752), np.float64(-94671.08551025206), np.float64(-74524.29750375988), np.float64(-76318.8076759911), np.float64(-66130.28832595298), np.float64(-67983.9239632403), np.float64(-79879.63056455221), np.float64(-74518.33502787403), np.float64(-76823.88902135448), np.float64(-77088.73950103136), np.float64(-79229.50490966497), np.float64(-80654.8919225332), np.float64(-79365.13864487536), np.float64(-81571.4109980233), np.float64(-89329.45932577166), np.float64(-79291.64474308262), np.float64(-73615.77353661842), np.float64(-67908.38324538428), np.float64(-78576.80677776538), np.float64(-90563.71975579123), np.float64(-62821.21851265056), np.float64(-84184.31026047688), np.float64(-60497.02026435056), np.float64(-87038.62213944447), np.float64(-70496.52282997822), np.float64(-84234.81885158528), np.float64(-76366.91619409216), np.float64(-87947.34669102039), np.float64(-97517.84233021729), np.float64(-81874.24871419088), np.float64(-66640.21872670294), np.float64(-72878.74474617734), np.float64(-81867.33214509553), np.float64(-77562.01469007562), np.float64(-71246.4093659768), np.float64(-68662.8431590051), np.float64(-74846.27125428618), np.float64(-76583.98805106299), np.float64(-89027.86016492853), np.float64(-85987.1125950124), np.float64(-78907.84838523886), np.float64(-72477.03165838456), np.float64(-84676.32431081684), np.float64(-69998.88994974796), np.float64(-75796.94607050873), np.float64(-88723.66922779311), np.float64(-81377.15915652733), np.float64(-85564.76400444566), np.float64(-72731.2118789491), np.float64(-92011.01114564751), np.float64(-78037.94712528007), np.float64(-68923.78141670967), np.float64(-67884.05418462957), np.float64(-74121.09696429729), np.float64(-59292.763534804864), np.float64(-75713.24786925846), np.float64(-68838.61836491206), np.float64(-84954.14359154833)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.19943252751736312), 'mean_inference_ms': np.float64(7.215397533196168), 'mean_action_processing_ms': np.float64(0.14735385045083457), 'mean_env_wait_ms': np.float64(1.3544956319334784), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.00420069694519043), 'StateBufferConnector_ms': np.float64(0.0034444332122802734), 'ViewRequirementAgentConnector_ms': np.float64(0.08513426780700684)}, 'num_episodes': 16, 'episode_return_max': np.float64(-55397.560797288854), 'episode_return_min': np.float64(-101709.51957233476), 'episode_return_mean': np.float64(-76823.24214369436), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 16080000, 'num_agent_steps_trained': 19900000, 'num_env_steps_sampled': 16080000, 'num_env_steps_trained': 19900000, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1317.7754728327554, 'num_env_steps_trained_throughput_per_sec': 1647.2193410409443, 'timesteps_total': 16080000, 'num_env_steps_sampled_lifetime': 16080000, 'num_agent_steps_sampled_lifetime': 16080000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 16080000, 'timers': {'training_iteration_time_ms': 63638.727, 'restore_workers_time_ms': 0.009, 'training_step_time_ms': 63638.69, 'sample_time_ms': 46323.76, 'load_time_ms': 36.886, 'load_throughput': 2711083.676, 'learn_time_ms': 397.122, 'learn_throughput': 251811.966, 'synch_weights_time_ms': 22.069}, 'counters': {'num_env_steps_sampled': 16080000, 'num_env_steps_trained': 19900000, 'num_agent_steps_sampled': 16080000, 'num_agent_steps_trained': 19900000, 'last_target_update_ts': 16080000, 'num_target_updates': 199}, 'done': False, 'training_iteration': 201, 'trial_id': 'default', 'date': '2025-03-27_19-59-41', 'timestamp': 1743073181, 'time_this_iter_s': 60.76379895210266, 'time_total_s': 13319.42420578003, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 13319.42420578003, 'iterations_since_restore': 201, 'perf': {'cpu_util_percent': np.float64(50.458536585365856), 'ram_util_percent': np.float64(90.10853658536584), 'gpu_util_percent0': np.float64(0.7431707317073172), 'vram_util_percent0': np.float64(0.39396158854166663)}})\n",
      "201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, Checkpoint saved in directory TrainingResult(checkpoint=Checkpoint(filesystem=local, path=SAC_layer_Big_chordal_relu_sampling001_327_5), metrics={'custom_metrics': {}, 'episode_media': {}, 'info': {'learner': {'default_policy': {'custom_metrics': {}, 'learner_stats': {'actor_loss': np.float64(7.5194024562835695), 'critic_loss': np.float64(0.7669937014579773), 'alpha_loss': np.float64(-17.471013641357423), 'alpha_value': np.float32(0.4746948), 'log_alpha_value': np.float32(-0.7450837), 'target_entropy': np.float32(-14.0), 'policy_t': np.float64(-0.009631396736949682), 'mean_q': np.float64(-11.356114387512207), 'max_q': np.float64(88.08373260498047), 'min_q': np.float64(-25.202571868896484)}, 'model': {}, 'num_grad_updates_lifetime': np.float64(2485.5), 'diff_num_grad_updates_vs_sampler_policy': np.float64(2484.5), 'td_error': array([ 0.14706898,  6.530042  ,  2.2044158 , ...,  0.6499419 ,\n",
      "        0.37633705, 14.581055  ], shape=(100000,), dtype=float32), 'mean_td_error': np.float64(4.260807704925537)}}, 'num_env_steps_sampled': 20080000, 'num_env_steps_trained': 24900000, 'num_agent_steps_sampled': 20080000, 'num_agent_steps_trained': 24900000, 'last_target_update_ts': 20080000, 'num_target_updates': 249}, 'env_runners': {'episode_reward_max': np.float64(-54610.63476678245), 'episode_reward_min': np.float64(-101912.84333920732), 'episode_reward_mean': np.float64(-77371.5452142158), 'episode_len_mean': np.float64(6000.0), 'episode_media': {}, 'episodes_timesteps_total': 600000, 'policy_reward_min': {'default_policy': np.float64(-101912.84333920732)}, 'policy_reward_max': {'default_policy': np.float64(-54610.63476678245)}, 'policy_reward_mean': {'default_policy': np.float64(-77371.5452142158)}, 'custom_metrics': {}, 'hist_stats': {'episode_reward': [np.float64(-87265.00678303203), np.float64(-69303.2053160704), np.float64(-88821.85211989684), np.float64(-62705.89313979828), np.float64(-72854.18402315247), np.float64(-70942.11558001694), np.float64(-93164.28256217876), np.float64(-68605.3794538616), np.float64(-90508.04977711906), np.float64(-66654.22221157215), np.float64(-73660.88114615614), np.float64(-66305.61748110545), np.float64(-67588.51202727568), np.float64(-85979.89353834318), np.float64(-73220.53417214795), np.float64(-98384.8808897089), np.float64(-73500.38453014781), np.float64(-74818.63171667159), np.float64(-78415.09825564077), np.float64(-84802.23116566429), np.float64(-69056.91087256312), np.float64(-73484.71459061868), np.float64(-86709.4788717425), np.float64(-75833.98913200163), np.float64(-70057.18321544385), np.float64(-79773.73662290155), np.float64(-94033.99226156091), np.float64(-101361.1080662428), np.float64(-59655.08766371399), np.float64(-64948.18293603431), np.float64(-65620.82815609808), np.float64(-71054.6260055471), np.float64(-67235.18279397885), np.float64(-69485.55928721653), np.float64(-67165.37017239758), np.float64(-62140.583033596704), np.float64(-79397.4064397162), np.float64(-77208.6813065188), np.float64(-92918.15942410714), np.float64(-81486.9300934303), np.float64(-86429.98512648797), np.float64(-91862.724667818), np.float64(-83783.75370275961), np.float64(-80313.48885055508), np.float64(-54610.63476678245), np.float64(-91666.6432685723), np.float64(-56873.16374968131), np.float64(-80531.34434158572), np.float64(-78761.49027525396), np.float64(-66296.30628320033), np.float64(-62604.15649562747), np.float64(-70250.87129491681), np.float64(-67009.64834908587), np.float64(-91689.76764967456), np.float64(-91008.94638656234), np.float64(-81611.73875117682), np.float64(-69016.20931330882), np.float64(-77287.70397641629), np.float64(-101912.84333920732), np.float64(-69472.42966858305), np.float64(-83133.85844172745), np.float64(-78180.38428228846), np.float64(-74685.68799869527), np.float64(-89553.12849368063), np.float64(-98461.02301348049), np.float64(-59897.221941504096), np.float64(-69572.76356441602), np.float64(-82919.25774189297), np.float64(-88556.1770837432), np.float64(-80123.82594781015), np.float64(-68533.52741548598), np.float64(-81078.04958404117), np.float64(-75913.5580188279), np.float64(-92233.02412246623), np.float64(-73701.55631138111), np.float64(-79061.44044528689), np.float64(-76271.64543289493), np.float64(-90726.9962408215), np.float64(-93194.40773323069), np.float64(-92992.0858766358), np.float64(-69913.71958128332), np.float64(-78965.67038491947), np.float64(-94814.72037241588), np.float64(-68955.69302479399), np.float64(-69918.12947267295), np.float64(-73646.65640016113), np.float64(-73994.35100847037), np.float64(-67080.24172665516), np.float64(-67253.39796395163), np.float64(-83563.0107031059), np.float64(-86674.51588155622), np.float64(-54670.163341932115), np.float64(-77322.00334738907), np.float64(-93865.53536878743), np.float64(-88218.35055962266), np.float64(-72764.11310146253), np.float64(-63945.28957554717), np.float64(-73936.17460687588), np.float64(-71669.90342779188), np.float64(-68070.84478962819)], 'episode_lengths': [6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000], 'policy_default_policy_reward': [np.float64(-87265.00678303203), np.float64(-69303.2053160704), np.float64(-88821.85211989684), np.float64(-62705.89313979828), np.float64(-72854.18402315247), np.float64(-70942.11558001694), np.float64(-93164.28256217876), np.float64(-68605.3794538616), np.float64(-90508.04977711906), np.float64(-66654.22221157215), np.float64(-73660.88114615614), np.float64(-66305.61748110545), np.float64(-67588.51202727568), np.float64(-85979.89353834318), np.float64(-73220.53417214795), np.float64(-98384.8808897089), np.float64(-73500.38453014781), np.float64(-74818.63171667159), np.float64(-78415.09825564077), np.float64(-84802.23116566429), np.float64(-69056.91087256312), np.float64(-73484.71459061868), np.float64(-86709.4788717425), np.float64(-75833.98913200163), np.float64(-70057.18321544385), np.float64(-79773.73662290155), np.float64(-94033.99226156091), np.float64(-101361.1080662428), np.float64(-59655.08766371399), np.float64(-64948.18293603431), np.float64(-65620.82815609808), np.float64(-71054.6260055471), np.float64(-67235.18279397885), np.float64(-69485.55928721653), np.float64(-67165.37017239758), np.float64(-62140.583033596704), np.float64(-79397.4064397162), np.float64(-77208.6813065188), np.float64(-92918.15942410714), np.float64(-81486.9300934303), np.float64(-86429.98512648797), np.float64(-91862.724667818), np.float64(-83783.75370275961), np.float64(-80313.48885055508), np.float64(-54610.63476678245), np.float64(-91666.6432685723), np.float64(-56873.16374968131), np.float64(-80531.34434158572), np.float64(-78761.49027525396), np.float64(-66296.30628320033), np.float64(-62604.15649562747), np.float64(-70250.87129491681), np.float64(-67009.64834908587), np.float64(-91689.76764967456), np.float64(-91008.94638656234), np.float64(-81611.73875117682), np.float64(-69016.20931330882), np.float64(-77287.70397641629), np.float64(-101912.84333920732), np.float64(-69472.42966858305), np.float64(-83133.85844172745), np.float64(-78180.38428228846), np.float64(-74685.68799869527), np.float64(-89553.12849368063), np.float64(-98461.02301348049), np.float64(-59897.221941504096), np.float64(-69572.76356441602), np.float64(-82919.25774189297), np.float64(-88556.1770837432), np.float64(-80123.82594781015), np.float64(-68533.52741548598), np.float64(-81078.04958404117), np.float64(-75913.5580188279), np.float64(-92233.02412246623), np.float64(-73701.55631138111), np.float64(-79061.44044528689), np.float64(-76271.64543289493), np.float64(-90726.9962408215), np.float64(-93194.40773323069), np.float64(-92992.0858766358), np.float64(-69913.71958128332), np.float64(-78965.67038491947), np.float64(-94814.72037241588), np.float64(-68955.69302479399), np.float64(-69918.12947267295), np.float64(-73646.65640016113), np.float64(-73994.35100847037), np.float64(-67080.24172665516), np.float64(-67253.39796395163), np.float64(-83563.0107031059), np.float64(-86674.51588155622), np.float64(-54670.163341932115), np.float64(-77322.00334738907), np.float64(-93865.53536878743), np.float64(-88218.35055962266), np.float64(-72764.11310146253), np.float64(-63945.28957554717), np.float64(-73936.17460687588), np.float64(-71669.90342779188), np.float64(-68070.84478962819)]}, 'sampler_perf': {'mean_raw_obs_processing_ms': np.float64(0.19843648027612937), 'mean_inference_ms': np.float64(7.097749830920507), 'mean_action_processing_ms': np.float64(0.14645689680209165), 'mean_env_wait_ms': np.float64(1.3480718778102767), 'mean_env_render_ms': np.float64(0.0)}, 'num_faulty_episodes': 0, 'connector_metrics': {'ObsPreprocessorConnector_ms': np.float64(0.006873130798339844), 'StateBufferConnector_ms': np.float64(0.003324270248413086), 'ViewRequirementAgentConnector_ms': np.float64(0.08550190925598145)}, 'num_episodes': 16, 'episode_return_max': np.float64(-54610.63476678245), 'episode_return_min': np.float64(-101912.84333920732), 'episode_return_mean': np.float64(-77371.5452142158), 'episodes_this_iter': 16}, 'num_healthy_workers': 16, 'num_in_flight_async_sample_reqs': 0, 'num_remote_worker_restarts': 0, 'num_agent_steps_sampled': 20080000, 'num_agent_steps_trained': 24900000, 'num_env_steps_sampled': 20080000, 'num_env_steps_trained': 24900000, 'num_env_steps_sampled_this_iter': 80000, 'num_env_steps_trained_this_iter': 100000, 'num_env_steps_sampled_throughput_per_sec': 1316.4893551804455, 'num_env_steps_trained_throughput_per_sec': 1645.6116939755568, 'timesteps_total': 20080000, 'num_env_steps_sampled_lifetime': 20080000, 'num_agent_steps_sampled_lifetime': 20080000, 'num_steps_trained_this_iter': 100000, 'agent_timesteps_total': 20080000, 'timers': {'training_iteration_time_ms': 63711.807, 'restore_workers_time_ms': 0.01, 'training_step_time_ms': 63711.773, 'sample_time_ms': 45886.471, 'load_time_ms': 37.235, 'load_throughput': 2685629.912, 'learn_time_ms': 397.644, 'learn_throughput': 251481.288, 'synch_weights_time_ms': 21.743}, 'counters': {'num_env_steps_sampled': 20080000, 'num_env_steps_trained': 24900000, 'num_agent_steps_sampled': 20080000, 'num_agent_steps_trained': 24900000, 'last_target_update_ts': 20080000, 'num_target_updates': 249}, 'done': False, 'training_iteration': 251, 'trial_id': 'default', 'date': '2025-03-27_20-53-23', 'timestamp': 1743076403, 'time_this_iter_s': 60.822176933288574, 'time_total_s': 16504.027030706406, 'pid': 5079, 'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': {'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'enable_rl_module_and_learner': False, 'enable_env_runner_and_connector_v2': False, 'env': 'joy-v1', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'env_task_fn': None, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, 'num_envs_per_env_runner': 1, 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0.01875, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'max_requests_in_flight_per_env_runner': 2, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 5000, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, 'num_learners': 1, 'num_gpus_per_learner': 0.6, 'num_cpus_per_learner': 1, 'local_gpu_idx': 0, 'gamma': 0.95, 'lr': None, 'grad_clip': None, 'grad_clip_by': 'global_norm', 'train_batch_size_per_learner': 256, 'train_batch_size': 100000, 'num_epochs': 1, 'minibatch_size': 10000, 'shuffle_batch_per_epoch': False, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'explore': True, 'exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x772ef7d73e20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, '_run_training_always_in_thread': False, '_evaluation_parallel_to_training_wo_thread': False, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': None, '_AlgorithmConfig__prior_exploration_config': None, 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 512], 'fcnet_activation': 'relu', 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'tanh', 'custom_model': None, 'custom_model_config': {}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': 1, 'replay_buffer_config': {'_enable_replay_buffer_api': True, 'capacity': 1000000, 'type': 'MultiAgentPrioritizedReplayBuffer', 'replay_batch_size': 10000, 'prioritized_replay': True, 'prioritized_replay_alpha': 0.6, 'prioritized_replay_beta': 0.4, 'prioritized_replay_eps': 1e-06}, 'store_buffer_in_checkpoints': False, 'training_intensity': None, 'optimization': {'actor_learning_rate': 0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, 'actor_lr': 3e-05, 'critic_lr': 0.0003, 'alpha_lr': 0.0003, 'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': 200000, '_deterministic_loss': False, '_use_beta_distribution': False, 'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': <class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 16504.027030706406, 'iterations_since_restore': 251, 'perf': {'cpu_util_percent': np.float64(50.09518072289155), 'ram_util_percent': np.float64(90.59518072289156), 'gpu_util_percent0': np.float64(0.720963855421687), 'vram_util_percent0': np.float64(0.3939650202371987)}})\n",
      "251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/prioritized_replay_buffer.py:140: RuntimeWarning: divide by zero encountered in scalar power\n",
      "  weight = (p_sample * len(self)) ** (-beta)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m save_name = \u001b[33m\"\u001b[39m\u001b[33mSAC_layer_Big_chordal_relu_sampling001_327\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     result = \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# result.pop(\"config\")\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;66;03m# pprint(result)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:331\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    330\u001b[39m     skipped = skip_exceptions(e)\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m skipped \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexception_cause\u001b[39;00m(skipped)\n\u001b[32m    333\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mstep() needs to return a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    335\u001b[39m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:328\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    326\u001b[39m start = time.time()\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    330\u001b[39m     skipped = skip_exceptions(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:933\u001b[39m, in \u001b[36mAlgorithm.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    923\u001b[39m     (\n\u001b[32m    924\u001b[39m         train_results,\n\u001b[32m    925\u001b[39m         eval_results,\n\u001b[32m    926\u001b[39m         train_iter_ctx,\n\u001b[32m    927\u001b[39m     ) = \u001b[38;5;28mself\u001b[39m._run_one_training_iteration_and_evaluation_in_parallel()\n\u001b[32m    929\u001b[39m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[32m    930\u001b[39m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[32m    931\u001b[39m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[32m    932\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m933\u001b[39m     train_results, train_iter_ctx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[38;5;66;03m# Sequential: Train (already done above), then evaluate.\u001b[39;00m\n\u001b[32m    936\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m evaluate_this_iter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.evaluation_parallel_to_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:3498\u001b[39m, in \u001b[36mAlgorithm._run_one_training_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   3494\u001b[39m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[32m   3495\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._timers[TRAINING_STEP_TIMER]:\n\u001b[32m   3496\u001b[39m     \u001b[38;5;66;03m# TODO (sven): Should we reduce the different\u001b[39;00m\n\u001b[32m   3497\u001b[39m     \u001b[38;5;66;03m#  `training_step_results` over time with MetricsLogger.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3498\u001b[39m     training_step_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3500\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training_step_results:\n\u001b[32m   3501\u001b[39m     results = training_step_results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/sac/sac.py:615\u001b[39m, in \u001b[36mSAC.training_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._training_step_new_api_stack(with_noise_reset=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    612\u001b[39m \u001b[38;5;66;03m# Old API stack (Policy, RolloutWorker, Connector, maybe RLModule,\u001b[39;00m\n\u001b[32m    613\u001b[39m \u001b[38;5;66;03m# maybe Learner).\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m615\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_training_step_old_api_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/algorithms/dqn/dqn.py:870\u001b[39m, in \u001b[36mDQN._training_step_old_api_stack\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    867\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cur_ts > \u001b[38;5;28mself\u001b[39m.config.num_steps_sampled_before_learning_starts:\n\u001b[32m    868\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sample_and_train_weight):\n\u001b[32m    869\u001b[39m         \u001b[38;5;66;03m# Sample training batch (MultiAgentBatch) from replay buffer.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m         train_batch = \u001b[43msample_min_n_steps_from_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_replay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcount_by_agent_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount_steps_by\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43magent_steps\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m         \u001b[38;5;66;03m# Postprocess batch before we learn on it\u001b[39;00m\n\u001b[32m    877\u001b[39m         post_fn = \u001b[38;5;28mself\u001b[39m.config.get(\u001b[33m\"\u001b[39m\u001b[33mbefore_learn_on_batch\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28;01mlambda\u001b[39;00m b, *a: b)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/utils.py:193\u001b[39m, in \u001b[36msample_min_n_steps_from_buffer\u001b[39m\u001b[34m(replay_buffer, min_steps, count_by_agent_steps)\u001b[39m\n\u001b[32m    191\u001b[39m train_batches = []\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m train_batch_size < min_steps:\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     batch = \u001b[43mreplay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m     batch_len = batch.agent_steps() \u001b[38;5;28;01mif\u001b[39;00m count_by_agent_steps \u001b[38;5;28;01melse\u001b[39;00m batch.env_steps()\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m batch_len == \u001b[32m0\u001b[39m:\n\u001b[32m    196\u001b[39m         \u001b[38;5;66;03m# Replay has not started, so we can't accumulate timesteps here\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/multi_agent_replay_buffer.py:331\u001b[39m, in \u001b[36mMultiAgentReplayBuffer.sample\u001b[39m\u001b[34m(self, num_items, policy_id, **kwargs)\u001b[39m\n\u001b[32m    329\u001b[39m samples = {}\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m policy_id, replay_buffer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.replay_buffers.items():\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     samples[policy_id] = \u001b[43mreplay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m MultiAgentBatch(samples, \u001b[38;5;28msum\u001b[39m(s.count \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m samples.values()))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd239/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/prioritized_replay_buffer.py:141\u001b[39m, in \u001b[36mPrioritizedReplayBuffer.sample\u001b[39m\u001b[34m(self, num_items, beta, **kwargs)\u001b[39m\n\u001b[32m    139\u001b[39m p_sample = \u001b[38;5;28mself\u001b[39m._it_sum[idx] / \u001b[38;5;28mself\u001b[39m._it_sum.sum()\n\u001b[32m    140\u001b[39m weight = (p_sample * \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)) ** (-beta)\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m count = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_storage\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m.count\n\u001b[32m    142\u001b[39m \u001b[38;5;66;03m# If zero-padded, count will not be the actual batch size of the\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[38;5;66;03m# data.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    145\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m._storage[idx], SampleBatch)\n\u001b[32m    146\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._storage[idx].zero_padded\n\u001b[32m    147\u001b[39m ):\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "import datetime\n",
    "from scipy.io import savemat\n",
    "\n",
    "n_iter = 1200\n",
    "save_iter = 0\n",
    "save_name = \"SAC_layer_Big_chordal_relu_sampling001_327\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}\", end=\", \")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%50 == 0:\n",
    "        checkpoint_dir = algo.save(save_name+\"_\"+str(save_iter))\n",
    "        print(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "\n",
    "        # Record Validation Env\n",
    "        env = gym.make(\"horcrux_terrain_v2/plane-v2\", **render_env_config)\n",
    "        obs = env.reset()[0]\n",
    "        env_done = False\n",
    "\n",
    "        _video_base_name = 'rl-video'\n",
    "\n",
    "        rew_return = 0\n",
    "        frames = []\n",
    "        info = []\n",
    "\n",
    "        for i in range(3000):\n",
    "            act = algo.compute_single_action(observation=obs)\n",
    "            obs, _step_rew, _, env_done, env_info = env.step(act)\n",
    "            pixels = env.render()\n",
    "            frames.append(pixels)\n",
    "            info.append(env_info)\n",
    "            rew_return += _step_rew\n",
    "\n",
    "        _f_name, _full_path = get_unique_filename(f\"./video/{_video_base_name}\")\n",
    "        rew_dict = get_data_from_info(info)\n",
    "        rew_dict['rew_return'] = rew_return\n",
    "\n",
    "        # Save Video\n",
    "        save_video(frames, \"./video/\", name_prefix=_f_name, fps=env.metadata['render_fps'])\n",
    "\n",
    "        # Save Video Info\n",
    "        _f_video_info = open(f\"./video/joy_input.txt\", 'a')\n",
    "        _f_video_info.write(f'File creation time: {datetime.datetime.now()}\\n')\n",
    "        _f_video_info.write(f'Video file name: {_f_name}, Joy input: {info[0][\"joy_input\"]}, Friction: {info[0][\"friction_coeff\"]}\\n')\n",
    "        _f_video_info.close()\n",
    "\n",
    "        # Save Reward Info mat file\n",
    "        savemat(f\"./data/{save_name}_{_f_name}.mat\", rew_dict)\n",
    "\n",
    "        env.close()\n",
    "\n",
    "\n",
    "algo.save(save_name+str(\"_final\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b055f640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd239",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
