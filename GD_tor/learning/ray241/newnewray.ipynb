{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 진짜 완전 새롭게 다시 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from horcrux_terrain_v2.envs import PlaneJoyWorld\n",
    "\n",
    "import ray\n",
    "from ray.tune.registry import register_env\n",
    "from ray.rllib.algorithms.sac import SACConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ray 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 20:19:36,670\tINFO worker.py:1832 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://10.130.6.78:8265 \u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "774cde6cfe494ca4b11b76ee8de90af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<div class=\"lm-Widget p-Widget lm-Panel p-Panel jp-Cell-outputWrapper\">\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <div class=\"jp-RenderedHTMLCommon\" style=\"display: flex; flex-direction: row;\">\n",
       "  <svg viewBox=\"0 0 567 224\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\" style=\"height: 3em;\">\n",
       "    <g clip-path=\"url(#clip0_4338_178347)\">\n",
       "        <path d=\"M341.29 165.561H355.29L330.13 129.051C345.63 123.991 354.21 112.051 354.21 94.2307C354.21 71.3707 338.72 58.1807 311.88 58.1807H271V165.561H283.27V131.661H311.8C314.25 131.661 316.71 131.501 319.01 131.351L341.25 165.561H341.29ZM283.29 119.851V70.0007H311.82C331.3 70.0007 342.34 78.2907 342.34 94.5507C342.34 111.271 331.34 119.861 311.82 119.861L283.29 119.851ZM451.4 138.411L463.4 165.561H476.74L428.74 58.1807H416L367.83 165.561H380.83L392.83 138.411H451.4ZM446.19 126.601H398L422 72.1407L446.24 126.601H446.19ZM526.11 128.741L566.91 58.1807H554.35L519.99 114.181L485.17 58.1807H472.44L514.01 129.181V165.541H526.13V128.741H526.11Z\" fill=\"var(--jp-ui-font-color0)\"/>\n",
       "        <path d=\"M82.35 104.44C84.0187 97.8827 87.8248 92.0678 93.1671 87.9146C98.5094 83.7614 105.083 81.5067 111.85 81.5067C118.617 81.5067 125.191 83.7614 130.533 87.9146C135.875 92.0678 139.681 97.8827 141.35 104.44H163.75C164.476 101.562 165.622 98.8057 167.15 96.2605L127.45 56.5605C121.071 60.3522 113.526 61.6823 106.235 60.3005C98.9443 58.9187 92.4094 54.9203 87.8602 49.0574C83.3109 43.1946 81.0609 35.8714 81.5332 28.4656C82.0056 21.0599 85.1679 14.0819 90.4252 8.8446C95.6824 3.60726 102.672 0.471508 110.08 0.0272655C117.487 -0.416977 124.802 1.86091 130.647 6.4324C136.493 11.0039 140.467 17.5539 141.821 24.8501C143.175 32.1463 141.816 39.6859 138 46.0505L177.69 85.7505C182.31 82.9877 187.58 81.4995 192.962 81.4375C198.345 81.3755 203.648 82.742 208.33 85.3976C213.012 88.0532 216.907 91.9029 219.616 96.5544C222.326 101.206 223.753 106.492 223.753 111.875C223.753 117.258 222.326 122.545 219.616 127.197C216.907 131.848 213.012 135.698 208.33 138.353C203.648 141.009 198.345 142.375 192.962 142.313C187.58 142.251 182.31 140.763 177.69 138L138 177.7C141.808 184.071 143.155 191.614 141.79 198.91C140.424 206.205 136.44 212.75 130.585 217.313C124.731 221.875 117.412 224.141 110.004 223.683C102.596 223.226 95.6103 220.077 90.3621 214.828C85.1139 209.58 81.9647 202.595 81.5072 195.187C81.0497 187.779 83.3154 180.459 87.878 174.605C92.4405 168.751 98.9853 164.766 106.281 163.401C113.576 162.035 121.119 163.383 127.49 167.19L167.19 127.49C165.664 124.941 164.518 122.182 163.79 119.3H141.39C139.721 125.858 135.915 131.673 130.573 135.826C125.231 139.98 118.657 142.234 111.89 142.234C105.123 142.234 98.5494 139.98 93.2071 135.826C87.8648 131.673 84.0587 125.858 82.39 119.3H60C58.1878 126.495 53.8086 132.78 47.6863 136.971C41.5641 141.163 34.1211 142.972 26.7579 142.059C19.3947 141.146 12.6191 137.574 7.70605 132.014C2.79302 126.454 0.0813599 119.29 0.0813599 111.87C0.0813599 104.451 2.79302 97.2871 7.70605 91.7272C12.6191 86.1673 19.3947 82.5947 26.7579 81.6817C34.1211 80.7686 41.5641 82.5781 47.6863 86.7696C53.8086 90.9611 58.1878 97.2456 60 104.44H82.35ZM100.86 204.32C103.407 206.868 106.759 208.453 110.345 208.806C113.93 209.159 117.527 208.258 120.522 206.256C123.517 204.254 125.725 201.276 126.771 197.828C127.816 194.38 127.633 190.677 126.253 187.349C124.874 184.021 122.383 181.274 119.205 179.577C116.027 177.88 112.359 177.337 108.826 178.042C105.293 178.746 102.113 180.654 99.8291 183.44C97.5451 186.226 96.2979 189.718 96.3 193.32C96.2985 195.364 96.7006 197.388 97.4831 199.275C98.2656 201.163 99.4132 202.877 100.86 204.32ZM204.32 122.88C206.868 120.333 208.453 116.981 208.806 113.396C209.159 109.811 208.258 106.214 206.256 103.219C204.254 100.223 201.275 98.0151 197.827 96.97C194.38 95.9249 190.676 96.1077 187.348 97.4873C184.02 98.8669 181.274 101.358 179.577 104.536C177.879 107.714 177.337 111.382 178.041 114.915C178.746 118.448 180.653 121.627 183.439 123.911C186.226 126.195 189.717 127.443 193.32 127.44C195.364 127.443 197.388 127.042 199.275 126.259C201.163 125.476 202.878 124.328 204.32 122.88ZM122.88 19.4205C120.333 16.8729 116.981 15.2876 113.395 14.9347C109.81 14.5817 106.213 15.483 103.218 17.4849C100.223 19.4868 98.0146 22.4654 96.9696 25.9131C95.9245 29.3608 96.1073 33.0642 97.4869 36.3922C98.8665 39.7202 101.358 42.4668 104.535 44.1639C107.713 45.861 111.381 46.4036 114.914 45.6992C118.447 44.9949 121.627 43.0871 123.911 40.301C126.195 37.515 127.442 34.0231 127.44 30.4205C127.44 28.3772 127.038 26.3539 126.255 24.4664C125.473 22.5788 124.326 20.8642 122.88 19.4205ZM19.42 100.86C16.8725 103.408 15.2872 106.76 14.9342 110.345C14.5813 113.93 15.4826 117.527 17.4844 120.522C19.4863 123.518 22.4649 125.726 25.9127 126.771C29.3604 127.816 33.0638 127.633 36.3918 126.254C39.7198 124.874 42.4664 122.383 44.1635 119.205C45.8606 116.027 46.4032 112.359 45.6988 108.826C44.9944 105.293 43.0866 102.114 40.3006 99.8296C37.5145 97.5455 34.0227 96.2983 30.42 96.3005C26.2938 96.3018 22.337 97.9421 19.42 100.86ZM100.86 100.86C98.3125 103.408 96.7272 106.76 96.3742 110.345C96.0213 113.93 96.9226 117.527 98.9244 120.522C100.926 123.518 103.905 125.726 107.353 126.771C110.8 127.816 114.504 127.633 117.832 126.254C121.16 124.874 123.906 122.383 125.604 119.205C127.301 116.027 127.843 112.359 127.139 108.826C126.434 105.293 124.527 102.114 121.741 99.8296C118.955 97.5455 115.463 96.2983 111.86 96.3005C109.817 96.299 107.793 96.701 105.905 97.4835C104.018 98.2661 102.303 99.4136 100.86 100.86Z\" fill=\"#00AEEF\"/>\n",
       "    </g>\n",
       "    <defs>\n",
       "        <clipPath id=\"clip0_4338_178347\">\n",
       "            <rect width=\"566.93\" height=\"223.75\" fill=\"white\"/>\n",
       "        </clipPath>\n",
       "    </defs>\n",
       "  </svg>\n",
       "</div>\n",
       "\n",
       "        <table class=\"jp-RenderedHTMLCommon\" style=\"border-collapse: collapse;color: var(--jp-ui-font-color1);font-size: var(--jp-ui-font-size1);\">\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>3.12.9</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "        <td style=\"text-align: left\"><b>2.43.0</b></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://10.130.6.78:8265\" target=\"_blank\">http://10.130.6.78:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "</table>\n",
       "\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "RayContext(dashboard_url='10.130.6.78:8265', python_version='3.12.9', ray_version='2.43.0', ray_commit='ecdcdc6a6e63dc4bcd6ea16aae256ce4d32a7e2c')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=69704)\u001b[0m 2025-03-14 20:20:40,436\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(SingleAgentEnvRunner pid=69700)\u001b[0m 2025-03-14 20:20:46,023\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 8x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_WrappedExecutable pid=69705)\u001b[0m Setting up process group for: env:// [rank=0, world_size=1]\n",
      "\u001b[36m(_WrappedExecutable pid=69705)\u001b[0m 2025-03-14 20:21:12,685\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import psutil\n",
    "\n",
    "# conn_ip = \"\"\n",
    "# interfaces = psutil.net_if_addrs()\n",
    "# for interface_name, addresses in interfaces.items():\n",
    "#     if \"openvpn\" in interface_name.lower() and \"tap\" in interface_name.lower():\n",
    "#         snicaddrs = interfaces[str(interface_name)]\n",
    "#         for addrfamily in snicaddrs:\n",
    "#             if addrfamily.family == socket.AF_INET:\n",
    "#                 conn_ip = addrfamily.address\n",
    "\n",
    "# 해당 init을 통해서 VPN을 통한 외부 접속 가능함.\n",
    "ray.init(dashboard_host=\"0.0.0.0\", dashboard_port=8265)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_config = {\n",
    "    \"forward_reward_weight\": 6.5,\n",
    "    \"side_cost_weight\": 2.0,\n",
    "    \"unhealthy_max_steps\": 100,\n",
    "    \"healthy_reward\": 0.5,\n",
    "    \"healthy_roll_range\": (-35,35),\n",
    "    \"terminating_roll_range\": (-85,85),\n",
    "    \"rotation_norm_cost_weight\": 0.01,\n",
    "    \"rotation_orientation_cost_weight\": 1.2,\n",
    "    \"termination_reward\": 0,\n",
    "    \"gait_params\": (30, 30, 60, 60, 0),\n",
    "    \"use_friction_chg\": True,\n",
    "    \"joy_input_random\": True,\n",
    "}\n",
    "\n",
    "# JoyWorld\n",
    "register_env(\"joy-v1\", lambda config: PlaneJoyWorld( forward_reward_weight=env_config[\"forward_reward_weight\"], \n",
    "                                                     side_cost_weight=env_config[\"side_cost_weight\"], \n",
    "                                                     unhealthy_max_steps=env_config[\"unhealthy_max_steps\"],\n",
    "                                                     healthy_reward=env_config[\"healthy_reward\"], \n",
    "                                                     healthy_roll_range=env_config[\"healthy_roll_range\"],\n",
    "                                                     terminating_roll_range=env_config[\"terminating_roll_range\"],\n",
    "                                                     rotation_norm_cost_weight=env_config[\"rotation_norm_cost_weight\"],\n",
    "                                                     rotation_orientation_cost_weight=env_config[\"rotation_orientation_cost_weight\"],\n",
    "                                                     termination_reward=env_config[\"termination_reward\"],\n",
    "                                                     gait_params=env_config[\"gait_params\"],\n",
    "                                                     use_friction_chg=env_config[\"use_friction_chg\"],\n",
    "                                                     joy_input_random=env_config[\"joy_input_random\"],\n",
    "                                                   )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-14 20:20:08,363\tWARNING algorithm_config.py:4703 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-03-14 20:20:08,364\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "/home/bong/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:512: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "`UnifiedLogger` will be removed in Ray 2.7.\n",
      "  return UnifiedLogger(config, logdir, loggers=None)\n",
      "/home/bong/anaconda3/envs/gd/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "/home/bong/anaconda3/envs/gd/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS=\"ignore::DeprecationWarning\"\n",
      "The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.\n",
      "  self._loggers.append(cls(self.config, self.logdir, self.trial))\n",
      "2025-03-14 20:21:09,036\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "2025-03-14 20:21:09,050\tWARNING sac.py:487 -- You are running SAC on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "2025-03-14 20:21:12,767\tINFO trainable.py:160 -- Trainable.setup took 64.396 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    }
   ],
   "source": [
    "config = (\n",
    "    SACConfig()\n",
    "    .environment(\"joy-v1\")\n",
    "    .env_runners(num_env_runners=16, num_envs_per_env_runner=4)\n",
    "    .framework('torch')\n",
    "    .learners(num_learners=1, num_gpus_per_learner=1)\n",
    "    .training(\n",
    "        gamma=0.9,\n",
    "        actor_lr=0.001,\n",
    "        critic_lr=0.002,\n",
    "        train_batch_size_per_learner= 32768,\n",
    "\n",
    "        replay_buffer_config={\n",
    "            \"_enable_replay_buffer_api\": True,\n",
    "            # \"type\": \"EpisodeReplayBuffer\",\n",
    "            \"capacity\": int(4e7),\n",
    "            \"replay_batch_size\": 1024,\n",
    "            # \"replay_sequence_length\": 1,\n",
    "        },\n",
    "\n",
    "        q_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define custom Q-model(s).\n",
    "            \"custom_model_config\": {},\n",
    "        },\n",
    "        policy_model_config = {\n",
    "            \"fcnet_hiddens\": [512, 512, 512, 512, 512, 32],\n",
    "            \"fcnet_activation\": \"tanh\",\n",
    "            \"post_fcnet_hiddens\": [],\n",
    "            \"post_fcnet_activation\": None,\n",
    "            \"custom_model\": None,  # Use this to define a custom policy model.\n",
    "            \"custom_model_config\": {},\n",
    "        },\n",
    "    )\n",
    ")\n",
    "\n",
    "# Build the SAC algo object from the config and run 1 training iteration.\n",
    "algo = config.build_algo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000, ('Checkpoint saved in directory '\n",
      " 'TrainingResult(checkpoint=Checkpoint(filesystem=local, '\n",
      " 'path=~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314_0), '\n",
      " \"metrics={'timers': {'training_iteration': 1.7743404020002345, \"\n",
      " \"'restore_env_runners': 1.3715231978022586e-05, 'training_step': \"\n",
      " \"0.07788534697921848, 'env_runner_sampling_timer': 0.06294259019098451, \"\n",
      " \"'replay_buffer_add_data_timer': 0.012423388496532422}, 'env_runners': \"\n",
      " \"{'num_env_steps_sampled_lifetime': 576, 'timers': {'connectors': \"\n",
      " \"{'NumpyToTensor': np.float64(0.00013170512771960998), \"\n",
      " \"'BatchIndividualItems': np.float64(6.939898187275396e-05), \"\n",
      " \"'AddTimeDimToBatchAndZeroPad': np.float64(1.2195371317525106e-05), \"\n",
      " \"'AddObservationsFromEpisodesToBatch': np.float64(3.797402561839562e-05), \"\n",
      " \"'GetActions': np.float64(0.002846431097489402), 'UnBatchToIndividualItems': \"\n",
      " \"np.float64(4.23569471735722e-05), 'ListifyDataForVectorEnv': \"\n",
      " \"np.float64(5.435709172422095e-05), 'NormalizeAndClipActions': \"\n",
      " \"np.float64(0.0003120373121945343), 'AddStatesFromEpisodesToBatch': \"\n",
      " \"np.float64(3.975400894405558e-06), 'RemoveSingleTsTimeRankFromBatch': \"\n",
      " \"np.float64(2.7597223389720194e-06), 'TensorToNumpy': \"\n",
      " \"np.float64(0.00032735457931605)}}, 'num_episodes_lifetime': 0, \"\n",
      " \"'num_agent_steps_sampled': {'default_agent': 576}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 576}, 'sample': \"\n",
      " \"np.float64(0.025678766353276424), 'env_to_module_sum_episodes_length_out': \"\n",
      " \"np.float64(0.18859071006944456), 'num_env_steps_sampled': 576, \"\n",
      " \"'weights_seq_no': 0.0, 'num_module_steps_sampled_lifetime': \"\n",
      " \"{'default_policy': 576}, 'num_episodes': 0, \"\n",
      " \"'num_agent_steps_sampled_lifetime': {'default_agent': 576}, \"\n",
      " \"'env_to_module_sum_episodes_length_in': np.float64(0.18859071006944456), \"\n",
      " \"'time_between_sampling': np.float64(0.039557647697295154), \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': nan}, \"\n",
      " \"'num_training_step_calls_per_iteration': 9, \"\n",
      " \"'num_env_steps_sampled_lifetime': 576, 'fault_tolerance': \"\n",
      " \"{'num_healthy_workers': 16, 'num_remote_worker_restarts': 0}, \"\n",
      " \"'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': nan, 'done': False, \"\n",
      " \"'training_iteration': 1, 'trial_id': 'default', 'date': \"\n",
      " \"'2025-03-14_20-21-39', 'timestamp': 1741951299, 'time_this_iter_s': \"\n",
      " \"1.7942140102386475, 'time_total_s': 1.7942140102386475, 'pid': 69331, \"\n",
      " \"'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': \"\n",
      " \"{'exploration_config': {}, 'extra_python_environs_for_driver': {}, \"\n",
      " \"'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', \"\n",
      " \"'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, \"\n",
      " \"'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': \"\n",
      " \"{'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, \"\n",
      " \"'gpu_options': {'allow_growth': True}, 'log_device_placement': False, \"\n",
      " \"'device_count': {'CPU': 1}, 'allow_soft_placement': True}, \"\n",
      " \"'local_tf_session_args': {'intra_op_parallelism_threads': 8, \"\n",
      " \"'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, \"\n",
      " \"'torch_compile_learner_what_to_compile': \"\n",
      " \"<TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, \"\n",
      " \"'torch_compile_learner_dynamo_backend': 'inductor', \"\n",
      " \"'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, \"\n",
      " \"'torch_compile_worker_dynamo_backend': 'onnxrt', \"\n",
      " \"'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, \"\n",
      " \"'torch_skip_nan_gradients': False, 'env': 'joy-v1', 'env_config': {}, \"\n",
      " \"'observation_space': None, 'action_space': None, 'clip_rewards': None, \"\n",
      " \"'normalize_actions': True, 'clip_actions': False, '_is_atari': None, \"\n",
      " \"'disable_env_checking': False, 'render_env': False, 'action_mask_key': \"\n",
      " \"'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, \"\n",
      " \"'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'SYNC', \"\n",
      " \"'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, \"\n",
      " \"'custom_resources_per_env_runner': {}, \"\n",
      " \"'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, \"\n",
      " \"'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, \"\n",
      " \"'_env_to_module_connector': None, \"\n",
      " \"'add_default_connectors_to_env_to_module_pipeline': True, \"\n",
      " \"'_module_to_env_connector': None, \"\n",
      " \"'add_default_connectors_to_module_to_env_pipeline': True, \"\n",
      " \"'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', \"\n",
      " \"'batch_mode': 'truncate_episodes', 'compress_observations': False, \"\n",
      " \"'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, \"\n",
      " \"'enable_tf1_exec_eagerly': False, 'sample_collector': <class \"\n",
      " \"'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, \"\n",
      " \"'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', \"\n",
      " \"'update_worker_filter_stats': True, 'use_worker_filter_stats': True, \"\n",
      " \"'sampler_perf_stats_ema_coef': None, 'num_learners': 1, \"\n",
      " \"'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', \"\n",
      " \"'num_aggregator_actors_per_learner': 0, \"\n",
      " \"'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, \"\n",
      " \"'max_requests_in_flight_per_learner': 3, 'gamma': 0.9, 'lr': None, \"\n",
      " \"'grad_clip': None, 'grad_clip_by': 'global_norm', \"\n",
      " \"'_train_batch_size_per_learner': 32768, 'train_batch_size': 256, \"\n",
      " \"'num_epochs': 1, 'minibatch_size': None, 'shuffle_batch_per_epoch': False, \"\n",
      " \"'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', \"\n",
      " \"'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, \"\n",
      " \"'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, \"\n",
      " \"'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': \"\n",
      " \"None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, \"\n",
      " \"'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': \"\n",
      " \"None, 'conv_transpose_kernel_initializer_config': None, \"\n",
      " \"'conv_transpose_bias_initializer': None, \"\n",
      " \"'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, \"\n",
      " \"'post_fcnet_weights_initializer_config': None, \"\n",
      " \"'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': \"\n",
      " \"None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': \"\n",
      " \"False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, \"\n",
      " \"'lstm_cell_size': 256, 'lstm_use_prev_action': False, \"\n",
      " \"'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, \"\n",
      " \"'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, \"\n",
      " \"'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': \"\n",
      " \"False, 'attention_num_transformer_units': 1, 'attention_dim': 64, \"\n",
      " \"'attention_num_heads': 1, 'attention_head_dim': 32, \"\n",
      " \"'attention_memory_inference': 50, 'attention_memory_training': 50, \"\n",
      " \"'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, \"\n",
      " \"'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, \"\n",
      " \"'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, \"\n",
      " \"'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, \"\n",
      " \"'custom_preprocessor': None, 'encoder_latent_dim': None, \"\n",
      " \"'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, \"\n",
      " \"'_use_default_native_models': -1, '_disable_preprocessor_api': False, \"\n",
      " \"'_disable_action_flattening': False}, '_learner_connector': None, \"\n",
      " \"'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': \"\n",
      " \"{}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': \"\n",
      " \"None, 'callbacks_on_env_runners_recreated': None, \"\n",
      " \"'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': \"\n",
      " \"None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': \"\n",
      " \"None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, \"\n",
      " \"'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, \"\n",
      " \"'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, \"\n",
      " \"'explore': True, 'enable_rl_module_and_learner': True, \"\n",
      " \"'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': \"\n",
      " \"{'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', \"\n",
      " \"'policy_map_capacity': 100, 'policy_mapping_fn': <function \"\n",
      " 'AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1839c4a980>, '\n",
      " \"'policies_to_train': None, 'policy_states_are_swappable': False, \"\n",
      " \"'observation_fn': None, 'offline_data_class': None, 'input_read_method': \"\n",
      " \"'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, \"\n",
      " \"'input_read_episodes': False, 'input_read_sample_batches': False, \"\n",
      " \"'input_read_batch_size': None, 'input_filesystem': None, \"\n",
      " \"'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'input_spaces_jsonable': True, 'materialize_data': False, \"\n",
      " \"'materialize_mapped_data': True, 'map_batches_kwargs': {}, \"\n",
      " \"'iter_batches_kwargs': {}, 'prelearner_class': None, \"\n",
      " \"'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, \"\n",
      " \"'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, \"\n",
      " \"'input_config': {}, 'actions_in_input_normalized': False, \"\n",
      " \"'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, \"\n",
      " \"'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'output_max_file_size': 67108864, 'output_max_rows_per_file': None, \"\n",
      " \"'output_write_remaining_data': False, 'output_write_method': \"\n",
      " \"'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': \"\n",
      " \"None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, \"\n",
      " \"'offline_sampling': False, 'evaluation_interval': None, \"\n",
      " \"'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', \"\n",
      " \"'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': \"\n",
      " \"False, 'evaluation_force_reset_envs_before_iteration': True, \"\n",
      " \"'evaluation_config': None, 'off_policy_estimation_methods': {}, \"\n",
      " \"'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, \"\n",
      " \"'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, \"\n",
      " \"'keep_per_episode_custom_metrics': False, \"\n",
      " \"'metrics_episode_collection_timeout_s': 60.0, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, \"\n",
      " \"'min_train_timesteps_per_iteration': 0, \"\n",
      " \"'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, \"\n",
      " \"'export_native_model_files': False, 'checkpoint_trainable_policies_only': \"\n",
      " \"False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', \"\n",
      " \"'log_sys_usage': True, 'fake_sampler': False, 'seed': None, \"\n",
      " \"'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, \"\n",
      " \"'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': \"\n",
      " \"60.0, 'restart_failed_sub_environments': False, \"\n",
      " \"'num_consecutive_env_runner_failures_tolerance': 100, \"\n",
      " \"'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': \"\n",
      " \"1800.0, '_model_config': {}, '_rl_module_spec': None, \"\n",
      " \"'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, \"\n",
      " \"'_validate_config': True, '_use_msgpack_checkpoints': False, \"\n",
      " \"'_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, \"\n",
      " \"'_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': \"\n",
      " \"False, '_disable_action_flattening': False, \"\n",
      " \"'_disable_initialize_loss_from_dummy_batch': False, \"\n",
      " \"'_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, \"\n",
      " \"'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, \"\n",
      " \"'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, \"\n",
      " \"'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, \"\n",
      " \"'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, \"\n",
      " \"'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': \"\n",
      " \"True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': \"\n",
      " \"1, 'replay_buffer_config': {'type': 'PrioritizedEpisodeReplayBuffer', \"\n",
      " \"'capacity': 40000000, 'alpha': 0.6, 'beta': 0.4, \"\n",
      " \"'_enable_replay_buffer_api': True, 'replay_batch_size': 1024, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100}, 'store_buffer_in_checkpoints': \"\n",
      " \"False, 'training_intensity': None, 'optimization': {'actor_learning_rate': \"\n",
      " \"0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, \"\n",
      " \"'actor_lr': 0.001, 'critic_lr': 0.002, 'alpha_lr': 0.0003, \"\n",
      " \"'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': \"\n",
      " \"1500, '_deterministic_loss': False, '_use_beta_distribution': False, \"\n",
      " \"'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': \"\n",
      " \"<class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', \"\n",
      " \"'policies': {'default_policy': (None, None, None, None)}, 'callbacks': \"\n",
      " \"<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, \"\n",
      " \"'create_env_on_driver': False, 'custom_eval_function': None, 'framework': \"\n",
      " \"'torch'}, 'time_since_restore': 1.7942140102386475, \"\n",
      " \"'iterations_since_restore': 1, 'perf': {'cpu_util_percent': \"\n",
      " \"np.float64(2.84054054054054), 'ram_util_percent': \"\n",
      " \"np.float64(67.55405405405403), 'gpu_util_percent0': \"\n",
      " \"np.float64(0.1310810810810811), 'vram_util_percent0': \"\n",
      " 'np.float64(0.05681218327702703)}})')\n",
      "001, 002, 003, 004, 005, 006, 007, 008, 009, 010, 011, 012, 013, 014, 015, 016, 017, 018, 019, 020, 021, 022, 023, 024, 025, 026, 027, 028, 029, 030, 031, 032, 033, 034, 035, 036, 037, 038, 039, 040, ('Checkpoint saved in directory '\n",
      " 'TrainingResult(checkpoint=Checkpoint(filesystem=local, '\n",
      " 'path=~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314_1), '\n",
      " \"metrics={'timers': {'training_iteration': 8.461362755283115, \"\n",
      " \"'restore_env_runners': 1.1092253873198702e-05, 'training_step': \"\n",
      " \"6.115163269101109, 'env_runner_sampling_timer': 0.04503578404170677, \"\n",
      " \"'replay_buffer_add_data_timer': 0.016704596680629617, \"\n",
      " \"'synch_env_connectors': 0.018322261658868456, \"\n",
      " \"'replay_buffer_sampling_timer': 5.506912347781627, 'learner_update_timer': \"\n",
      " \"5.836023898013287, 'replay_buffer_update_prios_timer': 0.22924497305118618, \"\n",
      " \"'synch_weights': 0.017664654974879117}, 'env_runners': \"\n",
      " \"{'num_env_steps_sampled_lifetime': 6546, 'timers': {'connectors': \"\n",
      " \"{'NumpyToTensor': np.float64(9.402806928360641e-05), 'BatchIndividualItems': \"\n",
      " \"np.float64(4.555660139840263e-05), 'AddTimeDimToBatchAndZeroPad': \"\n",
      " \"np.float64(8.127507110090443e-06), 'AddObservationsFromEpisodesToBatch': \"\n",
      " \"np.float64(2.45264702576654e-05), 'GetActions': \"\n",
      " \"np.float64(0.001442876190712659), 'UnBatchToIndividualItems': \"\n",
      " \"np.float64(3.5930108465102476e-05), 'ListifyDataForVectorEnv': \"\n",
      " \"np.float64(5.223609148775393e-05), 'NormalizeAndClipActions': \"\n",
      " \"np.float64(0.00022072726914480986), 'AddStatesFromEpisodesToBatch': \"\n",
      " \"np.float64(2.846823586119322e-06), 'RemoveSingleTsTimeRankFromBatch': \"\n",
      " \"np.float64(2.8020360220109877e-06), 'TensorToNumpy': \"\n",
      " \"np.float64(0.0001804100029577269)}}, 'num_episodes_lifetime': 6, \"\n",
      " \"'num_agent_steps_sampled': {'default_agent': 128}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 128}, 'sample': \"\n",
      " \"np.float64(0.017501665836295456), 'env_to_module_sum_episodes_length_out': \"\n",
      " \"np.float64(2.4867780654423477), 'num_env_steps_sampled': 128, \"\n",
      " \"'weights_seq_no': 78.0, 'num_module_steps_sampled_lifetime': \"\n",
      " \"{'default_policy': 6546}, 'num_episodes': 0, \"\n",
      " \"'num_agent_steps_sampled_lifetime': {'default_agent': 6546}, \"\n",
      " \"'env_to_module_sum_episodes_length_in': np.float64(2.4867780654423477), \"\n",
      " \"'time_between_sampling': np.float64(5.722523410425933), \"\n",
      " \"'episode_return_min': 244.17180697964687, 'agent_episode_returns_mean': \"\n",
      " \"{'default_agent': 761.164250930559}, 'module_episode_returns_mean': \"\n",
      " \"{'default_policy': 761.164250930559}, 'episode_len_min': 76, \"\n",
      " \"'episode_len_max': 99, 'episode_return_max': 1215.180542262393, \"\n",
      " \"'episode_return_mean': 761.164250930559, 'episode_duration_sec_mean': \"\n",
      " \"0.019785224166753324, 'episode_len_mean': 84.33333333333333, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.2471271519106}, \"\n",
      " \"'num_training_step_calls_per_iteration': 2, 'replay_buffer': \"\n",
      " \"{'num_agent_steps_added': {'default_agent': 128}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 2588672, 'num_module_steps_added': \"\n",
      " \"{'default_policy': 0}, 'num_module_steps_per_sample': {'default_policy': \"\n",
      " \"12322}, 'num_agent_steps_sampled': {'default_agent': 65536}, \"\n",
      " \"'num_agent_steps_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'module_actual_n_step': {'default_policy': 1.0}, \"\n",
      " \"'num_agent_episodes_added_lifetime': {'default_agent': 70}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 65536}, 'num_agent_episodes': \"\n",
      " \"{'default_agent': 65.06}, 'num_agent_resamples': {'default_agent': 0}, \"\n",
      " \"'num_episodes_stored': 65.06, 'num_module_steps_evicted_lifetime': \"\n",
      " \"{'default_policy': 0}, 'num_env_steps_per_sample': 12322, \"\n",
      " \"'num_env_steps_added': 128, 'num_module_episodes_added_lifetime': \"\n",
      " \"{'default_policy': 6546}, 'num_agent_steps_stored': {'default_agent': \"\n",
      " \"3363.18}, 'num_agent_steps_per_sample_lifetime': {'default_agent': 308599}, \"\n",
      " \"'num_env_steps_added_lifetime': 6546, 'num_resamples': 0, \"\n",
      " \"'num_env_steps_evicted_lifetime': 0, 'num_episodes_evicted_lifetime': 0, \"\n",
      " \"'num_module_steps_added_lifetime': {'default_policy': 70}, \"\n",
      " \"'num_module_steps_stored': {'default_policy': 65.06}, \"\n",
      " \"'num_agent_steps_added_lifetime': {'default_agent': 6546}, \"\n",
      " \"'num_episodes_per_sample': 140, 'num_agent_steps_per_sample': \"\n",
      " \"{'default_agent': 12322}, 'env_step_utilization': 0.08889095841485174, \"\n",
      " \"'num_env_steps_per_sample_lifetime': 308599, 'num_env_steps_sampled': 65536, \"\n",
      " \"'num_module_episodes_evicted': {'default_policy': 0}, \"\n",
      " \"'num_module_episodes_evicted_lifetime': {'default_policy': 0}, \"\n",
      " \"'module_step_utilization': {'default_policy': 0.08889095841485174}, \"\n",
      " \"'num_module_episodes': {'default_policy': 3363.18}, \"\n",
      " \"'num_module_steps_per_sample_lifetime': {'default_policy': 308599}, \"\n",
      " \"'num_module_episodes_added': {'default_policy': 128}, \"\n",
      " \"'num_module_steps_sampled_lifetime': {'default_policy': 2588672}, \"\n",
      " \"'num_env_steps_stored': 3363.18, 'agent_actual_n_step': {'default_agent': \"\n",
      " \"1.0}, 'num_agent_steps_sampled_lifetime': {'default_agent': 2588672}, \"\n",
      " \"'num_env_steps_evicted': 0, 'num_episodes_evicted': 0, \"\n",
      " \"'num_agent_episodes_evicted': {'default_agent': 0}, \"\n",
      " \"'num_module_steps_evicted': {'default_policy': 0}, \"\n",
      " \"'num_agent_episodes_added': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'num_agent_steps_evicted': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_per_sample': {'default_agent': 140}, \"\n",
      " \"'num_module_resamples': {'default_policy': 0}, 'num_episodes_added': 0, \"\n",
      " \"'num_episodes_added_lifetime': 70, 'actual_n_step': 1.0, \"\n",
      " \"'agent_step_utilization': {'default_agent': 0.08889095841485174}, \"\n",
      " \"'num_module_episodes_per_sample': {'default_policy': 140}}, 'learners': \"\n",
      " \"{'__all_modules__': {'num_env_steps_trained_lifetime': 2588672, \"\n",
      " \"'num_trainable_parameters': 287518.0, 'num_module_steps_trained': 65536, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'timers': {'connectors': \"\n",
      " \"{'AddColumnsFromEpisodesToTrainBatch': 0.14656452428716982, \"\n",
      " \"'AddStatesFromEpisodesToBatch': 4.665339073265872e-06, \"\n",
      " \"'AddNextObservationsFromEpisodesToTrainBatch': 0.16197025863240871, \"\n",
      " \"'NumpyToTensor': 0.005268920962959611, 'BatchIndividualItems': \"\n",
      " \"0.457122909243, 'AddTimeDimToBatchAndZeroPad': 1.2947384387402735e-05, \"\n",
      " \"'AddObservationsFromEpisodesToBatch': 0.04675961265651381}}, \"\n",
      " \"'num_env_steps_trained': 65536, 'learner_connector_sum_episodes_length_out': \"\n",
      " \"32768.0, 'num_module_steps_trained_lifetime': 2588672, \"\n",
      " \"'learner_connector_sum_episodes_length_in': 32768.0, \"\n",
      " \"'num_env_steps_trained_lifetime_throughput': 2686.5298657457915}, \"\n",
      " \"'default_policy': {'gradients_alpha_global_norm': 23.194461822509766, \"\n",
      " \"'qf_max': 22.055870056152344, 'total_loss': -27.064247131347656, \"\n",
      " \"'qf_learning_rate': 0.002, 'qf_twin_loss': 1.185197353363037, 'policy_loss': \"\n",
      " \"-28.8963565826416, 'last_target_update_ts': 6546.0, 'alpha_learning_rate': \"\n",
      " \"0.0003, 'policy_learning_rate': 0.001, 'qf_min': -17.191551208496094, \"\n",
      " \"'gradients_policy_global_norm': 2.762397527694702, 'qf_loss': \"\n",
      " \"1.1878077983856201, 'gradients_qf_twin_global_norm': 1.081749439239502, \"\n",
      " \"'logps': -9.194459915161133, 'alpha_loss': -0.5408953428268433, \"\n",
      " \"'qf_twin_learning_rate': 0.002, 'module_train_batch_size_mean': 32768.0, \"\n",
      " \"'target_entropy': -14.0, 'alpha_value': 0.9769497513771057, \"\n",
      " \"'num_module_steps_trained_lifetime': 2588672, 'qf_mean': 19.913829803466797, \"\n",
      " \"'log_alpha_value': -0.023320060223340988, 'weights_seq_no': 79.0, \"\n",
      " \"'gradients_qf_global_norm': 1.1653155088424683, 'num_trainable_parameters': \"\n",
      " \"287518.0, 'num_module_steps_trained': 65536, 'td_error_mean': \"\n",
      " \"6.383820533752441, 'num_non_trainable_parameters': 0.0, \"\n",
      " \"'num_target_updates': 79}}, 'num_env_steps_sampled_lifetime': 6546, \"\n",
      " \"'fault_tolerance': {'num_healthy_workers': 16, 'num_remote_worker_restarts': \"\n",
      " \"0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.2471271519106, 'done': False, \"\n",
      " \"'training_iteration': 41, 'trial_id': 'default', 'date': \"\n",
      " \"'2025-03-14_20-36-17', 'timestamp': 1741952177, 'time_this_iter_s': \"\n",
      " \"24.38611674308777, 'time_total_s': 879.4209396839142, 'pid': 69331, \"\n",
      " \"'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': \"\n",
      " \"{'exploration_config': {}, 'extra_python_environs_for_driver': {}, \"\n",
      " \"'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', \"\n",
      " \"'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, \"\n",
      " \"'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': \"\n",
      " \"{'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, \"\n",
      " \"'gpu_options': {'allow_growth': True}, 'log_device_placement': False, \"\n",
      " \"'device_count': {'CPU': 1}, 'allow_soft_placement': True}, \"\n",
      " \"'local_tf_session_args': {'intra_op_parallelism_threads': 8, \"\n",
      " \"'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, \"\n",
      " \"'torch_compile_learner_what_to_compile': \"\n",
      " \"<TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, \"\n",
      " \"'torch_compile_learner_dynamo_backend': 'inductor', \"\n",
      " \"'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, \"\n",
      " \"'torch_compile_worker_dynamo_backend': 'onnxrt', \"\n",
      " \"'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, \"\n",
      " \"'torch_skip_nan_gradients': False, 'env': 'joy-v1', 'env_config': {}, \"\n",
      " \"'observation_space': None, 'action_space': None, 'clip_rewards': None, \"\n",
      " \"'normalize_actions': True, 'clip_actions': False, '_is_atari': None, \"\n",
      " \"'disable_env_checking': False, 'render_env': False, 'action_mask_key': \"\n",
      " \"'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, \"\n",
      " \"'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'SYNC', \"\n",
      " \"'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, \"\n",
      " \"'custom_resources_per_env_runner': {}, \"\n",
      " \"'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, \"\n",
      " \"'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, \"\n",
      " \"'_env_to_module_connector': None, \"\n",
      " \"'add_default_connectors_to_env_to_module_pipeline': True, \"\n",
      " \"'_module_to_env_connector': None, \"\n",
      " \"'add_default_connectors_to_module_to_env_pipeline': True, \"\n",
      " \"'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', \"\n",
      " \"'batch_mode': 'truncate_episodes', 'compress_observations': False, \"\n",
      " \"'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, \"\n",
      " \"'enable_tf1_exec_eagerly': False, 'sample_collector': <class \"\n",
      " \"'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, \"\n",
      " \"'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', \"\n",
      " \"'update_worker_filter_stats': True, 'use_worker_filter_stats': True, \"\n",
      " \"'sampler_perf_stats_ema_coef': None, 'num_learners': 1, \"\n",
      " \"'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', \"\n",
      " \"'num_aggregator_actors_per_learner': 0, \"\n",
      " \"'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, \"\n",
      " \"'max_requests_in_flight_per_learner': 3, 'gamma': 0.9, 'lr': None, \"\n",
      " \"'grad_clip': None, 'grad_clip_by': 'global_norm', \"\n",
      " \"'_train_batch_size_per_learner': 32768, 'train_batch_size': 256, \"\n",
      " \"'num_epochs': 1, 'minibatch_size': None, 'shuffle_batch_per_epoch': False, \"\n",
      " \"'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', \"\n",
      " \"'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, \"\n",
      " \"'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, \"\n",
      " \"'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': \"\n",
      " \"None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, \"\n",
      " \"'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': \"\n",
      " \"None, 'conv_transpose_kernel_initializer_config': None, \"\n",
      " \"'conv_transpose_bias_initializer': None, \"\n",
      " \"'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, \"\n",
      " \"'post_fcnet_weights_initializer_config': None, \"\n",
      " \"'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': \"\n",
      " \"None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': \"\n",
      " \"False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, \"\n",
      " \"'lstm_cell_size': 256, 'lstm_use_prev_action': False, \"\n",
      " \"'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, \"\n",
      " \"'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, \"\n",
      " \"'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': \"\n",
      " \"False, 'attention_num_transformer_units': 1, 'attention_dim': 64, \"\n",
      " \"'attention_num_heads': 1, 'attention_head_dim': 32, \"\n",
      " \"'attention_memory_inference': 50, 'attention_memory_training': 50, \"\n",
      " \"'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, \"\n",
      " \"'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, \"\n",
      " \"'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, \"\n",
      " \"'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, \"\n",
      " \"'custom_preprocessor': None, 'encoder_latent_dim': None, \"\n",
      " \"'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, \"\n",
      " \"'_use_default_native_models': -1, '_disable_preprocessor_api': False, \"\n",
      " \"'_disable_action_flattening': False}, '_learner_connector': None, \"\n",
      " \"'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': \"\n",
      " \"{}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': \"\n",
      " \"None, 'callbacks_on_env_runners_recreated': None, \"\n",
      " \"'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': \"\n",
      " \"None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': \"\n",
      " \"None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, \"\n",
      " \"'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, \"\n",
      " \"'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, \"\n",
      " \"'explore': True, 'enable_rl_module_and_learner': True, \"\n",
      " \"'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': \"\n",
      " \"{'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', \"\n",
      " \"'policy_map_capacity': 100, 'policy_mapping_fn': <function \"\n",
      " 'AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1839c4a980>, '\n",
      " \"'policies_to_train': None, 'policy_states_are_swappable': False, \"\n",
      " \"'observation_fn': None, 'offline_data_class': None, 'input_read_method': \"\n",
      " \"'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, \"\n",
      " \"'input_read_episodes': False, 'input_read_sample_batches': False, \"\n",
      " \"'input_read_batch_size': None, 'input_filesystem': None, \"\n",
      " \"'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'input_spaces_jsonable': True, 'materialize_data': False, \"\n",
      " \"'materialize_mapped_data': True, 'map_batches_kwargs': {}, \"\n",
      " \"'iter_batches_kwargs': {}, 'prelearner_class': None, \"\n",
      " \"'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, \"\n",
      " \"'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, \"\n",
      " \"'input_config': {}, 'actions_in_input_normalized': False, \"\n",
      " \"'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, \"\n",
      " \"'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'output_max_file_size': 67108864, 'output_max_rows_per_file': None, \"\n",
      " \"'output_write_remaining_data': False, 'output_write_method': \"\n",
      " \"'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': \"\n",
      " \"None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, \"\n",
      " \"'offline_sampling': False, 'evaluation_interval': None, \"\n",
      " \"'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', \"\n",
      " \"'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': \"\n",
      " \"False, 'evaluation_force_reset_envs_before_iteration': True, \"\n",
      " \"'evaluation_config': None, 'off_policy_estimation_methods': {}, \"\n",
      " \"'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, \"\n",
      " \"'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, \"\n",
      " \"'keep_per_episode_custom_metrics': False, \"\n",
      " \"'metrics_episode_collection_timeout_s': 60.0, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, \"\n",
      " \"'min_train_timesteps_per_iteration': 0, \"\n",
      " \"'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, \"\n",
      " \"'export_native_model_files': False, 'checkpoint_trainable_policies_only': \"\n",
      " \"False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', \"\n",
      " \"'log_sys_usage': True, 'fake_sampler': False, 'seed': None, \"\n",
      " \"'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, \"\n",
      " \"'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': \"\n",
      " \"60.0, 'restart_failed_sub_environments': False, \"\n",
      " \"'num_consecutive_env_runner_failures_tolerance': 100, \"\n",
      " \"'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': \"\n",
      " \"1800.0, '_model_config': {}, '_rl_module_spec': None, \"\n",
      " \"'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, \"\n",
      " \"'_validate_config': True, '_use_msgpack_checkpoints': False, \"\n",
      " \"'_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, \"\n",
      " \"'_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': \"\n",
      " \"False, '_disable_action_flattening': False, \"\n",
      " \"'_disable_initialize_loss_from_dummy_batch': False, \"\n",
      " \"'_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, \"\n",
      " \"'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, \"\n",
      " \"'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, \"\n",
      " \"'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, \"\n",
      " \"'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, \"\n",
      " \"'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': \"\n",
      " \"True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': \"\n",
      " \"1, 'replay_buffer_config': {'type': 'PrioritizedEpisodeReplayBuffer', \"\n",
      " \"'capacity': 40000000, 'alpha': 0.6, 'beta': 0.4, \"\n",
      " \"'_enable_replay_buffer_api': True, 'replay_batch_size': 1024, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100}, 'store_buffer_in_checkpoints': \"\n",
      " \"False, 'training_intensity': None, 'optimization': {'actor_learning_rate': \"\n",
      " \"0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, \"\n",
      " \"'actor_lr': 0.001, 'critic_lr': 0.002, 'alpha_lr': 0.0003, \"\n",
      " \"'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': \"\n",
      " \"1500, '_deterministic_loss': False, '_use_beta_distribution': False, \"\n",
      " \"'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': \"\n",
      " \"<class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', \"\n",
      " \"'policies': {'default_policy': (None, None, None, None)}, 'callbacks': \"\n",
      " \"<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, \"\n",
      " \"'create_env_on_driver': False, 'custom_eval_function': None, 'framework': \"\n",
      " \"'torch'}, 'time_since_restore': 879.4209396839142, \"\n",
      " \"'iterations_since_restore': 41, 'perf': {'cpu_util_percent': \"\n",
      " \"np.float64(5.13125), 'ram_util_percent': np.float64(69.55), \"\n",
      " \"'gpu_util_percent0': np.float64(0.000625), 'vram_util_percent0': \"\n",
      " 'np.float64(0.07818094889322917)}})')\n",
      "041, 042, 043, 044, 045, 046, 047, 048, 049, 050, 051, 052, 053, 054, 055, 056, 057, 058, 059, 060, 061, 062, 063, 064, 065, 066, 067, 068, 069, 070, 071, 072, 073, 074, 075, 076, 077, 078, 079, 080, ('Checkpoint saved in directory '\n",
      " 'TrainingResult(checkpoint=Checkpoint(filesystem=local, '\n",
      " 'path=~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314_2), '\n",
      " \"metrics={'timers': {'training_iteration': 13.112996381465262, \"\n",
      " \"'restore_env_runners': 1.0202243137962675e-05, 'training_step': \"\n",
      " \"8.955918215010751, 'env_runner_sampling_timer': 0.03924984111602198, \"\n",
      " \"'replay_buffer_add_data_timer': 0.018536488145063024, \"\n",
      " \"'synch_env_connectors': 0.01803136171559801, 'replay_buffer_sampling_timer': \"\n",
      " \"5.302411876622225, 'learner_update_timer': 5.80141251845726, \"\n",
      " \"'replay_buffer_update_prios_timer': 0.23365842013901852, 'synch_weights': \"\n",
      " \"0.01790884137222642}, 'env_runners': {'num_env_steps_sampled_lifetime': \"\n",
      " \"11681, 'timers': {'connectors': {'NumpyToTensor': \"\n",
      " \"np.float64(8.127492663248252e-05), 'BatchIndividualItems': \"\n",
      " \"np.float64(3.7746282049915e-05), 'AddTimeDimToBatchAndZeroPad': \"\n",
      " \"np.float64(6.710422657533007e-06), 'AddObservationsFromEpisodesToBatch': \"\n",
      " \"np.float64(1.9858475499266303e-05), 'GetActions': \"\n",
      " \"np.float64(0.0009274278101300963), 'UnBatchToIndividualItems': \"\n",
      " \"np.float64(3.367868736640294e-05), 'ListifyDataForVectorEnv': \"\n",
      " \"np.float64(5.131287754881426e-05), 'NormalizeAndClipActions': \"\n",
      " \"np.float64(0.00018669742929507151), 'AddStatesFromEpisodesToBatch': \"\n",
      " \"np.float64(2.4922268422084707e-06), 'RemoveSingleTsTimeRankFromBatch': \"\n",
      " \"np.float64(2.771754583669919e-06), 'TensorToNumpy': \"\n",
      " \"np.float64(0.0001258558012865076)}}, 'num_episodes_lifetime': 11, \"\n",
      " \"'num_agent_steps_sampled': {'default_agent': 128}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 128}, 'sample': \"\n",
      " \"np.float64(0.014592066067557733), 'env_to_module_sum_episodes_length_out': \"\n",
      " \"np.float64(3.330131887256197), 'num_env_steps_sampled': 128, \"\n",
      " \"'weights_seq_no': 158.0, 'num_module_steps_sampled_lifetime': \"\n",
      " \"{'default_policy': 11681}, 'num_episodes': 0, \"\n",
      " \"'num_agent_steps_sampled_lifetime': {'default_agent': 11681}, \"\n",
      " \"'env_to_module_sum_episodes_length_in': np.float64(3.330131887256197), \"\n",
      " \"'time_between_sampling': np.float64(8.787502423412057), \"\n",
      " \"'episode_return_min': 244.17180697964687, 'agent_episode_returns_mean': \"\n",
      " \"{'default_agent': 1128.679738933606}, 'module_episode_returns_mean': \"\n",
      " \"{'default_policy': 1128.679738933606}, 'episode_len_min': 76, \"\n",
      " \"'episode_len_max': 177, 'episode_return_max': 2124.0423371175552, \"\n",
      " \"'episode_return_mean': 1128.679738933606, 'episode_duration_sec_mean': \"\n",
      " \"0.021475134222075417, 'episode_len_mean': 115.66666666666666, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.812489122610449}, \"\n",
      " \"'num_training_step_calls_per_iteration': 2, 'replay_buffer': \"\n",
      " \"{'num_agent_steps_added': {'default_agent': 128}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 5210112, 'num_module_steps_added': \"\n",
      " \"{'default_policy': 0}, 'num_module_steps_per_sample': {'default_policy': \"\n",
      " \"20032}, 'num_agent_steps_sampled': {'default_agent': 65536}, \"\n",
      " \"'num_agent_steps_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'module_actual_n_step': {'default_policy': 1.0}, \"\n",
      " \"'num_agent_episodes_added_lifetime': {'default_agent': 75}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 65536}, 'num_agent_episodes': \"\n",
      " \"{'default_agent': 71.22}, 'num_agent_resamples': {'default_agent': 0}, \"\n",
      " \"'num_episodes_stored': 71.22, 'num_module_steps_evicted_lifetime': \"\n",
      " \"{'default_policy': 0}, 'num_env_steps_per_sample': 20032, \"\n",
      " \"'num_env_steps_added': 128, 'num_module_episodes_added_lifetime': \"\n",
      " \"{'default_policy': 11681}, 'num_agent_steps_stored': {'default_agent': \"\n",
      " \"8501.66}, 'num_agent_steps_per_sample_lifetime': {'default_agent': 967840}, \"\n",
      " \"'num_env_steps_added_lifetime': 11681, 'num_resamples': 0, \"\n",
      " \"'num_env_steps_evicted_lifetime': 0, 'num_episodes_evicted_lifetime': 0, \"\n",
      " \"'num_module_steps_added_lifetime': {'default_policy': 75}, \"\n",
      " \"'num_module_steps_stored': {'default_policy': 71.22}, \"\n",
      " \"'num_agent_steps_added_lifetime': {'default_agent': 11681}, \"\n",
      " \"'num_episodes_per_sample': 150, 'num_agent_steps_per_sample': \"\n",
      " \"{'default_agent': 20032}, 'env_step_utilization': 0.14512193903569445, \"\n",
      " \"'num_env_steps_per_sample_lifetime': 967840, 'num_env_steps_sampled': 65536, \"\n",
      " \"'num_module_episodes_evicted': {'default_policy': 0}, \"\n",
      " \"'num_module_episodes_evicted_lifetime': {'default_policy': 0}, \"\n",
      " \"'module_step_utilization': {'default_policy': 0.14512193903569445}, \"\n",
      " \"'num_module_episodes': {'default_policy': 8501.66}, \"\n",
      " \"'num_module_steps_per_sample_lifetime': {'default_policy': 967840}, \"\n",
      " \"'num_module_episodes_added': {'default_policy': 128}, \"\n",
      " \"'num_module_steps_sampled_lifetime': {'default_policy': 5210112}, \"\n",
      " \"'num_env_steps_stored': 8501.66, 'agent_actual_n_step': {'default_agent': \"\n",
      " \"1.0}, 'num_agent_steps_sampled_lifetime': {'default_agent': 5210112}, \"\n",
      " \"'num_env_steps_evicted': 0, 'num_episodes_evicted': 0, \"\n",
      " \"'num_agent_episodes_evicted': {'default_agent': 0}, \"\n",
      " \"'num_module_steps_evicted': {'default_policy': 0}, \"\n",
      " \"'num_agent_episodes_added': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'num_agent_steps_evicted': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_per_sample': {'default_agent': 150}, \"\n",
      " \"'num_module_resamples': {'default_policy': 0}, 'num_episodes_added': 0, \"\n",
      " \"'num_episodes_added_lifetime': 75, 'actual_n_step': 1.0, \"\n",
      " \"'agent_step_utilization': {'default_agent': 0.14512193903569445}, \"\n",
      " \"'num_module_episodes_per_sample': {'default_policy': 150}}, 'learners': \"\n",
      " \"{'__all_modules__': {'num_env_steps_trained_lifetime': 5210112, \"\n",
      " \"'num_trainable_parameters': 287518.0, 'num_module_steps_trained': 65536, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'timers': {'connectors': \"\n",
      " \"{'AddColumnsFromEpisodesToTrainBatch': 0.14800559190199658, \"\n",
      " \"'AddStatesFromEpisodesToBatch': 3.925319188579608e-06, \"\n",
      " \"'AddNextObservationsFromEpisodesToTrainBatch': 0.09408068858291387, \"\n",
      " \"'NumpyToTensor': 0.0051827108712434395, 'BatchIndividualItems': \"\n",
      " \"0.4594762220711208, 'AddTimeDimToBatchAndZeroPad': 1.1930890109782569e-05, \"\n",
      " \"'AddObservationsFromEpisodesToBatch': 0.047423962031755376}}, \"\n",
      " \"'num_env_steps_trained': 65536, 'learner_connector_sum_episodes_length_out': \"\n",
      " \"32768.0, 'num_module_steps_trained_lifetime': 5210112, \"\n",
      " \"'learner_connector_sum_episodes_length_in': 32768.0, \"\n",
      " \"'num_env_steps_trained_lifetime_throughput': 2975.995349324281}, \"\n",
      " \"'default_policy': {'gradients_alpha_global_norm': 23.330543518066406, \"\n",
      " \"'qf_max': 29.698705673217773, 'total_loss': -32.08253860473633, \"\n",
      " \"'qf_learning_rate': 0.002, 'qf_twin_loss': 0.9866525530815125, \"\n",
      " \"'policy_loss': -32.98914337158203, 'last_target_update_ts': 11681.0, \"\n",
      " \"'alpha_learning_rate': 0.0003, 'policy_learning_rate': 0.001, 'qf_min': \"\n",
      " \"-24.094205856323242, 'gradients_policy_global_norm': 1.8423875570297241, \"\n",
      " \"'qf_loss': 1.0288490056991577, 'gradients_qf_twin_global_norm': \"\n",
      " \"2.6969070434570312, 'logps': -9.330541610717773, 'alpha_loss': \"\n",
      " \"-1.1088957786560059, 'qf_twin_learning_rate': 0.002, \"\n",
      " \"'module_train_batch_size_mean': 32768.0, 'target_entropy': -14.0, \"\n",
      " \"'alpha_value': 0.9535821080207825, 'num_module_steps_trained_lifetime': \"\n",
      " \"5210112, 'qf_mean': 24.091703414916992, 'log_alpha_value': \"\n",
      " \"-0.04752974584698677, 'weights_seq_no': 159.0, 'gradients_qf_global_norm': \"\n",
      " \"3.8786165714263916, 'num_trainable_parameters': 287518.0, \"\n",
      " \"'num_module_steps_trained': 65536, 'td_error_mean': 7.400050640106201, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'num_target_updates': 159}}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 11681, 'fault_tolerance': \"\n",
      " \"{'num_healthy_workers': 16, 'num_remote_worker_restarts': 0}, \"\n",
      " \"'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.812489122610449, 'done': \"\n",
      " \"False, 'training_iteration': 81, 'trial_id': 'default', 'date': \"\n",
      " \"'2025-03-14_20-51-19', 'timestamp': 1741953079, 'time_this_iter_s': \"\n",
      " \"22.015260934829712, 'time_total_s': 1780.7036356925964, 'pid': 69331, \"\n",
      " \"'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': \"\n",
      " \"{'exploration_config': {}, 'extra_python_environs_for_driver': {}, \"\n",
      " \"'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', \"\n",
      " \"'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, \"\n",
      " \"'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': \"\n",
      " \"{'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, \"\n",
      " \"'gpu_options': {'allow_growth': True}, 'log_device_placement': False, \"\n",
      " \"'device_count': {'CPU': 1}, 'allow_soft_placement': True}, \"\n",
      " \"'local_tf_session_args': {'intra_op_parallelism_threads': 8, \"\n",
      " \"'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, \"\n",
      " \"'torch_compile_learner_what_to_compile': \"\n",
      " \"<TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, \"\n",
      " \"'torch_compile_learner_dynamo_backend': 'inductor', \"\n",
      " \"'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, \"\n",
      " \"'torch_compile_worker_dynamo_backend': 'onnxrt', \"\n",
      " \"'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, \"\n",
      " \"'torch_skip_nan_gradients': False, 'env': 'joy-v1', 'env_config': {}, \"\n",
      " \"'observation_space': None, 'action_space': None, 'clip_rewards': None, \"\n",
      " \"'normalize_actions': True, 'clip_actions': False, '_is_atari': None, \"\n",
      " \"'disable_env_checking': False, 'render_env': False, 'action_mask_key': \"\n",
      " \"'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, \"\n",
      " \"'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'SYNC', \"\n",
      " \"'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, \"\n",
      " \"'custom_resources_per_env_runner': {}, \"\n",
      " \"'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, \"\n",
      " \"'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, \"\n",
      " \"'_env_to_module_connector': None, \"\n",
      " \"'add_default_connectors_to_env_to_module_pipeline': True, \"\n",
      " \"'_module_to_env_connector': None, \"\n",
      " \"'add_default_connectors_to_module_to_env_pipeline': True, \"\n",
      " \"'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', \"\n",
      " \"'batch_mode': 'truncate_episodes', 'compress_observations': False, \"\n",
      " \"'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, \"\n",
      " \"'enable_tf1_exec_eagerly': False, 'sample_collector': <class \"\n",
      " \"'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, \"\n",
      " \"'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', \"\n",
      " \"'update_worker_filter_stats': True, 'use_worker_filter_stats': True, \"\n",
      " \"'sampler_perf_stats_ema_coef': None, 'num_learners': 1, \"\n",
      " \"'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', \"\n",
      " \"'num_aggregator_actors_per_learner': 0, \"\n",
      " \"'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, \"\n",
      " \"'max_requests_in_flight_per_learner': 3, 'gamma': 0.9, 'lr': None, \"\n",
      " \"'grad_clip': None, 'grad_clip_by': 'global_norm', \"\n",
      " \"'_train_batch_size_per_learner': 32768, 'train_batch_size': 256, \"\n",
      " \"'num_epochs': 1, 'minibatch_size': None, 'shuffle_batch_per_epoch': False, \"\n",
      " \"'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', \"\n",
      " \"'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, \"\n",
      " \"'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, \"\n",
      " \"'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': \"\n",
      " \"None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, \"\n",
      " \"'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': \"\n",
      " \"None, 'conv_transpose_kernel_initializer_config': None, \"\n",
      " \"'conv_transpose_bias_initializer': None, \"\n",
      " \"'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, \"\n",
      " \"'post_fcnet_weights_initializer_config': None, \"\n",
      " \"'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': \"\n",
      " \"None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': \"\n",
      " \"False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, \"\n",
      " \"'lstm_cell_size': 256, 'lstm_use_prev_action': False, \"\n",
      " \"'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, \"\n",
      " \"'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, \"\n",
      " \"'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': \"\n",
      " \"False, 'attention_num_transformer_units': 1, 'attention_dim': 64, \"\n",
      " \"'attention_num_heads': 1, 'attention_head_dim': 32, \"\n",
      " \"'attention_memory_inference': 50, 'attention_memory_training': 50, \"\n",
      " \"'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, \"\n",
      " \"'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, \"\n",
      " \"'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, \"\n",
      " \"'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, \"\n",
      " \"'custom_preprocessor': None, 'encoder_latent_dim': None, \"\n",
      " \"'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, \"\n",
      " \"'_use_default_native_models': -1, '_disable_preprocessor_api': False, \"\n",
      " \"'_disable_action_flattening': False}, '_learner_connector': None, \"\n",
      " \"'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': \"\n",
      " \"{}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': \"\n",
      " \"None, 'callbacks_on_env_runners_recreated': None, \"\n",
      " \"'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': \"\n",
      " \"None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': \"\n",
      " \"None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, \"\n",
      " \"'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, \"\n",
      " \"'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, \"\n",
      " \"'explore': True, 'enable_rl_module_and_learner': True, \"\n",
      " \"'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': \"\n",
      " \"{'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', \"\n",
      " \"'policy_map_capacity': 100, 'policy_mapping_fn': <function \"\n",
      " 'AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1839c4a980>, '\n",
      " \"'policies_to_train': None, 'policy_states_are_swappable': False, \"\n",
      " \"'observation_fn': None, 'offline_data_class': None, 'input_read_method': \"\n",
      " \"'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, \"\n",
      " \"'input_read_episodes': False, 'input_read_sample_batches': False, \"\n",
      " \"'input_read_batch_size': None, 'input_filesystem': None, \"\n",
      " \"'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'input_spaces_jsonable': True, 'materialize_data': False, \"\n",
      " \"'materialize_mapped_data': True, 'map_batches_kwargs': {}, \"\n",
      " \"'iter_batches_kwargs': {}, 'prelearner_class': None, \"\n",
      " \"'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, \"\n",
      " \"'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, \"\n",
      " \"'input_config': {}, 'actions_in_input_normalized': False, \"\n",
      " \"'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, \"\n",
      " \"'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'output_max_file_size': 67108864, 'output_max_rows_per_file': None, \"\n",
      " \"'output_write_remaining_data': False, 'output_write_method': \"\n",
      " \"'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': \"\n",
      " \"None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, \"\n",
      " \"'offline_sampling': False, 'evaluation_interval': None, \"\n",
      " \"'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', \"\n",
      " \"'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': \"\n",
      " \"False, 'evaluation_force_reset_envs_before_iteration': True, \"\n",
      " \"'evaluation_config': None, 'off_policy_estimation_methods': {}, \"\n",
      " \"'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, \"\n",
      " \"'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, \"\n",
      " \"'keep_per_episode_custom_metrics': False, \"\n",
      " \"'metrics_episode_collection_timeout_s': 60.0, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, \"\n",
      " \"'min_train_timesteps_per_iteration': 0, \"\n",
      " \"'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, \"\n",
      " \"'export_native_model_files': False, 'checkpoint_trainable_policies_only': \"\n",
      " \"False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', \"\n",
      " \"'log_sys_usage': True, 'fake_sampler': False, 'seed': None, \"\n",
      " \"'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, \"\n",
      " \"'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': \"\n",
      " \"60.0, 'restart_failed_sub_environments': False, \"\n",
      " \"'num_consecutive_env_runner_failures_tolerance': 100, \"\n",
      " \"'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': \"\n",
      " \"1800.0, '_model_config': {}, '_rl_module_spec': None, \"\n",
      " \"'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, \"\n",
      " \"'_validate_config': True, '_use_msgpack_checkpoints': False, \"\n",
      " \"'_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, \"\n",
      " \"'_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': \"\n",
      " \"False, '_disable_action_flattening': False, \"\n",
      " \"'_disable_initialize_loss_from_dummy_batch': False, \"\n",
      " \"'_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, \"\n",
      " \"'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, \"\n",
      " \"'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, \"\n",
      " \"'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, \"\n",
      " \"'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, \"\n",
      " \"'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': \"\n",
      " \"True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': \"\n",
      " \"1, 'replay_buffer_config': {'type': 'PrioritizedEpisodeReplayBuffer', \"\n",
      " \"'capacity': 40000000, 'alpha': 0.6, 'beta': 0.4, \"\n",
      " \"'_enable_replay_buffer_api': True, 'replay_batch_size': 1024, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100}, 'store_buffer_in_checkpoints': \"\n",
      " \"False, 'training_intensity': None, 'optimization': {'actor_learning_rate': \"\n",
      " \"0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, \"\n",
      " \"'actor_lr': 0.001, 'critic_lr': 0.002, 'alpha_lr': 0.0003, \"\n",
      " \"'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': \"\n",
      " \"1500, '_deterministic_loss': False, '_use_beta_distribution': False, \"\n",
      " \"'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': \"\n",
      " \"<class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', \"\n",
      " \"'policies': {'default_policy': (None, None, None, None)}, 'callbacks': \"\n",
      " \"<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, \"\n",
      " \"'create_env_on_driver': False, 'custom_eval_function': None, 'framework': \"\n",
      " \"'torch'}, 'time_since_restore': 1780.7036356925964, \"\n",
      " \"'iterations_since_restore': 81, 'perf': {'cpu_util_percent': \"\n",
      " \"np.float64(5.305882352941176), 'ram_util_percent': \"\n",
      " \"np.float64(69.67647058823529), 'gpu_util_percent0': \"\n",
      " \"np.float64(0.0058823529411764705), 'vram_util_percent0': \"\n",
      " 'np.float64(0.07616708792892157)}})')\n",
      "081, 082, 083, 084, 085, 086, 087, 088, 089, 090, 091, 092, 093, 094, 095, 096, 097, 098, 099, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, ('Checkpoint saved in directory '\n",
      " 'TrainingResult(checkpoint=Checkpoint(filesystem=local, '\n",
      " 'path=~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314_3), '\n",
      " \"metrics={'timers': {'training_iteration': 16.335604470131372, \"\n",
      " \"'restore_env_runners': 9.754437576946965e-06, 'training_step': \"\n",
      " \"10.321035821555991, 'env_runner_sampling_timer': 0.037071772408089745, \"\n",
      " \"'replay_buffer_add_data_timer': 0.019654831865877947, \"\n",
      " \"'synch_env_connectors': 0.01774496098354093, 'replay_buffer_sampling_timer': \"\n",
      " \"5.344754995992635, 'learner_update_timer': 5.743916300719018, \"\n",
      " \"'replay_buffer_update_prios_timer': 0.2367859939515475, 'synch_weights': \"\n",
      " \"0.01810243723636606}, 'env_runners': {'num_env_steps_sampled_lifetime': \"\n",
      " \"16831, 'timers': {'connectors': {'NumpyToTensor': \"\n",
      " \"np.float64(7.52552110627941e-05), 'BatchIndividualItems': \"\n",
      " \"np.float64(3.4108751078904494e-05), 'AddTimeDimToBatchAndZeroPad': \"\n",
      " \"np.float64(6.027442182815825e-06), 'AddObservationsFromEpisodesToBatch': \"\n",
      " \"np.float64(1.7698422550916758e-05), 'GetActions': \"\n",
      " \"np.float64(0.0006985974415417513), 'UnBatchToIndividualItems': \"\n",
      " \"np.float64(3.279882976792592e-05), 'ListifyDataForVectorEnv': \"\n",
      " \"np.float64(5.1246724836590126e-05), 'NormalizeAndClipActions': \"\n",
      " \"np.float64(0.00017231613317117309), 'AddStatesFromEpisodesToBatch': \"\n",
      " \"np.float64(2.309883112962206e-06), 'RemoveSingleTsTimeRankFromBatch': \"\n",
      " \"np.float64(2.757714876181453e-06), 'TensorToNumpy': \"\n",
      " \"np.float64(0.00010174647318324854)}}, 'num_episodes_lifetime': 21, \"\n",
      " \"'num_agent_steps_sampled': {'default_agent': 128}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 128}, 'sample': \"\n",
      " \"np.float64(0.013275119703793152), 'env_to_module_sum_episodes_length_out': \"\n",
      " \"np.float64(3.710311311728025), 'num_env_steps_sampled': 128, \"\n",
      " \"'weights_seq_no': 238.0, 'num_module_steps_sampled_lifetime': \"\n",
      " \"{'default_policy': 16831}, 'num_episodes': 0, \"\n",
      " \"'num_agent_steps_sampled_lifetime': {'default_agent': 16831}, \"\n",
      " \"'env_to_module_sum_episodes_length_in': np.float64(3.710311311728025), \"\n",
      " \"'time_between_sampling': np.float64(10.249268925271496), \"\n",
      " \"'episode_return_min': 244.17180697964687, 'agent_episode_returns_mean': \"\n",
      " \"{'default_agent': 1267.089299399793}, 'module_episode_returns_mean': \"\n",
      " \"{'default_policy': 1267.089299399793}, 'episode_len_min': 55, \"\n",
      " \"'episode_len_max': 250, 'episode_return_max': 2526.584873742722, \"\n",
      " \"'episode_return_mean': 1267.089299399793, 'episode_duration_sec_mean': \"\n",
      " \"0.021921176499972717, 'episode_len_mean': 159.33333333333334, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.802311664203331}, \"\n",
      " \"'num_training_step_calls_per_iteration': 2, 'replay_buffer': \"\n",
      " \"{'num_agent_steps_added': {'default_agent': 128}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 7831552, 'num_module_steps_added': \"\n",
      " \"{'default_policy': 0}, 'num_module_steps_per_sample': {'default_policy': \"\n",
      " \"25838}, 'num_agent_steps_sampled': {'default_agent': 65536}, \"\n",
      " \"'num_agent_steps_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'module_actual_n_step': {'default_policy': 1.0}, \"\n",
      " \"'num_agent_episodes_added_lifetime': {'default_agent': 85}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 65536}, 'num_agent_episodes': \"\n",
      " \"{'default_agent': 79.09}, 'num_agent_resamples': {'default_agent': 0}, \"\n",
      " \"'num_episodes_stored': 79.09, 'num_module_steps_evicted_lifetime': \"\n",
      " \"{'default_policy': 0}, 'num_env_steps_per_sample': 25838, \"\n",
      " \"'num_env_steps_added': 128, 'num_module_episodes_added_lifetime': \"\n",
      " \"{'default_policy': 16831}, 'num_agent_steps_stored': {'default_agent': \"\n",
      " \"13645.27}, 'num_agent_steps_per_sample_lifetime': {'default_agent': \"\n",
      " \"1895817}, 'num_env_steps_added_lifetime': 16831, 'num_resamples': 0, \"\n",
      " \"'num_env_steps_evicted_lifetime': 0, 'num_episodes_evicted_lifetime': 0, \"\n",
      " \"'num_module_steps_added_lifetime': {'default_policy': 85}, \"\n",
      " \"'num_module_steps_stored': {'default_policy': 79.09}, \"\n",
      " \"'num_agent_steps_added_lifetime': {'default_agent': 16831}, \"\n",
      " \"'num_episodes_per_sample': 170, 'num_agent_steps_per_sample': \"\n",
      " \"{'default_agent': 25838}, 'env_step_utilization': 0.20772673153299198, \"\n",
      " \"'num_env_steps_per_sample_lifetime': 1895817, 'num_env_steps_sampled': \"\n",
      " \"65536, 'num_module_episodes_evicted': {'default_policy': 0}, \"\n",
      " \"'num_module_episodes_evicted_lifetime': {'default_policy': 0}, \"\n",
      " \"'module_step_utilization': {'default_policy': 0.20772673153299198}, \"\n",
      " \"'num_module_episodes': {'default_policy': 13645.27}, \"\n",
      " \"'num_module_steps_per_sample_lifetime': {'default_policy': 1895817}, \"\n",
      " \"'num_module_episodes_added': {'default_policy': 128}, \"\n",
      " \"'num_module_steps_sampled_lifetime': {'default_policy': 7831552}, \"\n",
      " \"'num_env_steps_stored': 13645.27, 'agent_actual_n_step': {'default_agent': \"\n",
      " \"1.0}, 'num_agent_steps_sampled_lifetime': {'default_agent': 7831552}, \"\n",
      " \"'num_env_steps_evicted': 0, 'num_episodes_evicted': 0, \"\n",
      " \"'num_agent_episodes_evicted': {'default_agent': 0}, \"\n",
      " \"'num_module_steps_evicted': {'default_policy': 0}, \"\n",
      " \"'num_agent_episodes_added': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'num_agent_steps_evicted': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_per_sample': {'default_agent': 170}, \"\n",
      " \"'num_module_resamples': {'default_policy': 0}, 'num_episodes_added': 0, \"\n",
      " \"'num_episodes_added_lifetime': 85, 'actual_n_step': 1.0, \"\n",
      " \"'agent_step_utilization': {'default_agent': 0.20772673153299198}, \"\n",
      " \"'num_module_episodes_per_sample': {'default_policy': 170}}, 'learners': \"\n",
      " \"{'__all_modules__': {'num_env_steps_trained_lifetime': 7831552, \"\n",
      " \"'num_trainable_parameters': 287518.0, 'num_module_steps_trained': 65536, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'timers': {'connectors': \"\n",
      " \"{'AddColumnsFromEpisodesToTrainBatch': 0.14944441367957462, \"\n",
      " \"'AddStatesFromEpisodesToBatch': 3.3704835869470304e-06, \"\n",
      " \"'AddNextObservationsFromEpisodesToTrainBatch': 0.055540500020150166, \"\n",
      " \"'NumpyToTensor': 0.005113943513767718, 'BatchIndividualItems': \"\n",
      " \"0.4625273645900838, 'AddTimeDimToBatchAndZeroPad': 1.1216803549968151e-05, \"\n",
      " \"'AddObservationsFromEpisodesToBatch': 0.048002553495573294}}, \"\n",
      " \"'num_env_steps_trained': 65536, 'learner_connector_sum_episodes_length_out': \"\n",
      " \"32768.0, 'num_module_steps_trained_lifetime': 7831552, \"\n",
      " \"'learner_connector_sum_episodes_length_in': 32768.0, \"\n",
      " \"'num_env_steps_trained_lifetime_throughput': 2970.783640752552}, \"\n",
      " \"'default_policy': {'gradients_alpha_global_norm': 23.282434463500977, \"\n",
      " \"'qf_max': 37.47346878051758, 'total_loss': -39.378509521484375, \"\n",
      " \"'qf_learning_rate': 0.002, 'qf_twin_loss': 0.8365726470947266, \"\n",
      " \"'policy_loss': -39.386783599853516, 'last_target_update_ts': 16831.0, \"\n",
      " \"'alpha_learning_rate': 0.0003, 'policy_learning_rate': 0.001, 'qf_min': \"\n",
      " \"-25.459300994873047, 'gradients_policy_global_norm': 1.583326816558838, \"\n",
      " \"'qf_loss': 0.8390367031097412, 'gradients_qf_twin_global_norm': \"\n",
      " \"1.9067118167877197, 'logps': -9.282435417175293, 'alpha_loss': \"\n",
      " \"-1.6673312187194824, 'qf_twin_learning_rate': 0.002, \"\n",
      " \"'module_train_batch_size_mean': 32768.0, 'target_entropy': -14.0, \"\n",
      " \"'alpha_value': 0.9308907985687256, 'num_module_steps_trained_lifetime': \"\n",
      " \"7831552, 'qf_mean': 30.745849609375, 'log_alpha_value': \"\n",
      " \"-0.07161330431699753, 'weights_seq_no': 239.0, 'gradients_qf_global_norm': \"\n",
      " \"2.0013880729675293, 'num_trainable_parameters': 287518.0, \"\n",
      " \"'num_module_steps_trained': 65536, 'td_error_mean': 7.384207725524902, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'num_target_updates': 239}}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 16831, 'fault_tolerance': \"\n",
      " \"{'num_healthy_workers': 16, 'num_remote_worker_restarts': 0}, \"\n",
      " \"'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.802311664203331, 'done': \"\n",
      " \"False, 'training_iteration': 121, 'trial_id': 'default', 'date': \"\n",
      " \"'2025-03-14_21-06-34', 'timestamp': 1741953994, 'time_this_iter_s': \"\n",
      " \"22.053736925125122, 'time_total_s': 2695.2334446907043, 'pid': 69331, \"\n",
      " \"'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': \"\n",
      " \"{'exploration_config': {}, 'extra_python_environs_for_driver': {}, \"\n",
      " \"'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', \"\n",
      " \"'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, \"\n",
      " \"'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': \"\n",
      " \"{'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, \"\n",
      " \"'gpu_options': {'allow_growth': True}, 'log_device_placement': False, \"\n",
      " \"'device_count': {'CPU': 1}, 'allow_soft_placement': True}, \"\n",
      " \"'local_tf_session_args': {'intra_op_parallelism_threads': 8, \"\n",
      " \"'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, \"\n",
      " \"'torch_compile_learner_what_to_compile': \"\n",
      " \"<TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, \"\n",
      " \"'torch_compile_learner_dynamo_backend': 'inductor', \"\n",
      " \"'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, \"\n",
      " \"'torch_compile_worker_dynamo_backend': 'onnxrt', \"\n",
      " \"'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, \"\n",
      " \"'torch_skip_nan_gradients': False, 'env': 'joy-v1', 'env_config': {}, \"\n",
      " \"'observation_space': None, 'action_space': None, 'clip_rewards': None, \"\n",
      " \"'normalize_actions': True, 'clip_actions': False, '_is_atari': None, \"\n",
      " \"'disable_env_checking': False, 'render_env': False, 'action_mask_key': \"\n",
      " \"'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, \"\n",
      " \"'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'SYNC', \"\n",
      " \"'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, \"\n",
      " \"'custom_resources_per_env_runner': {}, \"\n",
      " \"'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, \"\n",
      " \"'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, \"\n",
      " \"'_env_to_module_connector': None, \"\n",
      " \"'add_default_connectors_to_env_to_module_pipeline': True, \"\n",
      " \"'_module_to_env_connector': None, \"\n",
      " \"'add_default_connectors_to_module_to_env_pipeline': True, \"\n",
      " \"'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', \"\n",
      " \"'batch_mode': 'truncate_episodes', 'compress_observations': False, \"\n",
      " \"'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, \"\n",
      " \"'enable_tf1_exec_eagerly': False, 'sample_collector': <class \"\n",
      " \"'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, \"\n",
      " \"'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', \"\n",
      " \"'update_worker_filter_stats': True, 'use_worker_filter_stats': True, \"\n",
      " \"'sampler_perf_stats_ema_coef': None, 'num_learners': 1, \"\n",
      " \"'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', \"\n",
      " \"'num_aggregator_actors_per_learner': 0, \"\n",
      " \"'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, \"\n",
      " \"'max_requests_in_flight_per_learner': 3, 'gamma': 0.9, 'lr': None, \"\n",
      " \"'grad_clip': None, 'grad_clip_by': 'global_norm', \"\n",
      " \"'_train_batch_size_per_learner': 32768, 'train_batch_size': 256, \"\n",
      " \"'num_epochs': 1, 'minibatch_size': None, 'shuffle_batch_per_epoch': False, \"\n",
      " \"'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', \"\n",
      " \"'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, \"\n",
      " \"'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, \"\n",
      " \"'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': \"\n",
      " \"None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, \"\n",
      " \"'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': \"\n",
      " \"None, 'conv_transpose_kernel_initializer_config': None, \"\n",
      " \"'conv_transpose_bias_initializer': None, \"\n",
      " \"'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, \"\n",
      " \"'post_fcnet_weights_initializer_config': None, \"\n",
      " \"'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': \"\n",
      " \"None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': \"\n",
      " \"False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, \"\n",
      " \"'lstm_cell_size': 256, 'lstm_use_prev_action': False, \"\n",
      " \"'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, \"\n",
      " \"'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, \"\n",
      " \"'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': \"\n",
      " \"False, 'attention_num_transformer_units': 1, 'attention_dim': 64, \"\n",
      " \"'attention_num_heads': 1, 'attention_head_dim': 32, \"\n",
      " \"'attention_memory_inference': 50, 'attention_memory_training': 50, \"\n",
      " \"'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, \"\n",
      " \"'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, \"\n",
      " \"'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, \"\n",
      " \"'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, \"\n",
      " \"'custom_preprocessor': None, 'encoder_latent_dim': None, \"\n",
      " \"'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, \"\n",
      " \"'_use_default_native_models': -1, '_disable_preprocessor_api': False, \"\n",
      " \"'_disable_action_flattening': False}, '_learner_connector': None, \"\n",
      " \"'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': \"\n",
      " \"{}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': \"\n",
      " \"None, 'callbacks_on_env_runners_recreated': None, \"\n",
      " \"'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': \"\n",
      " \"None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': \"\n",
      " \"None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, \"\n",
      " \"'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, \"\n",
      " \"'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, \"\n",
      " \"'explore': True, 'enable_rl_module_and_learner': True, \"\n",
      " \"'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': \"\n",
      " \"{'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', \"\n",
      " \"'policy_map_capacity': 100, 'policy_mapping_fn': <function \"\n",
      " 'AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1839c4a980>, '\n",
      " \"'policies_to_train': None, 'policy_states_are_swappable': False, \"\n",
      " \"'observation_fn': None, 'offline_data_class': None, 'input_read_method': \"\n",
      " \"'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, \"\n",
      " \"'input_read_episodes': False, 'input_read_sample_batches': False, \"\n",
      " \"'input_read_batch_size': None, 'input_filesystem': None, \"\n",
      " \"'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'input_spaces_jsonable': True, 'materialize_data': False, \"\n",
      " \"'materialize_mapped_data': True, 'map_batches_kwargs': {}, \"\n",
      " \"'iter_batches_kwargs': {}, 'prelearner_class': None, \"\n",
      " \"'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, \"\n",
      " \"'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, \"\n",
      " \"'input_config': {}, 'actions_in_input_normalized': False, \"\n",
      " \"'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, \"\n",
      " \"'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'output_max_file_size': 67108864, 'output_max_rows_per_file': None, \"\n",
      " \"'output_write_remaining_data': False, 'output_write_method': \"\n",
      " \"'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': \"\n",
      " \"None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, \"\n",
      " \"'offline_sampling': False, 'evaluation_interval': None, \"\n",
      " \"'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', \"\n",
      " \"'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': \"\n",
      " \"False, 'evaluation_force_reset_envs_before_iteration': True, \"\n",
      " \"'evaluation_config': None, 'off_policy_estimation_methods': {}, \"\n",
      " \"'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, \"\n",
      " \"'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, \"\n",
      " \"'keep_per_episode_custom_metrics': False, \"\n",
      " \"'metrics_episode_collection_timeout_s': 60.0, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, \"\n",
      " \"'min_train_timesteps_per_iteration': 0, \"\n",
      " \"'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, \"\n",
      " \"'export_native_model_files': False, 'checkpoint_trainable_policies_only': \"\n",
      " \"False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', \"\n",
      " \"'log_sys_usage': True, 'fake_sampler': False, 'seed': None, \"\n",
      " \"'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, \"\n",
      " \"'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': \"\n",
      " \"60.0, 'restart_failed_sub_environments': False, \"\n",
      " \"'num_consecutive_env_runner_failures_tolerance': 100, \"\n",
      " \"'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': \"\n",
      " \"1800.0, '_model_config': {}, '_rl_module_spec': None, \"\n",
      " \"'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, \"\n",
      " \"'_validate_config': True, '_use_msgpack_checkpoints': False, \"\n",
      " \"'_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, \"\n",
      " \"'_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': \"\n",
      " \"False, '_disable_action_flattening': False, \"\n",
      " \"'_disable_initialize_loss_from_dummy_batch': False, \"\n",
      " \"'_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, \"\n",
      " \"'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, \"\n",
      " \"'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, \"\n",
      " \"'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, \"\n",
      " \"'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, \"\n",
      " \"'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': \"\n",
      " \"True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': \"\n",
      " \"1, 'replay_buffer_config': {'type': 'PrioritizedEpisodeReplayBuffer', \"\n",
      " \"'capacity': 40000000, 'alpha': 0.6, 'beta': 0.4, \"\n",
      " \"'_enable_replay_buffer_api': True, 'replay_batch_size': 1024, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100}, 'store_buffer_in_checkpoints': \"\n",
      " \"False, 'training_intensity': None, 'optimization': {'actor_learning_rate': \"\n",
      " \"0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, \"\n",
      " \"'actor_lr': 0.001, 'critic_lr': 0.002, 'alpha_lr': 0.0003, \"\n",
      " \"'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': \"\n",
      " \"1500, '_deterministic_loss': False, '_use_beta_distribution': False, \"\n",
      " \"'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': \"\n",
      " \"<class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', \"\n",
      " \"'policies': {'default_policy': (None, None, None, None)}, 'callbacks': \"\n",
      " \"<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, \"\n",
      " \"'create_env_on_driver': False, 'custom_eval_function': None, 'framework': \"\n",
      " \"'torch'}, 'time_since_restore': 2695.2334446907043, \"\n",
      " \"'iterations_since_restore': 121, 'perf': {'cpu_util_percent': \"\n",
      " \"np.float64(5.147058823529412), 'ram_util_percent': \"\n",
      " \"np.float64(69.80588235294118), 'gpu_util_percent0': np.float64(0.0), \"\n",
      " \"'vram_util_percent0': np.float64(0.08456600413602942)}})\")\n",
      "121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, ('Checkpoint saved in directory '\n",
      " 'TrainingResult(checkpoint=Checkpoint(filesystem=local, '\n",
      " 'path=~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314_4), '\n",
      " \"metrics={'timers': {'training_iteration': 18.37344961765413, \"\n",
      " \"'restore_env_runners': 9.564785108941638e-06, 'training_step': \"\n",
      " \"10.829844734887503, 'env_runner_sampling_timer': 0.04239418179380186, \"\n",
      " \"'replay_buffer_add_data_timer': 0.020509522204640827, \"\n",
      " \"'synch_env_connectors': 0.017539045395604434, \"\n",
      " \"'replay_buffer_sampling_timer': 5.203299967831217, 'learner_update_timer': \"\n",
      " \"5.768304759381258, 'replay_buffer_update_prios_timer': 0.23917093871872994, \"\n",
      " \"'synch_weights': 0.018078716254047195}, 'env_runners': \"\n",
      " \"{'num_env_steps_sampled_lifetime': 21975, 'timers': {'connectors': \"\n",
      " \"{'NumpyToTensor': np.float64(7.258334988976508e-05), 'BatchIndividualItems': \"\n",
      " \"np.float64(3.250559238909745e-05), 'AddTimeDimToBatchAndZeroPad': \"\n",
      " \"np.float64(5.754436296080916e-06), 'AddObservationsFromEpisodesToBatch': \"\n",
      " \"np.float64(1.6756283494407806e-05), 'GetActions': \"\n",
      " \"np.float64(0.000596069443756429), 'UnBatchToIndividualItems': \"\n",
      " \"np.float64(3.256743591534857e-05), 'ListifyDataForVectorEnv': \"\n",
      " \"np.float64(5.1188189056055565e-05), 'NormalizeAndClipActions': \"\n",
      " \"np.float64(0.000165752967731666), 'AddStatesFromEpisodesToBatch': \"\n",
      " \"np.float64(2.2363738444340462e-06), 'RemoveSingleTsTimeRankFromBatch': \"\n",
      " \"np.float64(2.760603342133731e-06), 'TensorToNumpy': \"\n",
      " \"np.float64(9.110025743294001e-05)}}, 'num_episodes_lifetime': 30, \"\n",
      " \"'num_agent_steps_sampled': {'default_agent': 131}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 131}, 'sample': \"\n",
      " \"np.float64(0.01271972505337171), 'env_to_module_sum_episodes_length_out': \"\n",
      " \"np.float64(3.8778346081752044), 'num_env_steps_sampled': 131, \"\n",
      " \"'weights_seq_no': 318.0, 'num_module_steps_sampled_lifetime': \"\n",
      " \"{'default_policy': 21975}, 'num_episodes': 2, \"\n",
      " \"'num_agent_steps_sampled_lifetime': {'default_agent': 21975}, \"\n",
      " \"'env_to_module_sum_episodes_length_in': np.float64(3.8778346081752044), \"\n",
      " \"'time_between_sampling': np.float64(10.808617034549663), \"\n",
      " \"'episode_return_min': 147.370981643932, 'agent_episode_returns_mean': \"\n",
      " \"{'default_agent': 1972.6678352162269}, 'module_episode_returns_mean': \"\n",
      " \"{'default_policy': 1972.6678352162269}, 'episode_len_min': 76, \"\n",
      " \"'episode_len_max': 335, 'episode_return_max': 4275.518412600786, \"\n",
      " \"'episode_return_mean': 1972.6678352162269, 'episode_duration_sec_mean': \"\n",
      " \"0.02421266023093967, 'episode_len_mean': 214.61538461538458, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.921919995946749}, \"\n",
      " \"'num_training_step_calls_per_iteration': 2, 'replay_buffer': \"\n",
      " \"{'num_agent_steps_added': {'default_agent': 131}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 10452992, 'num_module_steps_added': \"\n",
      " \"{'default_policy': 1}, 'num_module_steps_per_sample': {'default_policy': \"\n",
      " \"30423}, 'num_agent_steps_sampled': {'default_agent': 65536}, \"\n",
      " \"'num_agent_steps_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'module_actual_n_step': {'default_policy': 1.0}, \"\n",
      " \"'num_agent_episodes_added_lifetime': {'default_agent': 93}, \"\n",
      " \"'num_module_steps_sampled': {'default_policy': 65536}, 'num_agent_episodes': \"\n",
      " \"{'default_agent': 86.67}, 'num_agent_resamples': {'default_agent': 0}, \"\n",
      " \"'num_episodes_stored': 86.67, 'num_module_steps_evicted_lifetime': \"\n",
      " \"{'default_policy': 0}, 'num_env_steps_per_sample': 30423, \"\n",
      " \"'num_env_steps_added': 131, 'num_module_episodes_added_lifetime': \"\n",
      " \"{'default_policy': 21975}, 'num_agent_steps_stored': {'default_agent': \"\n",
      " \"18788.01}, 'num_agent_steps_per_sample_lifetime': {'default_agent': \"\n",
      " \"3031310}, 'num_env_steps_added_lifetime': 21975, 'num_resamples': 0, \"\n",
      " \"'num_env_steps_evicted_lifetime': 0, 'num_episodes_evicted_lifetime': 0, \"\n",
      " \"'num_module_steps_added_lifetime': {'default_policy': 93}, \"\n",
      " \"'num_module_steps_stored': {'default_policy': 86.67}, \"\n",
      " \"'num_agent_steps_added_lifetime': {'default_agent': 21975}, \"\n",
      " \"'num_episodes_per_sample': 185, 'num_agent_steps_per_sample': \"\n",
      " \"{'default_agent': 30423}, 'env_step_utilization': 0.2607713433420712, \"\n",
      " \"'num_env_steps_per_sample_lifetime': 3031310, 'num_env_steps_sampled': \"\n",
      " \"65536, 'num_module_episodes_evicted': {'default_policy': 0}, \"\n",
      " \"'num_module_episodes_evicted_lifetime': {'default_policy': 0}, \"\n",
      " \"'module_step_utilization': {'default_policy': 0.2607713433420712}, \"\n",
      " \"'num_module_episodes': {'default_policy': 18788.01}, \"\n",
      " \"'num_module_steps_per_sample_lifetime': {'default_policy': 3031310}, \"\n",
      " \"'num_module_episodes_added': {'default_policy': 131}, \"\n",
      " \"'num_module_steps_sampled_lifetime': {'default_policy': 10452992}, \"\n",
      " \"'num_env_steps_stored': 18788.01, 'agent_actual_n_step': {'default_agent': \"\n",
      " \"1.0}, 'num_agent_steps_sampled_lifetime': {'default_agent': 10452992}, \"\n",
      " \"'num_env_steps_evicted': 0, 'num_episodes_evicted': 0, \"\n",
      " \"'num_agent_episodes_evicted': {'default_agent': 0}, \"\n",
      " \"'num_module_steps_evicted': {'default_policy': 0}, \"\n",
      " \"'num_agent_episodes_added': {'default_agent': 1}, \"\n",
      " \"'num_agent_episodes_evicted_lifetime': {'default_agent': 0}, \"\n",
      " \"'num_agent_steps_evicted': {'default_agent': 0}, \"\n",
      " \"'num_agent_episodes_per_sample': {'default_agent': 185}, \"\n",
      " \"'num_module_resamples': {'default_policy': 0}, 'num_episodes_added': 1, \"\n",
      " \"'num_episodes_added_lifetime': 93, 'actual_n_step': 1.0, \"\n",
      " \"'agent_step_utilization': {'default_agent': 0.2607713433420712}, \"\n",
      " \"'num_module_episodes_per_sample': {'default_policy': 185}}, 'learners': \"\n",
      " \"{'__all_modules__': {'num_env_steps_trained_lifetime': 10452992, \"\n",
      " \"'num_trainable_parameters': 287518.0, 'num_module_steps_trained': 65536, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'timers': {'connectors': \"\n",
      " \"{'AddColumnsFromEpisodesToTrainBatch': 0.15070709751620157, \"\n",
      " \"'AddStatesFromEpisodesToBatch': 3.0216686771213883e-06, \"\n",
      " \"'AddNextObservationsFromEpisodesToTrainBatch': 0.03675333096098024, \"\n",
      " \"'NumpyToTensor': 0.005072920046970835, 'BatchIndividualItems': \"\n",
      " \"0.4646100920193499, 'AddTimeDimToBatchAndZeroPad': 1.0769112912540008e-05, \"\n",
      " \"'AddObservationsFromEpisodesToBatch': 0.04851456588515533}}, \"\n",
      " \"'num_env_steps_trained': 65536, 'learner_connector_sum_episodes_length_out': \"\n",
      " \"32768.0, 'num_module_steps_trained_lifetime': 10452992, \"\n",
      " \"'learner_connector_sum_episodes_length_in': 32768.0, \"\n",
      " \"'num_env_steps_trained_lifetime_throughput': 2962.5869112933287}, \"\n",
      " \"'default_policy': {'gradients_alpha_global_norm': 23.256147384643555, \"\n",
      " \"'qf_max': 44.39308166503906, 'total_loss': -45.56179428100586, \"\n",
      " \"'qf_learning_rate': 0.002, 'qf_twin_loss': 0.7279784679412842, \"\n",
      " \"'policy_loss': -44.80774688720703, 'last_target_update_ts': 21975.0, \"\n",
      " \"'alpha_learning_rate': 0.0003, 'policy_learning_rate': 0.001, 'qf_min': \"\n",
      " \"-20.51523208618164, 'gradients_policy_global_norm': 1.2497345209121704, \"\n",
      " \"'qf_loss': 0.7421652674674988, 'gradients_qf_twin_global_norm': \"\n",
      " \"2.238593578338623, 'logps': -9.256147384643555, 'alpha_loss': \"\n",
      " \"-2.224191188812256, 'qf_twin_learning_rate': 0.002, \"\n",
      " \"'module_train_batch_size_mean': 32768.0, 'target_entropy': -14.0, \"\n",
      " \"'alpha_value': 0.9087921977043152, 'num_module_steps_trained_lifetime': \"\n",
      " \"10452992, 'qf_mean': 36.395835876464844, 'log_alpha_value': \"\n",
      " \"-0.09563881903886795, 'weights_seq_no': 319.0, 'gradients_qf_global_norm': \"\n",
      " \"2.296354055404663, 'num_trainable_parameters': 287518.0, \"\n",
      " \"'num_module_steps_trained': 65536, 'td_error_mean': 6.310128211975098, \"\n",
      " \"'num_non_trainable_parameters': 0.0, 'num_target_updates': 319}}, \"\n",
      " \"'num_env_steps_sampled_lifetime': 21975, 'fault_tolerance': \"\n",
      " \"{'num_healthy_workers': 16, 'num_remote_worker_restarts': 0}, \"\n",
      " \"'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, \"\n",
      " \"'num_env_steps_sampled_lifetime_throughput': 5.921919995946749, 'done': \"\n",
      " \"False, 'training_iteration': 161, 'trial_id': 'default', 'date': \"\n",
      " \"'2025-03-14_21-21-35', 'timestamp': 1741954895, 'time_this_iter_s': \"\n",
      " \"22.114824056625366, 'time_total_s': 3596.005661010742, 'pid': 69331, \"\n",
      " \"'hostname': 'OMEN-BY-HP-45L', 'node_ip': '10.130.6.78', 'config': \"\n",
      " \"{'exploration_config': {}, 'extra_python_environs_for_driver': {}, \"\n",
      " \"'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', \"\n",
      " \"'num_gpus': 0, '_fake_gpus': False, 'num_cpus_for_main_process': 1, \"\n",
      " \"'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': \"\n",
      " \"{'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, \"\n",
      " \"'gpu_options': {'allow_growth': True}, 'log_device_placement': False, \"\n",
      " \"'device_count': {'CPU': 1}, 'allow_soft_placement': True}, \"\n",
      " \"'local_tf_session_args': {'intra_op_parallelism_threads': 8, \"\n",
      " \"'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, \"\n",
      " \"'torch_compile_learner_what_to_compile': \"\n",
      " \"<TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, \"\n",
      " \"'torch_compile_learner_dynamo_backend': 'inductor', \"\n",
      " \"'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, \"\n",
      " \"'torch_compile_worker_dynamo_backend': 'onnxrt', \"\n",
      " \"'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, \"\n",
      " \"'torch_skip_nan_gradients': False, 'env': 'joy-v1', 'env_config': {}, \"\n",
      " \"'observation_space': None, 'action_space': None, 'clip_rewards': None, \"\n",
      " \"'normalize_actions': True, 'clip_actions': False, '_is_atari': None, \"\n",
      " \"'disable_env_checking': False, 'render_env': False, 'action_mask_key': \"\n",
      " \"'action_mask', 'env_runner_cls': None, 'num_env_runners': 16, \"\n",
      " \"'num_envs_per_env_runner': 4, 'gym_env_vectorize_mode': 'SYNC', \"\n",
      " \"'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, \"\n",
      " \"'custom_resources_per_env_runner': {}, \"\n",
      " \"'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, \"\n",
      " \"'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, \"\n",
      " \"'_env_to_module_connector': None, \"\n",
      " \"'add_default_connectors_to_env_to_module_pipeline': True, \"\n",
      " \"'_module_to_env_connector': None, \"\n",
      " \"'add_default_connectors_to_module_to_env_pipeline': True, \"\n",
      " \"'episode_lookback_horizon': 1, 'rollout_fragment_length': 'auto', \"\n",
      " \"'batch_mode': 'truncate_episodes', 'compress_observations': False, \"\n",
      " \"'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, \"\n",
      " \"'enable_tf1_exec_eagerly': False, 'sample_collector': <class \"\n",
      " \"'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, \"\n",
      " \"'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', \"\n",
      " \"'update_worker_filter_stats': True, 'use_worker_filter_stats': True, \"\n",
      " \"'sampler_perf_stats_ema_coef': None, 'num_learners': 1, \"\n",
      " \"'num_gpus_per_learner': 1, 'num_cpus_per_learner': 'auto', \"\n",
      " \"'num_aggregator_actors_per_learner': 0, \"\n",
      " \"'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, \"\n",
      " \"'max_requests_in_flight_per_learner': 3, 'gamma': 0.9, 'lr': None, \"\n",
      " \"'grad_clip': None, 'grad_clip_by': 'global_norm', \"\n",
      " \"'_train_batch_size_per_learner': 32768, 'train_batch_size': 256, \"\n",
      " \"'num_epochs': 1, 'minibatch_size': None, 'shuffle_batch_per_epoch': False, \"\n",
      " \"'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', \"\n",
      " \"'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, \"\n",
      " \"'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, \"\n",
      " \"'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': \"\n",
      " \"None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, \"\n",
      " \"'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': \"\n",
      " \"None, 'conv_transpose_kernel_initializer_config': None, \"\n",
      " \"'conv_transpose_bias_initializer': None, \"\n",
      " \"'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, \"\n",
      " \"'post_fcnet_weights_initializer_config': None, \"\n",
      " \"'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': \"\n",
      " \"None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': \"\n",
      " \"False, 'vf_share_layers': True, 'use_lstm': False, 'max_seq_len': 20, \"\n",
      " \"'lstm_cell_size': 256, 'lstm_use_prev_action': False, \"\n",
      " \"'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, \"\n",
      " \"'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, \"\n",
      " \"'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': \"\n",
      " \"False, 'attention_num_transformer_units': 1, 'attention_dim': 64, \"\n",
      " \"'attention_num_heads': 1, 'attention_head_dim': 32, \"\n",
      " \"'attention_memory_inference': 50, 'attention_memory_training': 50, \"\n",
      " \"'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, \"\n",
      " \"'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, \"\n",
      " \"'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, \"\n",
      " \"'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, \"\n",
      " \"'custom_preprocessor': None, 'encoder_latent_dim': None, \"\n",
      " \"'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, \"\n",
      " \"'_use_default_native_models': -1, '_disable_preprocessor_api': False, \"\n",
      " \"'_disable_action_flattening': False}, '_learner_connector': None, \"\n",
      " \"'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': \"\n",
      " \"{}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': \"\n",
      " \"None, 'callbacks_on_env_runners_recreated': None, \"\n",
      " \"'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': \"\n",
      " \"None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': \"\n",
      " \"None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, \"\n",
      " \"'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, \"\n",
      " \"'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, \"\n",
      " \"'explore': True, 'enable_rl_module_and_learner': True, \"\n",
      " \"'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': \"\n",
      " \"{'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', \"\n",
      " \"'policy_map_capacity': 100, 'policy_mapping_fn': <function \"\n",
      " 'AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x7f1839c4a980>, '\n",
      " \"'policies_to_train': None, 'policy_states_are_swappable': False, \"\n",
      " \"'observation_fn': None, 'offline_data_class': None, 'input_read_method': \"\n",
      " \"'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, \"\n",
      " \"'input_read_episodes': False, 'input_read_sample_batches': False, \"\n",
      " \"'input_read_batch_size': None, 'input_filesystem': None, \"\n",
      " \"'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'input_spaces_jsonable': True, 'materialize_data': False, \"\n",
      " \"'materialize_mapped_data': True, 'map_batches_kwargs': {}, \"\n",
      " \"'iter_batches_kwargs': {}, 'prelearner_class': None, \"\n",
      " \"'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, \"\n",
      " \"'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, \"\n",
      " \"'input_config': {}, 'actions_in_input_normalized': False, \"\n",
      " \"'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, \"\n",
      " \"'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], \"\n",
      " \"'output_max_file_size': 67108864, 'output_max_rows_per_file': None, \"\n",
      " \"'output_write_remaining_data': False, 'output_write_method': \"\n",
      " \"'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': \"\n",
      " \"None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, \"\n",
      " \"'offline_sampling': False, 'evaluation_interval': None, \"\n",
      " \"'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', \"\n",
      " \"'evaluation_sample_timeout_s': 120.0, 'evaluation_parallel_to_training': \"\n",
      " \"False, 'evaluation_force_reset_envs_before_iteration': True, \"\n",
      " \"'evaluation_config': None, 'off_policy_estimation_methods': {}, \"\n",
      " \"'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, \"\n",
      " \"'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, \"\n",
      " \"'keep_per_episode_custom_metrics': False, \"\n",
      " \"'metrics_episode_collection_timeout_s': 60.0, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': 1, \"\n",
      " \"'min_train_timesteps_per_iteration': 0, \"\n",
      " \"'min_sample_timesteps_per_iteration': 100, 'log_gradients': True, \"\n",
      " \"'export_native_model_files': False, 'checkpoint_trainable_policies_only': \"\n",
      " \"False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', \"\n",
      " \"'log_sys_usage': True, 'fake_sampler': False, 'seed': None, \"\n",
      " \"'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, \"\n",
      " \"'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': \"\n",
      " \"60.0, 'restart_failed_sub_environments': False, \"\n",
      " \"'num_consecutive_env_runner_failures_tolerance': 100, \"\n",
      " \"'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': \"\n",
      " \"1800.0, '_model_config': {}, '_rl_module_spec': None, \"\n",
      " \"'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, \"\n",
      " \"'_validate_config': True, '_use_msgpack_checkpoints': False, \"\n",
      " \"'_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, \"\n",
      " \"'_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': \"\n",
      " \"False, '_disable_action_flattening': False, \"\n",
      " \"'_disable_initialize_loss_from_dummy_batch': False, \"\n",
      " \"'_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, \"\n",
      " \"'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, \"\n",
      " \"'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, \"\n",
      " \"'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, \"\n",
      " \"'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, \"\n",
      " \"'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'twin_q': \"\n",
      " \"True, 'q_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'policy_model_config': {'fcnet_hiddens': [512, 512, 512, 512, 512, 32], \"\n",
      " \"'fcnet_activation': 'tanh', 'post_fcnet_hiddens': [], \"\n",
      " \"'post_fcnet_activation': None, 'custom_model': None, 'custom_model_config': \"\n",
      " \"{}}, 'tau': 0.005, 'initial_alpha': 1.0, 'target_entropy': 'auto', 'n_step': \"\n",
      " \"1, 'replay_buffer_config': {'type': 'PrioritizedEpisodeReplayBuffer', \"\n",
      " \"'capacity': 40000000, 'alpha': 0.6, 'beta': 0.4, \"\n",
      " \"'_enable_replay_buffer_api': True, 'replay_batch_size': 1024, \"\n",
      " \"'metrics_num_episodes_for_smoothing': 100}, 'store_buffer_in_checkpoints': \"\n",
      " \"False, 'training_intensity': None, 'optimization': {'actor_learning_rate': \"\n",
      " \"0.0003, 'critic_learning_rate': 0.0003, 'entropy_learning_rate': 0.0003}, \"\n",
      " \"'actor_lr': 0.001, 'critic_lr': 0.002, 'alpha_lr': 0.0003, \"\n",
      " \"'target_network_update_freq': 0, 'num_steps_sampled_before_learning_starts': \"\n",
      " \"1500, '_deterministic_loss': False, '_use_beta_distribution': False, \"\n",
      " \"'use_state_preprocessor': -1, 'worker_side_prioritization': -1, 'class': \"\n",
      " \"<class 'ray.rllib.algorithms.sac.sac.SACConfig'>, 'input': 'sampler', \"\n",
      " \"'policies': {'default_policy': (None, None, None, None)}, 'callbacks': \"\n",
      " \"<class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, \"\n",
      " \"'create_env_on_driver': False, 'custom_eval_function': None, 'framework': \"\n",
      " \"'torch'}, 'time_since_restore': 3596.005661010742, \"\n",
      " \"'iterations_since_restore': 161, 'perf': {'cpu_util_percent': \"\n",
      " \"np.float64(5.3062499999999995), 'ram_util_percent': np.float64(69.83125), \"\n",
      " \"'gpu_util_percent0': np.float64(0.0), 'vram_util_percent0': \"\n",
      " 'np.float64(0.0774078369140625)}})')\n",
      "161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/prioritized_episode_buffer.py:475: RuntimeWarning: divide by zero encountered in scalar power\n",
      "  weight = (p_sample * self.get_num_timesteps()) ** (-beta)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "134217727",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m save_name = \u001b[33m\"\u001b[39m\u001b[33m~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     result = \u001b[43malgo\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m03d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# result.pop(\"config\")\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# pprint(result)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:330\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    329\u001b[39m     skipped = skip_exceptions(e)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m skipped \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexception_cause\u001b[39;00m(skipped)\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mdict\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mstep() needs to return a dict.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# We do not modify internal state nor update this result if duplicate.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/tune/trainable/trainable.py:327\u001b[39m, in \u001b[36mTrainable.train\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    325\u001b[39m start = time.time()\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    329\u001b[39m     skipped = skip_exceptions(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:964\u001b[39m, in \u001b[36mAlgorithm.step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    959\u001b[39m \u001b[38;5;66;03m# - No evaluation necessary, just run the next training iteration.\u001b[39;00m\n\u001b[32m    960\u001b[39m \u001b[38;5;66;03m# - We have to evaluate in this training iteration, but no parallelism ->\u001b[39;00m\n\u001b[32m    961\u001b[39m \u001b[38;5;66;03m#   evaluate after the training iteration is entirely done.\u001b[39;00m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    963\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.enable_env_runner_and_connector_v2:\n\u001b[32m--> \u001b[39m\u001b[32m964\u001b[39m         train_results, train_iter_ctx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run_one_training_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    965\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    966\u001b[39m         (\n\u001b[32m    967\u001b[39m             train_results,\n\u001b[32m    968\u001b[39m             train_iter_ctx,\n\u001b[32m    969\u001b[39m         ) = \u001b[38;5;28mself\u001b[39m._run_one_training_iteration_old_api_stack()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:2991\u001b[39m, in \u001b[36mAlgorithm._run_one_training_iteration\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   2989\u001b[39m \u001b[38;5;66;03m# Try to train one step.\u001b[39;00m\n\u001b[32m   2990\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metrics.log_time((TIMERS, TRAINING_STEP_TIMER)):\n\u001b[32m-> \u001b[39m\u001b[32m2991\u001b[39m     training_step_return_value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2992\u001b[39m     has_run_once = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2994\u001b[39m \u001b[38;5;66;03m# On the new API stack, results should NOT be returned anymore as\u001b[39;00m\n\u001b[32m   2995\u001b[39m \u001b[38;5;66;03m# a dict, but purely logged through the `MetricsLogger` API. This\u001b[39;00m\n\u001b[32m   2996\u001b[39m \u001b[38;5;66;03m# way, we make sure to never miss a single stats/counter/timer\u001b[39;00m\n\u001b[32m   2997\u001b[39m \u001b[38;5;66;03m# when calling `self.training_step()` more than once within the same\u001b[39;00m\n\u001b[32m   2998\u001b[39m \u001b[38;5;66;03m# iteration.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/algorithms/dqn/dqn.py:630\u001b[39m, in \u001b[36mDQN.training_step\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    627\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._training_step_old_api_stack()\n\u001b[32m    629\u001b[39m \u001b[38;5;66;03m# New API stack (RLModule, Learner, EnvRunner, ConnectorV2).\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_training_step_new_api_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/algorithms/dqn/dqn.py:674\u001b[39m, in \u001b[36mDQN._training_step_new_api_stack\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    670\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(sample_and_train_weight):\n\u001b[32m    671\u001b[39m     \u001b[38;5;66;03m# Sample a list of episodes used for learning from the replay buffer.\u001b[39;00m\n\u001b[32m    672\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metrics.log_time((TIMERS, REPLAY_BUFFER_SAMPLE_TIMER)):\n\u001b[32m--> \u001b[39m\u001b[32m674\u001b[39m         episodes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlocal_replay_buffer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtotal_train_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_step\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mn_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# In case an `EpisodeReplayBuffer` is used we need to provide\u001b[39;49;00m\n\u001b[32m    678\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# the sequence length.\u001b[39;49;00m\n\u001b[32m    679\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbatch_length_T\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_stateful\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    680\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_seq_len\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlookback\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv_runner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_stateful\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    682\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO (simon): Implement `burn_in_len` in SAC and remove this\u001b[39;49;00m\n\u001b[32m    683\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# if-else clause.\u001b[39;49;00m\n\u001b[32m    684\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmin_batch_length_T\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mburn_in_len\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mhasattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mburn_in_len\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplay_buffer_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbeta\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m            \u001b[49m\u001b[43msample_episodes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    692\u001b[39m         \u001b[38;5;66;03m# Get the replay buffer metrics.\u001b[39;00m\n\u001b[32m    693\u001b[39m         replay_buffer_results = \u001b[38;5;28mself\u001b[39m.local_replay_buffer.get_metrics()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/gd/lib/python3.12/site-packages/ray/rllib/utils/replay_buffers/prioritized_episode_buffer.py:477\u001b[39m, in \u001b[36mPrioritizedEpisodeReplayBuffer.sample\u001b[39m\u001b[34m(self, num_items, batch_size_B, batch_length_T, n_step, beta, gamma, include_infos, include_extra_model_outputs, to_numpy, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m weight = (p_sample * \u001b[38;5;28mself\u001b[39m.get_num_timesteps()) ** (-beta)\n\u001b[32m    476\u001b[39m \u001b[38;5;66;03m# Now, get the transition stored at this index.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m index_triple = \u001b[38;5;28mself\u001b[39m._indices[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tree_idx_to_sample_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# Compute the actual episode index (offset by the number of\u001b[39;00m\n\u001b[32m    480\u001b[39m \u001b[38;5;66;03m# already evicted episodes)\u001b[39;00m\n\u001b[32m    481\u001b[39m episode_idx, episode_ts = (\n\u001b[32m    482\u001b[39m     index_triple[\u001b[32m0\u001b[39m] - \u001b[38;5;28mself\u001b[39m._num_episodes_evicted,\n\u001b[32m    483\u001b[39m     index_triple[\u001b[32m1\u001b[39m],\n\u001b[32m    484\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 134217727"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "n_iter = 4000\n",
    "save_iter = 0\n",
    "save_name = \"~/learned_policy/SAC_layer_512_5_32_linear_friction_joy_314\"\n",
    "\n",
    "for i in range(n_iter):\n",
    "    result = algo.train()\n",
    "    print(f\"{i:03d}\", end=\", \")\n",
    "    # result.pop(\"config\")\n",
    "    # pprint(result)\n",
    "\n",
    "    if i%40 == 0:\n",
    "        checkpoint_dir = algo.save(checkpoint_dir=save_name+f\"_{save_iter}\")\n",
    "        pprint(f\"Checkpoint saved in directory {checkpoint_dir}\")\n",
    "        save_iter += 1\n",
    "\n",
    "checkpoint_dir = algo.save(checkpoint_dir=save_name+\"_final\")\n",
    "pprint(f\"Checkpoint saved in directory {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
