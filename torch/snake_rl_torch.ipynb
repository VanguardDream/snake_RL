{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snake-RL (Pytorch)\n",
    "Gait Decomposition을 활용하여 Gait 자체를 학습하는 연구를 이 Jupyter 노트북에 작성을 하려고함. Gait Decomposition은 뱀 로봇의 움직임을 P함수와 M행렬로 분해하여 뱀 로봇의 Gait를 표현하는 방법이며, 이 방법을 통해서 직관적으로 뱀 로봇의 움직임을 표현할 수 있고, 파라미터 튜닝을 진행할 수 있다. 관련 내용은 [Arxiv 논문](https://arxiv.org/abs/2112.02057)을 참조할 것.\n",
    "\n",
    "## Gait Decomposition에 대한 이해\n",
    "Gait Decomposition에 대한 코드는 Gait 클래스에 구현되어 있다. 따라서 Gait 생성 코드를 코드에 import하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from gait import gait\n",
    "\n",
    "g = gait(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드에서 삽입된 gait.py코드는 위 논문의 P함수와 M행렬을 객체로 구현한 코드이다.\n",
    "\n",
    "Gait가 잘 생성되는지 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[15.  0. -0. -0.  0.  0. -0. -0.  0.  0.  0.  0. -0. -0.]]\n",
      "[[ 0.   13.97 -0.   -0.    0.    0.   -0.   -0.    0.    0.   -0.   -0.\n",
      "  -0.   -0.  ]]\n",
      "[[  0.     0.   -23.31  -0.     0.     0.    -0.    -0.     0.     0.\n",
      "   -0.    -0.    -0.    -0.  ]]\n",
      "[[  0.     0.    -0.   -24.04   0.     0.    -0.    -0.     0.     0.\n",
      "   -0.    -0.    -0.    -0.  ]]\n",
      "[[ 0.    0.   -0.   -0.   28.53  0.   -0.   -0.    0.    0.   -0.   -0.\n",
      "  -0.   -0.  ]]\n",
      "[[ 0.    0.   -0.   -0.    0.   29.42 -0.   -0.    0.    0.   -0.   -0.\n",
      "  -0.   -0.  ]]\n",
      "[[  0.     0.    -0.    -0.     0.     0.   -29.96  -0.     0.     0.\n",
      "   -0.    -0.    -0.    -0.  ]]\n",
      "[[ -0.     0.    -0.    -0.     0.     0.    -0.   -29.08   0.     0.\n",
      "   -0.    -0.     0.    -0.  ]]\n",
      "[[-0.    0.   -0.   -0.    0.    0.   -0.   -0.   27.41  0.   -0.   -0.\n",
      "   0.   -0.  ]]\n",
      "[[-0.    0.   -0.   -0.    0.    0.   -0.   -0.    0.   23.07 -0.   -0.\n",
      "   0.   -0.  ]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,10):\n",
    "    print(g.generate(i).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 생성된 Gait 데이터를 통해서 모터를 동작시키면 뱀 로봇이 움직이게 된다. Mujoco 시뮬레이터에서 움직이는 것을 그림으로 나타내면 아래 그림과 같다.\n",
    "\n",
    "![fig1](./img/fig1.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 출력 결과와 같이 $i$가 증가하면서 각 모터에 입력되는 입력 신호가 바뀌는 것을 확인할 수 있다. \n",
    "위 결과는 P함수와 M행렬의 행렬 곱에서 대각 원소의 값을 출력한 결과이다. 위와 같은 결과를 모터에 전달하여 뱀 로봇이 움직이도록 만들 수 있다.\n",
    "\n",
    "P함수는 모터의 목표 위치를 계산하는 함수로 주기 함수의 꼴을 갖는다. 주변 환경이 변하지 않는 이상적인 환경에서는 미리 학습된 P함수를 통해서 뱀 로봇을 움직이게 만들 수 있다.\n",
    "하지만, 뱀 로봇이 항상 이상적인 환경에서 동작하지 않기 때문에 학습된 P함수가 최적 값을 내지못할 수도 있다. 우리는 이런 점에서 P함수를 센싱되는 지형의 데이터나 로봇의 상태에 따라서 변경할 수 있는 알고리즘을 구현하고자 한다.\n",
    "\n",
    "이를 위해 P함수의 정의를 명확하게 하고자한다.\n",
    "\n",
    "$$\n",
    "P(t,A,\\phi) \\to \\bar{\\theta}\n",
    "$$\n",
    "\n",
    "위 식을 확인하면 P함수는 시간과 진폭, 위상차를 독립 변수로 갖는 함수이다. 더 상세하게 P함수를 나타내면 다음과 같다.\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\bar{\\theta} = \\left( \n",
    "    \\begin{matrix}\n",
    "    i = \\text{odd}\\;, \\theta_i =  A_{\\text{dor.}}\\cdot \\sin(\\frac{2 \\pi}{m}t + \\frac{i}{2} \\cdot \\phi_{\\text{dor.}})\\;\\;\\; \\\\ \\\\\n",
    "    i = \\text{even}\\;, \\theta_i =   A_{\\text{lat.}}\\cdot \\sin(\\frac{2 \\pi}{m}t + \\frac{i-1}{2}\\cdot \\phi_{\\text{lat.}})\\; \\end{matrix} \n",
    "    \\right)\\quad\\quad\n",
    "\\end{equation*}\n",
    "$$ \n",
    "여기에서, $m$은 P함수의 주파수 성분을 나타내기 위한 상수이며, $i$는 모터의 순서를 나타낸다.  우리 시스템에서는 Head 모터가 0번이다. $(i=0, \\text{Head})$\n",
    "\n",
    "이 때 다시 Gait 생성 코드를 보면 순서대로 머리모터부터 홀수 번째 모터들이 순서대로 움직이는 것으로 볼 수 있다. P함수는 t에 따라서 모든 모터에 대한 $\\theta$값이 변경되는데 홀수번째 모터만 동작하는 이유는 우리가 뱀 로봇의 Gait를 정의하기 위해서 모션 행렬 M을 정의했기 때문이다. 모션 행렬 M은 뱀 로봇의 Gait를 구분하기 위한 주요한 파라미터이다. 이 행렬을 통해서 시간 t에서 어떤 모터가 동작할지 정할 수 있다. 현재 우리는 뱀 로봇의 Gait로 3가지 Gait를 정의했다. Inchworm, Serpentine, Sidewind이고 이를 모션 행렬로 표현하면 아래와 같다.\n",
    "\n",
    "### Inchworm gait의 모션 행렬\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\mathbb{M_\\text{inch}} = \\begin{bmatrix}\n",
    "1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 1 \\\\\n",
    "0 & 0 & 0 & 0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix} \\end{equation*}\n",
    "$$\n",
    "### Serpentine gait의 모션 행렬\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbb{M_\\text{ser}} = \\begin{bmatrix}\n",
    "1 & 0 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 1 & 0 & \\cdots & 0 & 0\\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0\\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    " 0 & 0 & 0 & \\cdots & 1 & 0\\\\\n",
    " 0 & 0 & 0 & \\cdots & 0 & 1 \n",
    "\\end{bmatrix} = \\mathbb{I}\n",
    "\\end{equation} \n",
    "$$\n",
    "### Sidewind gait의 모션 행렬\n",
    "$$\n",
    "\\begin{equation}\n",
    "    \\mathbb{M_\\text{side}} = \\begin{bmatrix}\n",
    "0 & 1 & 0 & \\cdots & 0 & 0 \\\\\n",
    "1 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 0 \\\\\n",
    "0 & 0 & 1 & \\cdots & 0 & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\\n",
    "0 & 0 & 0 & \\cdots & 0 & 1\\\\\n",
    "0 & 0 & 0 & \\cdots & 1 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "$\\mathbb{m}$행렬은 k개의 열벡터로 이루어진다. $(\\mathbb{M} = \\{m_1,..m_k\\})$ 여기에서 이 열벡터는 해당 시간에서 움직이는 모터의 인덱스를 표현한다. 따라서 P함수와 M행렬을 내적하면 어떤 모터가 어느 정도 움직이면 되는지를 표현할 수 있다. 여기에서 시스템 모터의 목표 각도 Array를 $\\mathbb{G}$라고 가정하면, 수식으로 다음과 같이 표현할 수 있다.\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mathbb{M} = \\left[\n",
    "\\begin{matrix}\n",
    "    \\vert & \\vert &        & \\vert \\\\\n",
    "    m_1   &   m_2 & \\cdots & m_k \\\\\n",
    "    \\vert & \\vert &        & \\vert \\\\\n",
    "\\end{matrix}\n",
    "\\right] \\; , \\, m_k \\in \\mathbb{R}^{14}\\\\\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "    \\mathbb{G}_k = \\bar{\\theta} \\, \\cdot \\, {m_k}^{T}   \\; , \\; \\mathbb{G}_{k} \\in \\mathbb{R}^{14 \\times 14}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "이렇게 표현된 Gait는 P함수의 파라미터를 조절하여 튜닝(최적화)시킬 수 있다. 최적화를 진행하기 위해서는 Gait의 성능을 평가할 수 있는 범함수가 필요하다. 우리는 성능 평가를 위한 범함수를 아래와 같이 정의했다.\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "    U(k,P(k,\\,\\bar{\\theta}),\\mathbb{M}) = {i} \\cdot \\Delta x - {j} \\cdot |\\Delta y| - {l} \\cdot |\\frac{\\Delta y}{\\Delta x}| - m \\cdot {\\int}_{t_{0}}^{t_f} {\\| \\mathbb{G}_{k} \\|}_1 \\,dk \\\\\n",
    "    \\\\\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "위 범함수는 정의된 뱀 로봇이 10초 동안 움직이고 난 뒤의 결과를 통해 Gait 성능을 평가하는 함수이다. $i,j,l$은 성능 지표 이며 이 지표를 변경하면서 어떤 성능을 중점적으로 최적화할 것인지 표현할 수 있다. 위와 같은 범 함수를 활용하여 P함수의 파라미터를 최적화시킬 수 있었다. 하지만 이렇게 최적화된 Gait는 Open-loop로 제어되어, 뱀 로봇의 상태를 피드백받지 않고 모터의 목표값을 생성한다. 따라서 다양한 환경에서 적응하기 어렵다. \n",
    "\n",
    "우리는 이렇게 Decomposed된 Gait 구성 요소를 활용하여 Closed-loop제어를 하기위해서 DNN 네트워크를 활용하고자 한다. \n",
    "\n",
    "제안하는 네트워크 구조는 다음과 같다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig2](./img/RL-control-block.png)\n",
    "\n",
    "위 그림과 같이 Gait Decomposition을 활용하여 뱀 로봇을 구동시키며 얻은 State, Reward를 통해서 신경망을 학습시키고, Feedback하여 뱀 로봇을 제어할 수 있도록 블록을 구성하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## State Listener 구현\n",
    "위와 같은 구조로 뱀 로봇을 움직이기 위해서 시뮬레이션 결과를 받아올 수 있는 Listener를 구현해야 했다. 신경망 입력으로는 벡터 $\\bar{x}$가 입력되며 이 벡터의 원소는 아래와 같다.\n",
    "\n",
    "$$\n",
    "\\bar{x} = \\left( \\begin{align*} k \\\\ \\theta \\\\ \\dot{\\theta} \\\\ \\bar{q} \\end{align*}\\right)\n",
    "$$\n",
    "\n",
    "여기서 $k$는 time step을 나타내며, $\\theta$는 관절의 각도, $\\bar{q}$는 머리 링크의 오리엔테이션과 위치를 나타낸다.\n",
    "\n",
    "이와 같은 데이터를 Mujoco 시뮬레이터에서 얻어야한다. Python에서 Mujoco를 import하고 관련된 설정을 진행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mujoco_py\n",
    "\n",
    "snake = mujoco_py.load_model_from_path(\"../description/mujoco/snake_dgistV2.xml\")\n",
    "simulator = mujoco_py.MjSim(snake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같은 설정을 통해서 뱀 로봇 정의 파일을 Mujoco가 불러와 시뮬레이션 환경을 구축할 수 있게 되었다.\n",
    "\n",
    "이후 각 Step마다 필요한 정보를 가져오는 함수를 구현하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stepListener(k) -> np.ndarray:\n",
    "    joint_names = ['joint1','joint2','joint3','joint4','joint5','joint6','joint7','joint8','joint9','joint10','joint11','joint12','joint13','joint14']\n",
    "\n",
    "    theta = np.array([simulator.data.get_joint_qpos(x) for x in joint_names])\n",
    "    dtheta = np.array([simulator.data.get_joint_qvel(x) for x in joint_names])\n",
    "    x = np.array(simulator.data.get_body_xpos('head'))\n",
    "    q = np.array(simulator.data.get_body_xquat('head'))\n",
    "\n",
    "    # print(theta)\n",
    "    # print(dtheta)\n",
    "    # print(q)\n",
    "    state = np.concatenate((np.array([k%14]),theta,dtheta,x,q))\n",
    "\n",
    "    # return np.array([k, theta, dtheta, q],dtype='object')\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward 계산 함수 구현\n",
    "받아온 State를 통해서 Reward를 계산하는 함수를 구현해야한다. GD 최적화 논문에서는 0초에서 Terminal까지의 변위를 통해 Reward를 계산했지만 여기서는 State간의 Reward를 계산해야한다. 이런 Reward를 계산하기 앞서, 현재 Quaternion형태로 받아오는 방향 정보를 알기 쉬운 Euler 형태로 바꾸는 함수를 구현하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat2euler(x, y, z, w):\n",
    "        t0 = +2.0 * (w * x + y * z)\n",
    "        t1 = +1.0 - 2.0 * (x * x + y * y)\n",
    "        roll_x = math.atan2(t0, t1)\n",
    "     \n",
    "        t2 = +2.0 * (w * y - z * x)\n",
    "        t2 = +1.0 if t2 > +1.0 else t2\n",
    "        t2 = -1.0 if t2 < -1.0 else t2\n",
    "        pitch_y = math.asin(t2)\n",
    "     \n",
    "        t3 = +2.0 * (w * z + x * y)\n",
    "        t4 = +1.0 - 2.0 * (y * y + z * z)\n",
    "        yaw_z = math.atan2(t3, t4)\n",
    "     \n",
    "        return roll_x, pitch_y, yaw_z # in radians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 State간의 변위를 이용하여 Reward를 계산하는 함수를 구현하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getReward(k:int,l_s:list, c_s:list)-> float:\n",
    "    l_s = np.array(l_s)\n",
    "    c_s = np.array(c_s)\n",
    "\n",
    "    s = c_s - l_s\n",
    "\n",
    "    r,p,y = quat2euler(s[-3],s[-2],s[-1],s[-4])\n",
    "\n",
    "    if abs(r) > math.pi/2:\n",
    "        return -300, True\n",
    "    \n",
    "    if abs(p) > math.pi/2:\n",
    "        return -300, True\n",
    "\n",
    "    if abs(y) > math.pi/2:\n",
    "        return -300, True\n",
    "\n",
    "\n",
    "    reward = \\\n",
    "        300 * s[-7] + 10 * c_s[-7]/(k + 1)\\\n",
    "            - 100 * abs(c_s[-6]) \\\n",
    "                # + (4 / (abs(r) + 1)) \\\n",
    "                    # + (4 / (abs(p) + 1)) \\\n",
    "                        # - 10 * abs(y)\n",
    "    return reward, False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후 뱀 로봇이 P함수와 M행렬에 따라서 움직일 수 있도록 $\\mathbb{G}$벡터를 계산하는 코드를 구현해야 한다. Gait Decomposition은 Gait 파라미터가 바뀌지 않는 상태에서 연속적으로 뱀 로봇의 움직임을 생성하는 반면에, 신경망을 통해 Feed forward하는 이 시스템의 경우 새롭게 Gait 파라미터를 받아 P함수의 특성을 바꾸는 기능이 추가되어야한다. 이를 코드로 구현하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genGait(k:int, gait:int, d_amp:float, d_phase:float, d_lam:float,l_amp:float, l_phase:float, l_lam:float, tau:int) -> np.ndarray:\n",
    "    if tau < 1:\n",
    "        tau = 1\n",
    "\n",
    "    g.setParams(gait, d_amp, d_phase, d_lam, l_amp, l_phase, l_lam, tau)\n",
    "    goal_P = g.generate(k)\n",
    "\n",
    "    return goal_P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위와 같이 구현한 코드가 시뮬레이터에서 잘 작동하는지 확인해보도록 하자. 아직 신경망이 구현되지 않았으므로 임의의 Gait 파라미터를 생성하기 위해서 Random 패키지를 사용하여 Gait를 생성하기로 한다. 이를 코드로 구현하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# viewer = mujoco_py.MjViewer(simulator) #For rendering sim results.\n",
    "\n",
    "# for k in range(0,5000):\n",
    "#     p1 = random.randint(0,900)/10\n",
    "#     p2 = random.randint(0,3600)/10\n",
    "#     p3 = random.randint(-10,10)\n",
    "#     p4 = random.randint(0,900)/10\n",
    "#     p5 = random.randint(0,3600)/10\n",
    "#     p6 = random.randint(-10,10)\n",
    "#     p7 = random.randint(1,4)\n",
    "\n",
    "#     G_k = genGait(k,1,p1,p2,p3,p4,p5,p6,p7)\n",
    "#     motor_idx = np.nonzero(G_k)\n",
    "\n",
    "#     for idx in motor_idx:\n",
    "#                 if not(len(idx) == 0):\n",
    "#                     simulator.data.ctrl[idx] = g.degtorad(G_k[idx])\n",
    "\n",
    "#     simulator.step()\n",
    "#     viewer.render()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 코드를 실행시키면 아래와 같은 모양으로 뱀 로봇이 움직이는 것을 확인할 수 있다.\n",
    "![fig2](./img/randomized-movement.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replay Memory 구현\n",
    "Replay Memory는 학습 속도를 증가시키기 위해서 여러 케이스로 실험을 진행한 결과를 저장할 수 있도록 구현된 Memory이다. 일반적으로 학습에는 병렬 연산이 많이 이루어지므로 데이터를 모아 둔 뒤 한번에 학습하는 것이 더 빠르다고 한다. Replay Memory코드는 [Pytorch 튜토리얼](https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html)을 참고했다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple, deque\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network 구현\n",
    "뱀 로봇의 상태 변화를 통해서 적절한 제어 신호를 생성하는 Q Network는 그 신경망 구조에 따라서 학습 속도나 성능이 달라질 수 있다. 우선 간단한 MLP구조의 신경망을 통해서 뱀 로봇의 제어를 진행해보도록 코드를 구현했다.\n",
    "\n",
    "### MLP 기반 네트워크\n",
    "먼저 기본적인 MLP 기반으로 네트워크를 구성하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN_MLP, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(36,16, bias=True)\n",
    "        self.fc2 = nn.Linear(16,32, bias=True)\n",
    "        self.fc3 = nn.Linear(32,8,bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = x.float()\n",
    "        \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP 기반 + 다중 선택 네트워크\n",
    "이전 버전의 네트워크는 Policy Net에서 생성된 Gait 파라미터를 그대로 Gait 생성기에 적용하여 움직임을 생성했지만, 다중 선택지를 생성하는 MLP 기반의 네트워크를 아래와 같이 구현했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN_MLP_MC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN_MLP_MC, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(36,64, bias=True)\n",
    "        self.fc2 = nn.Linear(64,64, bias=True)\n",
    "        self.fc3 = nn.Linear(64,40,bias=True)\n",
    "        self.drop = nn.Dropout(0.85)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = x.float()\n",
    "        \n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x.reshape(-1,8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 기반으로 네트워크\n",
    "MLP로 네트워크를 구성하여 실험해본 결과 생각보다 Gait 학습이 수렴되는 모습이 보이지 않아 RNN 기반의 네트워크 구성을 진행해보았다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class DQN_RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN_RNN, self).__init__()\n",
    "\n",
    "        self.lstm1 = nn.LSTM(36,9)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        # x = torch.tensor(x,device=device)\n",
    "        x = x.float()\n",
    "        \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # x = F.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP 기반으로 구성된 Q-Network는 3개의 Layer가 있으며 각 레이어가 선형 결합되도록 구성되었다. 또한 2번 층 이후에 Dropout를 진행한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training 루프 구현 준비\n",
    "뱀 로봇을 움직이게 만들고, 이를 학습시키기 위한 준비가 끝났다. 본격적으로 신경망을 학습시키는 코드를 구현해야한다. 먼저 학습에 필요한 Hyper 파라미터를 조절하는 코드와 액션 벡터를 추출하는 함수 등을 구현한다..\n",
    "\n",
    "### Hyper 파라미터\n",
    "Hyper 파라미터는 단순한 변수로 표현할 수 있다. 이에 해당되는 코드는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "GAMMA = 0.85\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# n_actions = 14 #number of joints\n",
    "\n",
    "# Single choice net\n",
    "# policy_net = DQN_MLP().to(device)\n",
    "# target_net = DQN_MLP().to(device)\n",
    "\n",
    "# Multiple choice net\n",
    "policy_net = DQN_MLP_MC().to(device)\n",
    "target_net = DQN_MLP_MC().to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(),lr=0.1)\n",
    "\n",
    "memory = ReplayMemory(100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Action 추출기 구현\n",
    "\n",
    "구현된 신경망을 통해서 다음 State로 전이되기 위한 Action을 추출하는 코드를 아래와 같이 구현했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_done = 0\n",
    "\n",
    "def select_action(input):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * math.exp(-1. * steps_done / EPS_DECAY)\n",
    "\n",
    "    steps_done = steps_done + 1\n",
    "\n",
    "    action_elements = policy_net(input)\n",
    "\n",
    "    if action_elements.size(dim=0) == 0:\n",
    "        #Flat action\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                return torch.tensor([action_elements[0] * 80,\n",
    "                action_elements[1] * 180,\n",
    "                action_elements[2] * 10,\n",
    "                action_elements[3] * 80,\n",
    "                action_elements[4] * 180,\n",
    "                action_elements[5] * 10,\n",
    "                abs(action_elements[6]) * 4], device=device)\n",
    "\n",
    "        else:\n",
    "            return torch.tensor([random.randint(-80,80), \n",
    "            random.randint(-360,360), \n",
    "            random.randint(-10,10), \n",
    "            random.randint(-80,80), \n",
    "            random.randint(-360,360), \n",
    "            random.randint(-10,10), \n",
    "            random.randint(1,7)], device=device)\n",
    "    else:\n",
    "        #Multiple choice\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                action_elements = action_elements[action_elements[:,7].max(0).indices]\n",
    "                return torch.tensor([action_elements[0] * 80,\n",
    "                action_elements[1] * 180,\n",
    "                action_elements[2] * 10,\n",
    "                action_elements[3] * 80,\n",
    "                action_elements[4] * 180,\n",
    "                action_elements[5] * 10,\n",
    "                abs(action_elements[6]) * 4], device=device)\n",
    "        else:\n",
    "            return torch.tensor([random.randint(-80,80), \n",
    "            random.randint(-360,360), \n",
    "            random.randint(-10,10), \n",
    "            random.randint(-80,80), \n",
    "            random.randint(-360,360), \n",
    "            random.randint(-10,10), \n",
    "            random.randint(1,7)], device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 결과 Plot 함수 구현\n",
    "에피소드 마다 학습되는 결과를 Plot하기 위한 Plotting 함수를 구현하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# It does not work with VS Code ipython...\n",
    "# is_ipython = 'inline' in matplotlib.get_backend()\n",
    "# if is_ipython:\n",
    "#     from IPython import display\n",
    "\n",
    "delta_x = []\n",
    "delta_y = []\n",
    "disp_o = []\n",
    "accum_reward = []\n",
    "\n",
    "\n",
    "def plot_duration():\n",
    "    plt.figure(1)\n",
    "    plt.clf()\n",
    "    dx = torch.tensor(delta_x, dtype=torch.float)\n",
    "    dy = torch.tensor(delta_y, dtype=torch.float)\n",
    "    dio = torch.tensor(disp_o, dtype=torch.float)\n",
    "    rewards = torch.tensor(accum_reward, dtype=torch.float)\n",
    "\n",
    "    plt.title('Training process...')\n",
    "    plt.xlabel('Episodes')\n",
    "    plt.ylabel('Reward')\n",
    "    # plt.plot(dx.numpy(),label='delta X')\n",
    "    # plt.plot(dy.numpy(),label='delta Y')\n",
    "    # plt.plot(dio.numpy(),label='disp')\n",
    "    plt.plot(rewards.numpy(),label='step reward')\n",
    "    plt.legend()\n",
    "\n",
    "    # if len(dx) >= 100:\n",
    "    #     means_dx = dx.unfold(0,100,1).mean(1).view(-1)\n",
    "    #     means_dx = torch.cat((torch.zeros(99), means_dx))\n",
    "\n",
    "    #     means_dy = dy.unfold(0,100,1).mean(1).view(-1)\n",
    "    #     means_dy = torch.cat((torch.zeros(99), means_dy))\n",
    "\n",
    "    #     means_dio = dio.unfold(0,100,1).mean(1).view(-1)\n",
    "    #     means_dio = torch.cat((torch.zeros(99), means_dio))\n",
    "\n",
    "    #     plt.plot(means_dx.numpy(),means_dy.numpy(),means_dio.numpy())\n",
    "    #     plt.legend()\n",
    "\n",
    "    plt.pause(0.01)\n",
    "    \n",
    "    # if is_ipython:\n",
    "    #     display.clear_output(wait=True)\n",
    "    #     display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 불러오기 (옵션)\n",
    "학습된 모델을 이어서 학습시키고 싶으면 모델을 불러와서 다시 학습을 진행하면 된다. 해당 코드는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net.load_state_dict(torch.load(\"./weights/policy.pt\"))\n",
    "policy_net.eval()\n",
    "target_net.load_state_dict(torch.load(\"./weights/policy.pt\"))\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop 구현\n",
    "학습을 위해 필요한 대부분의 블록이 구현되었다. 이제 실제로 학습을 진행하는(Optimizing) 코드를 구현해야한다. 이는 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optmize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        print('Sim data is too small terminate optimizing...')\n",
    "\n",
    "    transition = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    batch = Transition(*zip(*transition))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    non_final_next_states = torch.reshape(non_final_next_states,(BATCH_SIZE,36))\n",
    "\n",
    "    # state_batch = torch.cat(batch.state)\n",
    "    # state_batch = torch.reshape(state_batch,(BATCH_SIZE,36))\n",
    "    # action_batch = torch.cat(batch.action)\n",
    "    # action_batch = torch.reshape(action_batch,(BATCH_SIZE,8))\n",
    "    # reward_batch = torch.cat(batch.reward)\n",
    "    # reward_batch = torch.reshape(reward_batch,(BATCH_SIZE,1))\n",
    "\n",
    "    state_batch = torch.cat(batch.state).view(BATCH_SIZE,-1)\n",
    "    action_batch = torch.cat(batch.action).view(BATCH_SIZE,-1)\n",
    "    reward_batch = torch.cat(batch.reward).view(BATCH_SIZE,-1)\n",
    "\n",
    "    gather_indices = [7 for i in range(BATCH_SIZE)]\n",
    "    gather_indices = torch.tensor(gather_indices,device=device).unsqueeze(axis=-1)\n",
    "\n",
    "    state_action_values = policy_net(state_batch)\n",
    "    state_action_values = torch.gather(state_action_values,1,gather_indices).squeeze(1)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).gather(1,gather_indices).reshape(BATCH_SIZE).detach()\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.squeeze(1)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values,expected_state_action_values)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # for param in policy_net.parameters():\n",
    "    #     param.grad.data.clamp_(-1,1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optmize_model2():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        print('Sim data is too small terminate optimizing...')\n",
    "\n",
    "    transition = memory.sample(BATCH_SIZE)\n",
    "\n",
    "    batch = Transition(*zip(*transition))\n",
    "\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None, batch.next_state)), device=device, dtype=torch.bool)\n",
    "\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state if s is not None])\n",
    "    non_final_next_states = torch.reshape(non_final_next_states,(BATCH_SIZE,36))\n",
    "\n",
    "    state_batch = torch.cat(batch.state).view(BATCH_SIZE,-1)\n",
    "    action_batch = torch.cat(batch.action).view(BATCH_SIZE,-1)\n",
    "    reward_batch = torch.cat(batch.reward).view(BATCH_SIZE,-1)\n",
    "\n",
    "    state_action_values = policy_net(state_batch)\n",
    "    state_action_values = state_action_values[:,7].max(0).values\n",
    "\n",
    "    # state_action_values = policy_net(state_batch)\n",
    "    # state_action_values = torch.gather(state_action_values,1,gather_indices).squeeze(1)\n",
    "\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states)[:,7].max(0).values\n",
    "\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.squeeze(1)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values,expected_state_action_values)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # for param in policy_net.parameters():\n",
    "    #     param.grad.data.clamp_(-1,1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop 구현\n",
    "위 코드들을 이용해서 Sim Data를 획득하고 최적화를 진행하는 코드를 구현하면 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n",
      "/home/bong/anaconda3/envs/rl/lib/python3.8/site-packages/torch/nn/modules/loss.py:912: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 100\n",
    "# viewer = mujoco_py.MjViewer(simulator) #For rendering sim results.\n",
    "\n",
    "for i_episode in range(num_episodes):\n",
    "    \n",
    "    simulator.reset()\n",
    "    k = 0\n",
    "    avg_reward = 0\n",
    "    last_state = stepListener(k)\n",
    "\n",
    "    simulator.step()\n",
    "\n",
    "    k_range = 500\n",
    "\n",
    "    for k in range(k_range):\n",
    "        action = select_action(torch.from_numpy(last_state))\n",
    "        # action = policy_net(torch.from_numpy(last_state))\n",
    "\n",
    "        gait_param = action.tolist()\n",
    "\n",
    "        G_k = genGait(k,1, gait_param[0], gait_param[1], gait_param[2], gait_param[3], gait_param[4], gait_param[5], gait_param[6])\n",
    "\n",
    "        motor_idx = np.nonzero(G_k)\n",
    "\n",
    "        # print(gait_param)\n",
    "\n",
    "        for idx in motor_idx:\n",
    "                    if not(len(idx) == 0):\n",
    "                        simulator.data.ctrl[idx] = g.degtorad(G_k[idx])\n",
    "\n",
    "        simulator.step()\n",
    "        # viewer.render()\n",
    "\n",
    "        current_state = stepListener(k)\n",
    "        reward, is_Done = getReward(k,last_state, current_state)\n",
    "\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        avg_reward = avg_reward + reward\n",
    "        \n",
    "        memory.push(torch.from_numpy(last_state), action, torch.from_numpy(current_state), reward)\n",
    "\n",
    "        last_state = current_state\n",
    "\n",
    "        # if k == k_range -1:\n",
    "        #     memory.push(_,_,None,_)\n",
    "\n",
    "    optmize_model2()\n",
    "\n",
    "    dx = current_state[-7]\n",
    "    dy = current_state[-6]\n",
    "    disp = math.sqrt( dx**2 + dy**2 )\n",
    "\n",
    "    delta_x.append(dx)\n",
    "    delta_y.append(dy)\n",
    "    disp_o.append(disp)\n",
    "    accum_reward.append(avg_reward / k_range)\n",
    "    \n",
    "    plot_duration()\n",
    "\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습된 network 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating window glfw\n",
      "0.000000 | 0.000000 | 0.000000\n",
      "0.000000 | 0.000000 | 0.000000\n",
      "0.000000 | -1.022395 | 0.000000\n",
      "-0.002299 | -1.331115 | 0.781166\n",
      "-0.001437 | -0.977690 | 2.209603\n",
      "0.105457 | -0.206852 | 4.530922\n",
      "0.146340 | 0.782465 | 7.482983\n",
      "0.237910 | 0.721734 | 9.231882\n",
      "0.385834 | 0.699958 | 10.117329\n",
      "0.640593 | 0.700861 | 10.464780\n",
      "0.759825 | 0.649548 | 10.676416\n",
      "0.908139 | 0.516838 | 11.032383\n",
      "0.424104 | 0.369952 | 11.721959\n",
      "0.093266 | 0.357985 | 12.734906\n",
      "-0.554688 | -0.210378 | 14.095721\n",
      "-0.211727 | -0.230834 | 15.911074\n",
      "0.454324 | -0.241087 | 18.184673\n",
      "2.014136 | -0.512731 | 19.765247\n",
      "3.125966 | -1.244931 | 20.899566\n",
      "2.846919 | -0.627935 | 21.658447\n",
      "0.679396 | -1.273503 | 23.065407\n",
      "-2.261265 | -2.704286 | 25.441636\n",
      "-5.952038 | -4.684012 | 28.746253\n",
      "-7.916742 | -6.384819 | 31.983872\n",
      "-10.247575 | -7.857970 | 35.038923\n",
      "-14.146536 | -9.057323 | 38.103796\n",
      "-18.343928 | -10.347530 | 41.310752\n",
      "-21.059209 | -11.234253 | 44.357663\n",
      "-23.734898 | -12.033646 | 47.677490\n",
      "-26.441093 | -12.627868 | 51.201849\n",
      "-28.293286 | -12.694528 | 54.494412\n",
      "-30.256323 | -12.285276 | 58.377633\n",
      "-32.711731 | -11.936032 | 62.924620\n",
      "-34.934037 | -11.742194 | 67.554277\n",
      "-35.250090 | -12.037964 | 72.024169\n",
      "-35.140955 | -11.839536 | 76.137976\n",
      "-33.911270 | -12.608506 | 79.163811\n",
      "-31.321480 | -14.015272 | 81.684800\n",
      "-27.912683 | -15.566314 | 83.592963\n",
      "-26.374334 | -14.854064 | 84.940483\n",
      "-24.686045 | -13.650865 | 86.058686\n",
      "-22.343958 | -12.567603 | 87.105586\n",
      "-19.908364 | -11.690800 | 87.781549\n",
      "-17.620801 | -11.052954 | 87.895045\n",
      "-17.031459 | -9.239152 | 87.549458\n",
      "-17.441648 | -7.260565 | 87.929273\n",
      "-18.697962 | -5.037026 | 89.076572\n",
      "-20.446030 | -2.437384 | 90.930190\n",
      "-20.758571 | -0.612815 | 93.543992\n",
      "-21.613135 | 1.755109 | 96.637269\n",
      "-22.167747 | 3.975809 | 99.959892\n",
      "-22.565819 | 5.737768 | 103.331085\n",
      "-23.663629 | 7.889112 | 105.711399\n",
      "-25.248751 | 9.737039 | 106.657681\n",
      "-27.187233 | 9.618262 | 106.298720\n",
      "-29.002992 | 8.926732 | 105.378449\n",
      "-31.413901 | 8.960038 | 104.419449\n",
      "-33.994872 | 9.207056 | 103.858871\n",
      "-36.478204 | 9.413023 | 103.750997\n",
      "-38.392870 | 9.938649 | 104.484534\n",
      "-39.201886 | 10.345648 | 105.746661\n",
      "-39.617108 | 11.945829 | 106.980820\n",
      "-38.974669 | 13.254194 | 108.126569\n",
      "-37.935094 | 14.910469 | 108.482110\n",
      "-36.785828 | 14.934586 | 108.705518\n",
      "-35.216773 | 14.703450 | 108.162837\n",
      "-33.526879 | 14.482099 | 106.902374\n",
      "-31.408753 | 13.940350 | 105.322173\n",
      "-28.373535 | 13.772495 | 104.130141\n",
      "-24.568508 | 12.268601 | 103.224425\n",
      "-20.136434 | 9.409976 | 102.608482\n",
      "-15.855859 | 4.964646 | 101.480008\n",
      "-12.247650 | -0.336232 | 99.670787\n",
      "-10.161020 | -2.794083 | 97.910172\n",
      "-8.786769 | -4.729948 | 97.959847\n",
      "-7.465153 | -6.489087 | 99.275017\n",
      "-6.763405 | -7.905114 | 101.833964\n",
      "-5.864146 | -10.107584 | 103.484278\n",
      "-4.497666 | -13.308523 | 104.518686\n",
      "-2.515504 | -16.402436 | 104.889851\n",
      "-0.051315 | -18.938662 | 104.645868\n",
      "2.199661 | -20.495568 | 104.068003\n",
      "3.452773 | -21.487812 | 103.977569\n",
      "3.312774 | -22.383575 | 104.921366\n",
      "1.945150 | -22.829206 | 106.874846\n",
      "-0.331696 | -23.196194 | 109.537849\n",
      "-2.137333 | -23.225648 | 112.473564\n",
      "-2.533502 | -23.441046 | 114.880407\n",
      "-1.937372 | -24.124777 | 116.864722\n",
      "-0.344607 | -24.484213 | 117.707025\n",
      "1.845571 | -25.084800 | 117.841557\n",
      "4.760967 | -25.031721 | 117.358143\n",
      "7.654366 | -24.625879 | 116.671799\n",
      "10.080643 | -23.955510 | 116.035866\n",
      "11.794930 | -21.672134 | 115.592651\n",
      "12.782441 | -18.982853 | 115.341868\n",
      "13.359892 | -15.610518 | 115.317941\n",
      "14.261884 | -11.667572 | 115.146668\n",
      "15.114277 | -7.660824 | 114.822330\n",
      "15.938215 | -3.818368 | 114.153360\n",
      "16.719415 | -1.128569 | 112.739076\n",
      "18.275003 | 2.186594 | 111.094703\n",
      "19.010794 | 2.514322 | 110.660978\n",
      "19.347217 | 2.739573 | 111.187614\n",
      "19.150381 | 3.205718 | 112.312676\n",
      "18.765911 | 4.216211 | 113.418964\n",
      "18.741792 | 5.844224 | 113.274783\n",
      "19.964979 | 6.103666 | 112.443985\n",
      "22.133227 | 5.838261 | 110.732755\n",
      "25.640057 | 5.280131 | 108.912454\n",
      "30.128405 | 4.431371 | 107.324702\n",
      "35.119069 | 3.665506 | 106.100479\n",
      "40.366699 | 2.048121 | 105.192331\n",
      "45.863387 | 1.186157 | 104.545220\n",
      "50.387745 | -0.733905 | 102.825231\n",
      "55.228500 | -0.763188 | 101.452162\n",
      "59.768328 | -0.089704 | 99.994332\n",
      "63.866710 | 0.110389 | 98.368049\n",
      "67.698960 | 0.861550 | 96.062669\n",
      "71.654785 | 0.696797 | 93.443330\n",
      "75.536783 | 1.225539 | 90.143686\n",
      "79.441700 | 2.383477 | 86.405240\n",
      "83.772903 | 2.203522 | 83.299306\n",
      "88.188500 | 2.658358 | 80.093405\n",
      "92.929936 | 3.645165 | 76.973610\n",
      "97.975590 | 5.209011 | 74.041378\n",
      "104.088856 | 5.326585 | 72.222093\n",
      "110.425555 | 6.388300 | 70.653479\n",
      "117.121527 | 7.224112 | 69.048577\n",
      "123.370220 | 9.068454 | 68.814844\n",
      "129.701675 | 10.066737 | 68.546861\n",
      "133.914715 | 10.464151 | 69.725424\n",
      "137.053260 | 10.077504 | 71.506915\n",
      "139.317889 | 10.061710 | 72.548123\n",
      "141.694832 | 9.918434 | 73.801290\n",
      "143.666441 | 9.667721 | 75.046589\n",
      "145.012268 | 10.229767 | 76.054008\n",
      "146.809994 | 10.734795 | 76.973856\n",
      "148.629037 | 10.344519 | 76.330425\n",
      "150.635491 | 8.176383 | 75.119316\n",
      "152.284598 | 5.457508 | 73.341533\n",
      "151.607374 | 4.444288 | 71.044041\n",
      "150.503038 | 3.239632 | 68.403617\n",
      "149.273660 | 1.920131 | 65.411564\n",
      "148.668288 | 1.034744 | 61.715375\n",
      "149.342045 | 0.776014 | 58.306683\n",
      "151.023957 | 1.211449 | 54.962383\n",
      "154.009621 | 2.173493 | 51.712536\n",
      "162.280617 | 3.058377 | 48.954873\n",
      "170.106198 | 4.837500 | 46.768775\n",
      "176.016993 | 3.938115 | 45.031579\n",
      "-178.711787 | 3.733731 | 43.779322\n",
      "-174.246204 | 3.846868 | 43.194034\n",
      "-171.355268 | 3.505367 | 43.069175\n",
      "-169.572029 | 2.292054 | 43.076074\n",
      "-169.525318 | 0.124817 | 42.949259\n",
      "-169.871519 | 0.691398 | 42.061831\n",
      "-170.671622 | 0.011441 | 42.217511\n",
      "-171.339156 | -1.373225 | 42.883683\n",
      "-171.668633 | -2.852194 | 43.987358\n",
      "-171.698435 | -4.065546 | 45.623970\n",
      "-171.563674 | -4.953053 | 47.895103\n",
      "-171.468490 | -5.711288 | 51.063885\n",
      "-171.664882 | -6.527715 | 54.877192\n",
      "-172.016485 | -7.830503 | 59.018944\n",
      "-172.365735 | -8.990125 | 62.583976\n",
      "-173.356236 | -10.049815 | 65.443276\n",
      "-174.581355 | -10.809448 | 67.754914\n",
      "-175.743811 | -11.240328 | 69.786893\n",
      "-176.368259 | -11.283816 | 71.794761\n",
      "-176.296490 | -11.961469 | 73.189608\n",
      "-175.348396 | -11.429026 | 73.777258\n",
      "-175.584629 | -9.819800 | 73.836193\n",
      "-177.307444 | -6.845096 | 73.342443\n",
      "-179.031102 | -3.515180 | 72.029141\n",
      "179.825069 | -0.262675 | 70.061249\n",
      "177.141433 | 3.652044 | 67.681605\n",
      "174.283862 | 7.454827 | 64.899720\n",
      "177.505528 | 6.186571 | 63.374987\n",
      "-177.021839 | 5.863215 | 62.094622\n",
      "-172.218941 | 6.077387 | 60.771897\n",
      "-167.433738 | 6.402492 | 59.422491\n",
      "-162.368144 | 6.668672 | 58.026760\n",
      "-156.885637 | 6.811311 | 56.590133\n",
      "-151.007987 | 7.628360 | 55.557671\n",
      "-146.354806 | 8.265076 | 55.111766\n",
      "-142.836030 | 7.600929 | 54.802179\n",
      "-141.357297 | 6.562183 | 55.298675\n",
      "-142.028486 | 5.484288 | 56.483513\n",
      "-144.352409 | 4.507778 | 58.447622\n",
      "-146.860004 | 3.882309 | 61.299578\n",
      "-148.552916 | 3.822643 | 63.860298\n",
      "-149.150215 | 2.988399 | 65.312409\n",
      "-148.639660 | 1.807636 | 65.238957\n",
      "-147.138351 | 0.282166 | 63.600883\n",
      "-144.883301 | -1.415022 | 60.912992\n",
      "-145.373511 | -0.678669 | 58.226736\n",
      "-145.406364 | -0.076124 | 55.697958\n",
      "-146.128056 | 0.475147 | 53.525669\n",
      "-146.268886 | 0.815659 | 51.851062\n",
      "-145.705603 | 1.968144 | 51.215850\n",
      "-145.658842 | 2.806764 | 50.686113\n",
      "-146.088602 | 3.645910 | 50.218319\n",
      "-148.300580 | 4.982226 | 49.822206\n",
      "-151.201161 | 4.675547 | 49.654754\n",
      "-154.695665 | 4.584895 | 50.148709\n",
      "-156.912130 | 5.040670 | 50.950993\n",
      "-157.864698 | 5.896938 | 51.761206\n",
      "-158.177960 | 7.536854 | 52.108948\n",
      "-158.013265 | 8.299664 | 52.468401\n",
      "-157.208826 | 8.817906 | 52.289160\n",
      "-156.084720 | 9.258311 | 51.553618\n",
      "-154.992506 | 10.259283 | 50.134583\n",
      "-156.516553 | 11.072561 | 48.499289\n",
      "-159.343709 | 12.745065 | 45.874513\n",
      "-162.273395 | 14.826566 | 42.501142\n",
      "-162.898138 | 15.584631 | 39.897461\n",
      "-164.440962 | 16.894814 | 36.577486\n",
      "-164.367783 | 18.754861 | 33.249564\n",
      "-164.662298 | 19.302955 | 30.486984\n",
      "-165.519016 | 19.829406 | 27.699251\n",
      "-166.972258 | 20.740995 | 24.745515\n",
      "-170.143661 | 21.609001 | 21.434393\n",
      "-173.204345 | 21.773495 | 18.878092\n",
      "-176.037872 | 20.771679 | 17.451450\n",
      "-179.154669 | 18.892676 | 17.223412\n",
      "177.790060 | 16.674671 | 17.983579\n",
      "175.240842 | 14.393376 | 19.304802\n",
      "171.282862 | 12.097979 | 20.394858\n",
      "165.653416 | 9.821620 | 21.464066\n",
      "158.409177 | 8.477202 | 22.159095\n",
      "150.256051 | 6.428220 | 22.964793\n",
      "142.828032 | 3.950995 | 23.171938\n",
      "135.173459 | 1.531650 | 23.409877\n",
      "127.851942 | -0.284340 | 22.965017\n",
      "121.840509 | -1.932139 | 21.919358\n",
      "119.660467 | -3.655196 | 21.000497\n",
      "117.221119 | -5.523111 | 21.007778\n",
      "116.365697 | -7.154506 | 21.721385\n",
      "117.435719 | -8.690046 | 23.050740\n",
      "117.931076 | -10.069496 | 25.819266\n",
      "118.697659 | -10.881801 | 28.454063\n",
      "119.403749 | -11.510472 | 31.030893\n",
      "119.951190 | -12.254586 | 33.667178\n",
      "120.157961 | -13.407092 | 36.489765\n",
      "119.411691 | -15.319190 | 39.563513\n",
      "118.921641 | -17.951288 | 42.756069\n",
      "117.809185 | -20.315515 | 45.963085\n",
      "116.300961 | -22.650707 | 49.537431\n",
      "114.629129 | -24.670947 | 53.405530\n",
      "113.349520 | -26.251072 | 57.272318\n",
      "111.551233 | -27.884272 | 60.954149\n",
      "108.671757 | -29.012726 | 64.505209\n",
      "104.492487 | -29.718732 | 67.574881\n",
      "99.858505 | -30.165374 | 70.354974\n",
      "94.804097 | -31.170414 | 72.831913\n",
      "90.442592 | -32.092877 | 74.999978\n",
      "89.609757 | -32.111100 | 75.961921\n",
      "90.372597 | -32.027662 | 76.100902\n",
      "91.397666 | -31.952966 | 75.971817\n",
      "91.603791 | -31.245199 | 76.033750\n",
      "91.010831 | -30.109337 | 76.337343\n",
      "89.697276 | -28.694058 | 76.816133\n",
      "86.078164 | -27.411376 | 77.350934\n",
      "81.835161 | -26.187549 | 77.550131\n",
      "76.926847 | -25.736505 | 77.390854\n",
      "69.989922 | -26.057666 | 77.546312\n",
      "63.908512 | -26.934542 | 77.274993\n",
      "57.367236 | -28.558474 | 77.217190\n",
      "52.423503 | -30.033569 | 76.848443\n",
      "47.389301 | -31.679190 | 76.658030\n",
      "42.714207 | -33.228841 | 76.607518\n",
      "37.879304 | -33.851794 | 77.065757\n",
      "33.026233 | -34.050026 | 77.345161\n",
      "28.441032 | -33.574608 | 77.322804\n",
      "24.039068 | -33.181687 | 76.698256\n",
      "20.319227 | -33.094023 | 75.478344\n",
      "18.693887 | -34.035658 | 73.590749\n",
      "19.571780 | -36.117053 | 71.289394\n",
      "22.650782 | -39.150908 | 68.692647\n",
      "26.555502 | -42.326933 | 66.191896\n",
      "30.619192 | -44.534574 | 64.147714\n",
      "31.589301 | -44.649903 | 64.358455\n",
      "31.243486 | -43.389348 | 65.326205\n",
      "29.835970 | -40.865300 | 66.846199\n",
      "27.618470 | -36.807387 | 67.945093\n",
      "24.606262 | -31.727099 | 68.571817\n",
      "20.425452 | -26.645323 | 69.750692\n",
      "18.538714 | -22.098196 | 70.213467\n",
      "14.375009 | -17.437586 | 71.055182\n",
      "10.000030 | -13.126975 | 72.045160\n",
      "5.872563 | -9.239806 | 73.680172\n",
      "2.968163 | -5.878478 | 75.853778\n",
      "-0.144415 | -2.519594 | 78.264775\n",
      "-1.781787 | 2.014688 | 80.610199\n",
      "-2.550024 | 2.472524 | 81.817396\n",
      "-4.304614 | 3.411165 | 82.747465\n",
      "-6.655260 | 4.116339 | 82.770822\n",
      "-9.673428 | 4.884328 | 82.042941\n",
      "-12.759090 | 5.570399 | 80.768904\n",
      "-15.247982 | 4.805243 | 79.581249\n",
      "-18.468124 | 4.469989 | 78.266403\n",
      "-20.003554 | 4.430169 | 76.831089\n",
      "-21.179751 | 4.215678 | 75.230360\n",
      "-23.338902 | 4.398049 | 74.180535\n",
      "-23.806266 | 4.113017 | 74.058149\n",
      "-26.143884 | 4.433066 | 74.588624\n",
      "-28.540609 | 4.967365 | 75.474643\n",
      "-31.037883 | 6.738641 | 76.715735\n",
      "-33.355757 | 7.412371 | 77.514259\n",
      "-33.299078 | 7.931544 | 78.029695\n",
      "-32.296875 | 8.461943 | 79.044636\n",
      "-30.442354 | 9.120735 | 80.528836\n",
      "-28.383420 | 10.983576 | 82.730891\n",
      "-27.115039 | 11.738560 | 84.703048\n",
      "-25.946966 | 12.771754 | 86.833842\n",
      "-24.600488 | 13.944050 | 88.834444\n",
      "-22.790317 | 13.890863 | 90.042784\n",
      "-21.662807 | 14.088217 | 90.884821\n",
      "-20.232581 | 14.166185 | 91.657023\n",
      "-19.076418 | 14.614396 | 92.146534\n",
      "-17.884541 | 15.147906 | 92.476343\n",
      "-18.067740 | 15.226431 | 92.813010\n",
      "-18.712863 | 14.717376 | 92.909877\n",
      "-19.653323 | 13.648689 | 92.504894\n",
      "-20.576002 | 12.567279 | 92.568615\n",
      "-22.190186 | 11.682639 | 92.787902\n",
      "-24.564393 | 11.070946 | 93.061441\n",
      "-24.657567 | 9.547842 | 93.803140\n",
      "-24.864227 | 7.702716 | 94.462668\n",
      "-24.123330 | 5.183583 | 94.542804\n",
      "-22.311124 | 2.185114 | 94.001822\n",
      "-19.122706 | -0.983481 | 93.034762\n",
      "-18.553035 | -0.239892 | 91.544817\n",
      "-18.467148 | 0.739767 | 90.376540\n",
      "-18.557879 | 1.657653 | 89.613852\n",
      "-18.198211 | 1.719008 | 89.434115\n",
      "-17.599736 | 1.448471 | 89.344109\n",
      "-17.431995 | 1.300565 | 89.194972\n",
      "-17.323133 | 1.157665 | 88.887149\n",
      "-17.107127 | 1.026095 | 88.700844\n",
      "-17.350546 | 0.894482 | 88.403657\n",
      "-15.947150 | 0.378806 | 88.026103\n",
      "-16.506829 | -0.030213 | 88.140937\n",
      "-14.879196 | -0.341650 | 88.453350\n",
      "-13.043066 | -1.644593 | 89.098500\n",
      "-11.425639 | -1.989758 | 89.299020\n",
      "-10.529816 | -1.761141 | 88.937278\n",
      "-9.517441 | -0.933322 | 88.128175\n",
      "-8.505727 | -0.201241 | 86.749555\n",
      "-8.198413 | 0.489003 | 85.037035\n",
      "-9.249205 | 0.866744 | 83.301883\n",
      "-10.137969 | 1.315568 | 81.845737\n",
      "-9.446041 | 1.241778 | 81.221635\n",
      "-9.213211 | 2.535319 | 80.874186\n",
      "-8.774033 | 3.343269 | 80.936290\n",
      "-7.349193 | 4.299503 | 81.128759\n",
      "-4.211720 | 5.255390 | 81.380636\n",
      "0.031770 | 6.524524 | 81.924854\n",
      "3.113709 | 7.529642 | 82.333078\n",
      "5.561107 | 8.040548 | 82.105763\n",
      "8.648298 | 8.084994 | 81.089517\n",
      "10.373104 | 7.788262 | 79.481668\n",
      "10.929531 | 7.384062 | 77.709484\n",
      "10.389010 | 6.869708 | 76.254657\n",
      "9.338710 | 6.388267 | 75.498088\n",
      "9.500058 | 6.299827 | 75.648601\n",
      "9.669435 | 6.539509 | 76.596906\n",
      "9.855248 | 5.361162 | 77.221921\n",
      "9.299936 | 4.248633 | 77.892650\n",
      "8.188559 | 3.212401 | 78.498279\n",
      "6.700562 | 2.378139 | 78.817262\n",
      "5.468712 | 1.562477 | 78.673999\n",
      "4.234769 | 0.613955 | 79.094807\n",
      "4.036971 | -0.118975 | 79.945335\n",
      "3.979791 | -1.248021 | 81.097062\n",
      "5.269462 | -3.145813 | 82.488368\n",
      "5.689724 | -5.309048 | 83.586673\n",
      "5.574209 | -8.542142 | 83.651170\n",
      "4.995139 | -11.069700 | 82.851686\n",
      "5.338826 | -12.244567 | 81.523287\n",
      "6.844381 | -12.686853 | 80.079343\n",
      "5.152253 | -11.417838 | 79.631210\n",
      "3.376913 | -9.756057 | 79.758716\n",
      "4.846420 | -8.841650 | 80.169408\n",
      "6.533037 | -8.013268 | 80.588325\n",
      "6.491483 | -6.275439 | 80.928857\n",
      "7.111964 | -4.460419 | 80.011074\n",
      "8.409539 | -2.125462 | 80.088483\n",
      "10.757399 | 0.988673 | 80.879679\n",
      "14.755219 | 0.748949 | 81.825783\n",
      "19.170875 | -1.307086 | 82.612097\n",
      "23.069581 | -4.526015 | 83.114250\n",
      "25.524376 | -8.037132 | 83.570459\n",
      "27.701500 | -10.765432 | 82.465020\n",
      "30.373867 | -12.847418 | 80.262617\n",
      "31.334729 | -12.669032 | 78.159376\n",
      "31.911416 | -11.262266 | 75.949897\n",
      "32.396318 | -8.728773 | 73.712171\n",
      "33.841769 | -5.945150 | 71.112531\n",
      "34.842364 | -3.157443 | 68.426760\n",
      "37.572196 | -0.548570 | 65.502495\n",
      "39.682467 | 0.597354 | 63.757532\n",
      "41.955750 | 1.611798 | 62.318239\n",
      "44.531066 | 2.779586 | 61.221344\n",
      "47.237164 | 4.802296 | 60.875111\n",
      "49.707515 | 6.152628 | 60.535705\n",
      "52.202328 | 7.478426 | 60.398529\n",
      "53.282584 | 8.431383 | 59.369784\n",
      "53.028376 | 10.074997 | 58.723200\n",
      "52.833903 | 11.275119 | 58.600016\n",
      "51.858873 | 11.596109 | 59.243465\n",
      "50.576686 | 10.900400 | 59.997766\n",
      "49.091803 | 9.620475 | 60.632348\n",
      "48.212321 | 8.144080 | 61.129878\n",
      "48.202950 | 6.028296 | 61.723285\n",
      "47.828693 | 4.211264 | 62.102514\n",
      "47.301635 | 2.589474 | 62.462809\n",
      "47.008342 | 0.331421 | 63.251316\n",
      "45.803413 | -1.670836 | 63.832585\n",
      "46.594847 | -4.180633 | 64.109813\n",
      "44.809611 | -6.484041 | 64.343422\n",
      "41.953567 | -9.331942 | 63.636169\n",
      "38.495573 | -10.350728 | 61.905625\n",
      "33.416824 | -10.296977 | 59.269052\n",
      "28.455981 | -9.724071 | 55.309267\n",
      "21.663055 | -8.484613 | 50.886736\n",
      "15.069581 | -8.010423 | 46.107131\n",
      "10.632611 | -8.599992 | 41.274590\n",
      "7.294362 | -8.917969 | 36.998800\n",
      "5.628498 | -9.504124 | 32.904322\n",
      "7.490647 | -10.031766 | 28.478782\n",
      "9.658958 | -9.929799 | 24.863748\n",
      "12.385541 | -9.493239 | 22.196849\n",
      "16.434575 | -8.911643 | 20.165811\n",
      "20.550421 | -8.034249 | 18.453478\n",
      "24.745736 | -6.723052 | 16.275611\n",
      "28.410057 | -4.076051 | 13.832868\n",
      "31.357619 | -0.221598 | 11.457637\n",
      "33.793042 | 4.590449 | 9.408699\n",
      "34.927087 | 9.572013 | 8.041068\n",
      "34.837837 | 10.344497 | 7.590820\n",
      "34.463318 | 11.029333 | 7.259922\n",
      "34.458496 | 12.541500 | 6.841000\n",
      "34.157947 | 14.092029 | 6.314554\n",
      "33.586283 | 14.918228 | 5.610534\n",
      "33.091849 | 15.411062 | 4.776724\n",
      "32.493307 | 16.067153 | 2.991197\n",
      "31.894413 | 16.115060 | 0.847986\n",
      "30.742724 | 16.011344 | -1.780598\n",
      "29.991949 | 16.565302 | -3.459648\n",
      "29.317913 | 16.063191 | -5.685974\n",
      "28.488402 | 16.016184 | -8.517328\n",
      "28.470602 | 15.298007 | -10.580132\n",
      "29.276159 | 15.388979 | -11.772999\n",
      "30.452851 | 14.792897 | -12.438339\n",
      "31.266430 | 14.405898 | -12.765547\n",
      "32.105510 | 14.196911 | -13.000957\n",
      "31.842587 | 13.754626 | -13.181001\n",
      "30.079581 | 13.794530 | -13.375129\n",
      "27.109363 | 12.616511 | -13.653468\n",
      "23.599359 | 11.031130 | -13.382247\n",
      "19.877668 | 9.557048 | -12.233273\n",
      "16.324141 | 6.587534 | -10.744338\n",
      "13.743621 | 4.978069 | -8.128937\n",
      "11.458151 | 3.546865 | -4.811991\n",
      "9.768309 | 2.446412 | -1.083511\n",
      "9.766833 | 3.606571 | 3.043198\n",
      "9.566039 | 2.083971 | 6.051988\n",
      "9.866965 | 1.896216 | 10.010672\n",
      "11.691168 | 2.925606 | 14.847054\n",
      "14.159171 | 5.324522 | 19.470232\n",
      "15.084834 | 5.542739 | 22.368665\n",
      "15.077600 | 5.858975 | 25.052828\n",
      "13.677147 | 5.978164 | 27.691225\n",
      "10.695985 | 5.863393 | 30.043569\n",
      "6.291081 | 5.624580 | 32.233443\n",
      "3.530424 | 6.578500 | 34.447071\n",
      "0.633234 | 7.867617 | 36.342312\n",
      "-4.543390 | 7.201609 | 37.340351\n",
      "-8.508101 | 7.465838 | 38.040189\n",
      "-12.901340 | 7.240255 | 38.581426\n",
      "-19.212725 | 6.756317 | 38.868830\n",
      "-24.584122 | 7.608279 | 39.151089\n",
      "-31.104788 | 7.532687 | 39.507490\n",
      "-37.450485 | 8.742178 | 39.577263\n",
      "-44.070658 | 8.866320 | 39.846973\n",
      "-49.602205 | 9.364935 | 40.201214\n",
      "-54.854244 | 9.876355 | 41.363513\n",
      "-59.990692 | 10.487457 | 43.192869\n",
      "-65.172192 | 10.231384 | 44.681518\n",
      "-69.546357 | 10.303099 | 46.133722\n",
      "-73.452227 | 11.007665 | 46.397338\n",
      "-76.516188 | 11.006226 | 47.201792\n",
      "-78.479680 | 10.857888 | 48.773737\n",
      "-78.719026 | 10.304002 | 50.795285\n",
      "-77.940453 | 10.201175 | 53.419389\n",
      "-76.483127 | 10.972379 | 56.575673\n",
      "-74.614659 | 12.149230 | 59.930421\n",
      "-72.316086 | 13.345316 | 63.327821\n",
      "-71.659573 | 13.754294 | 65.730796\n",
      "-71.550001 | 14.491360 | 67.877145\n",
      "-71.854988 | 15.659920 | 69.708997\n",
      "-71.313425 | 16.069300 | 71.552053\n",
      "-70.297828 | 15.826564 | 73.076411\n",
      "-69.061102 | 14.765196 | 74.179702\n",
      "-68.247406 | 13.769928 | 74.724989\n",
      "-66.389569 | 11.891138 | 75.424240\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3799/3135774575.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctrl\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegtorad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_k\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def target_action(input):\n",
    "    if input.size(dim=0) == 0:\n",
    "        return torch.tensor([input[0] * 80,\n",
    "        input[1] * 180,\n",
    "        input[2] * 10,\n",
    "        input[3] * 80,\n",
    "        input[4] * 180,\n",
    "        input[5] * 10,\n",
    "        abs(input[6]) * 4,\n",
    "        input[7]], device=device)\n",
    "    else:\n",
    "        action_elements = input[input[:,7].max(0).indices]\n",
    "        return torch.tensor([action_elements[0] * 80,\n",
    "        action_elements[1] * 180,\n",
    "        action_elements[2] * 10,\n",
    "        action_elements[3] * 80,\n",
    "        action_elements[4] * 180,\n",
    "        action_elements[5] * 10,\n",
    "        abs(action_elements[6]) * 4], device=device)\n",
    "\n",
    "\n",
    "\n",
    "simulator.reset()\n",
    "viewer = mujoco_py.MjViewer(simulator) #For rendering sim results.\n",
    "\n",
    "\n",
    "for k in range(6000):\n",
    "        state = stepListener(k)\n",
    "\n",
    "        r,p,y = quat2euler(state[-3], state[-2], state[-1], state[-4])\n",
    "\n",
    "        print(\"%2f | %2f | %2f\"%(math.degrees(r), math.degrees(p), math.degrees(y)))\n",
    "        # print(\"%2f | %2f | %2f | %2f\"%(math.degrees(state[-3]), math.degrees(state[-2]), math.degrees(state[-1]), math.degrees(state[-4])))\n",
    "\n",
    "        action = target_net(torch.from_numpy(state))\n",
    "\n",
    "        gait_param = target_action(action).tolist()\n",
    "\n",
    "        G_k = genGait(k,1, gait_param[0], gait_param[1], gait_param[2], gait_param[3], gait_param[4], gait_param[5], gait_param[6])\n",
    "\n",
    "        motor_idx = np.nonzero(G_k)\n",
    "\n",
    "        for idx in motor_idx:\n",
    "                    if not(len(idx) == 0):\n",
    "                        simulator.data.ctrl[idx] = g.degtorad(G_k[idx])\n",
    "\n",
    "        simulator.step()\n",
    "        viewer.render()\n",
    "\n",
    "del viewer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 Model 저장하기\n",
    "모델 학습을 처음부터 다시 진행하는 것보다 학습되어진 모델에 이어서 학습하는 것이 더 빠르게 수렴할 수 있으므로 모델을 저장해야한다. Pytorch는 Pickle 기반으로 변수를 파일로 저장한다. 아래 코드로 학습된 Target Net을 저장할 수 있다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "nprefix = now.strftime(\"%Y%m%d%H%m\")\n",
    "\n",
    "torch.save(policy_net.state_dict(),\"./weights/policy\"+nprefix+\"V3.pt\")\n",
    "torch.save(target_net.state_dict(),\"./weights/target\"+nprefix+\"v3.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reward_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3799/4034064853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnext_state_values\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtarget_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mexpected_state_action_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnext_state_values\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreward_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reward_batch' is not defined"
     ]
    }
   ],
   "source": [
    "next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "next_state_values= target_net(torch.ones((2,36)))[:,7].max(0).values\n",
    "\n",
    "expected_state_action_values = (next_state_values * GAMMA) + reward_batch.squeeze(1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "25153d951b89deeb1c78c92fd88111ab529a9e48e9f3ab99db1d36fbf759f4d2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('rl': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
